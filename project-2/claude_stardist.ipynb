{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705c6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cellpose in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (4.0.7)\n",
      "Requirement already satisfied: stardist in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (0.9.1)\n",
      "Requirement already satisfied: scikit-image in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (0.25.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: opencv-python in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: pandas in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (1.16.3)\n",
      "Requirement already satisfied: joblib in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (1.26.4)\n",
      "Requirement already satisfied: natsort in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (8.4.0)\n",
      "Requirement already satisfied: tifffile in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (2025.10.16)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (4.11.0.86)\n",
      "Requirement already satisfied: fastremap in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (1.17.7)\n",
      "Requirement already satisfied: imagecodecs in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (2025.8.2)\n",
      "Requirement already satisfied: roifile in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (2025.5.10)\n",
      "Requirement already satisfied: fill-voids in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (2.1.1)\n",
      "Requirement already satisfied: segment_anything in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from cellpose) (1.0)\n",
      "Requirement already satisfied: csbdeep>=0.8.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from stardist) (0.8.1)\n",
      "Requirement already satisfied: numba in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from stardist) (0.60.0)\n",
      "Requirement already satisfied: imageio in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from stardist) (2.37.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from scikit-image) (3.5)\n",
      "Requirement already satisfied: pillow>=10.1 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from scikit-image) (12.0.0)\n",
      "Requirement already satisfied: packaging>=21 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from scikit-image) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: matplotlib in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from csbdeep>=0.8.0->stardist) (3.10.7)\n",
      "Requirement already satisfied: six in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from csbdeep>=0.8.0->stardist) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from numba->stardist) (0.43.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from matplotlib->csbdeep>=0.8.0->stardist) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from matplotlib->csbdeep>=0.8.0->stardist) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from matplotlib->csbdeep>=0.8.0->stardist) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from matplotlib->csbdeep>=0.8.0->stardist) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/swooshie/Desktop/User/Aditya/NYU/Semester/Fall-2025/Courses/Computer Vision/Projects/Repository/computer-vision/cell_project_env/lib/python3.12/site-packages (from matplotlib->csbdeep>=0.8.0->stardist) (3.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install cellpose stardist scikit-image scikit-learn opencv-python torch torchvision pandas tqdm scipy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pretrained models\n",
    "from cellpose import models as cellpose_models\n",
    "from cellpose.models import CellposeModel\n",
    "import stardist\n",
    "from stardist.models import StarDist2D\n",
    "from stardist.data import test_image_nuclei\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy import ndimage\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Setup device - MPS for MacBook M3, fallback to CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Metal Performance Shaders)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. RLE ENCODING/DECODING\n",
    "# ============================================================================\n",
    "\n",
    "def rle_decode_instance_mask(rle: str, shape: tuple) -> np.ndarray:\n",
    "    \"\"\"Decode RLE string back to instance mask\"\"\"\n",
    "    if not rle or str(rle).strip() in (\"\", \"0\", \"nan\"):\n",
    "        return np.zeros(shape, dtype=np.uint16)\n",
    "    s = list(map(int, rle.split()))\n",
    "    mask = np.zeros(shape[0]*shape[1], dtype=np.uint16)\n",
    "    for i in range(0, len(s), 3):\n",
    "        val, start, length = s[i], s[i+1], s[i+2]\n",
    "        mask[start-1:start-1+length] = val\n",
    "    return mask.reshape(shape, order=\"F\")\n",
    "\n",
    "def rle_encode_instance_mask(mask: np.ndarray) -> str:\n",
    "    \"\"\"Encode instance mask to RLE string\"\"\"\n",
    "    pixels = mask.flatten(order=\"F\").astype(np.int32)\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    \n",
    "    rle = []\n",
    "    for i in range(0, len(runs)-1):\n",
    "        start = runs[i]\n",
    "        end = runs[i+1] if i+1 < len(runs) else len(pixels)-1\n",
    "        length = end - start\n",
    "        val = pixels[start]\n",
    "        if val > 0:\n",
    "            rle.extend([val, start, length])\n",
    "    \n",
    "    return \" \".join(map(str, rle)) if rle else \"0\"\n",
    "\n",
    "# ============================================================================\n",
    "# 2. XML ANNOTATION PARSING\n",
    "# ============================================================================\n",
    "\n",
    "def parse_xml_annotations(xml_path):\n",
    "    \"\"\"Parse raw XML annotations to get instance masks and labels\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    annotations = {}\n",
    "    for annotation in root.findall('Annotation'):\n",
    "        cell_type = annotation.get('Name')\n",
    "        if cell_type not in ['Epithelial', 'Lymphocyte', 'Macrophage', 'Neutrophil']:\n",
    "            continue\n",
    "        \n",
    "        regions = []\n",
    "        for region in annotation.findall('Region'):\n",
    "            vertices = []\n",
    "            for vertex in region.findall('Vertex'):\n",
    "                x = int(vertex.get('X'))\n",
    "                y = int(vertex.get('Y'))\n",
    "                vertices.append([x, y])\n",
    "            if vertices:\n",
    "                regions.append(np.array(vertices, dtype=np.int32))\n",
    "        \n",
    "        annotations[cell_type] = regions\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def create_instance_masks_from_xml(xml_path, image_shape):\n",
    "    \"\"\"Create instance segmentation masks from XML polygons\"\"\"\n",
    "    annotations = parse_xml_annotations(xml_path)\n",
    "    \n",
    "    masks = {}\n",
    "    for cell_type in ['Epithelial', 'Lymphocyte', 'Macrophage', 'Neutrophil']:\n",
    "        instance_mask = np.zeros(image_shape[:2], dtype=np.uint16)\n",
    "        \n",
    "        if cell_type in annotations:\n",
    "            for instance_id, polygon in enumerate(annotations[cell_type], 1):\n",
    "                cv2.drawContours(instance_mask, [polygon], 0, instance_id, -1)\n",
    "        \n",
    "        masks[cell_type] = instance_mask\n",
    "    \n",
    "    return masks\n",
    "\n",
    "# ============================================================================\n",
    "# 3. FEATURE EXTRACTION FOR CLASSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def extract_nucleus_features(image, instance_mask, nucleus_id):\n",
    "    \"\"\"Extract features for a single nucleus\"\"\"\n",
    "    nucleus_region = (instance_mask == nucleus_id)\n",
    "    \n",
    "    # Get the bounding box\n",
    "    coords = np.where(nucleus_region)\n",
    "    if len(coords[0]) == 0:\n",
    "        return None\n",
    "    \n",
    "    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "    \n",
    "    # Extract intensity statistics\n",
    "    nucleus_pixels = image[nucleus_region]\n",
    "    \n",
    "    features = {\n",
    "        'mean_intensity': nucleus_pixels.mean(),\n",
    "        'std_intensity': nucleus_pixels.std(),\n",
    "        'min_intensity': nucleus_pixels.min(),\n",
    "        'max_intensity': nucleus_pixels.max(),\n",
    "        'area': nucleus_region.sum(),\n",
    "        'perimeter': cv2.contourArea(np.where(nucleus_region)),\n",
    "        'solidity': nucleus_region.sum() / ((y_max - y_min + 1) * (x_max - x_min + 1)),\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_training_features(train_dir, train_csv, xml_dir):\n",
    "    \"\"\"Extract features from training set for classifier\"\"\"\n",
    "    df = pd.read_csv(train_csv)\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\"):\n",
    "        img_id = row['image_id']\n",
    "        img_path = Path(train_dir) / f\"{img_id}.tif\"\n",
    "        xml_path = Path(xml_dir) / f\"{img_id}.xml\"\n",
    "        \n",
    "        if not img_path.exists() or not xml_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        # Convert to grayscale for intensity features\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        masks = create_instance_masks_from_xml(xml_path, image.shape)\n",
    "        \n",
    "        for cell_type, mask in masks.items():\n",
    "            for nucleus_id in np.unique(mask):\n",
    "                if nucleus_id == 0:\n",
    "                    continue\n",
    "                \n",
    "                feat = extract_nucleus_features(gray, mask, nucleus_id)\n",
    "                if feat:\n",
    "                    all_features.append(feat)\n",
    "                    label = ['Epithelial', 'Lymphocyte', 'Macrophage', 'Neutrophil'].index(cell_type)\n",
    "                    all_labels.append(label)\n",
    "    \n",
    "    features_df = pd.DataFrame(all_features)\n",
    "    return features_df.values, np.array(all_labels)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. SEGMENTATION WITH CELLPOSE\n",
    "# ============================================================================\n",
    "\n",
    "class CellposeSegmenter:\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = device\n",
    "        # Use pretrained nuclei model\n",
    "        self.model = CellposeModel(gpu=(device=='mps' or device=='cuda'), \n",
    "                             model_type='nuclei',\n",
    "                             device=device)\n",
    "    \n",
    "    def segment(self, image):\n",
    "        \"\"\"Segment nuclei in image\"\"\"\n",
    "        # Cellpose expects RGB images\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            img = image\n",
    "        else:\n",
    "            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Run segmentation\n",
    "        masks, _, _, _ = self.model.eval(img, diameter=30, channels=[0, 0])\n",
    "        \n",
    "        return masks\n",
    "\n",
    "# ============================================================================\n",
    "# 5. SEGMENTATION WITH STARDIST\n",
    "# ============================================================================\n",
    "\n",
    "class StarDistSegmenter:\n",
    "    def __init__(self):\n",
    "        # Use pretrained 2D nuclei model\n",
    "        self.model = StarDist2D.from_pretrained('2D_nuclei_obj')\n",
    "    \n",
    "    def segment(self, image):\n",
    "        \"\"\"Segment nuclei in image\"\"\"\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            img = image\n",
    "        \n",
    "        # Normalize to 0-1\n",
    "        img = (img / 255.0).astype(np.float32)\n",
    "        \n",
    "        labels, _ = self.model.predict_instances(img)\n",
    "        \n",
    "        return labels\n",
    "\n",
    "# ============================================================================\n",
    "# 6. ENSEMBLE SEGMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "def ensemble_segment(image, use_cellpose=True, use_stardist=True):\n",
    "    \"\"\"Ensemble both models for robust segmentation\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if use_cellpose:\n",
    "        try:\n",
    "            segmenter = CellposeSegmenter(device=str(device))\n",
    "            cellpose_mask = segmenter.segment(image)\n",
    "            results.append(cellpose_mask)\n",
    "        except Exception as e:\n",
    "            print(f\"Cellpose failed: {e}\")\n",
    "    \n",
    "    if use_stardist:\n",
    "        try:\n",
    "            segmenter = StarDistSegmenter()\n",
    "            stardist_mask = segmenter.segment(image)\n",
    "            results.append(stardist_mask)\n",
    "        except Exception as e:\n",
    "            print(f\"StarDist failed: {e}\")\n",
    "    \n",
    "    if not results:\n",
    "        raise Exception(\"Both segmentation models failed\")\n",
    "    \n",
    "    if len(results) == 1:\n",
    "        return results[0]\n",
    "    \n",
    "    # Ensemble: take union of detections and merge close instances\n",
    "    ensemble_mask = np.zeros_like(results[0])\n",
    "    current_id = 1\n",
    "    \n",
    "    for result in results:\n",
    "        for nucleus_id in np.unique(result):\n",
    "            if nucleus_id == 0:\n",
    "                continue\n",
    "            nucleus = (result == nucleus_id)\n",
    "            ensemble_mask[nucleus] = current_id\n",
    "            current_id += 1\n",
    "    \n",
    "    return ensemble_mask\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CELL TYPE CLASSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "class NucleusClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def train(self, features, labels):\n",
    "        \"\"\"Train classifier on extracted features\"\"\"\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        self.model.fit(features_scaled, labels)\n",
    "        self.is_fitted = True\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Predict cell types\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise Exception(\"Classifier not trained\")\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        return self.model.predict(features_scaled)\n",
    "    \n",
    "    def save(self, path):\n",
    "        joblib.dump({'model': self.model, 'scaler': self.scaler}, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        data = joblib.load(path)\n",
    "        self.model = data['model']\n",
    "        self.scaler = data['scaler']\n",
    "        self.is_fitted = True\n",
    "\n",
    "# ============================================================================\n",
    "# 8. INFERENCE PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def predict_image_with_classification(image_path, segmenter, classifier, device):\n",
    "    \"\"\"Segment and classify nuclei in an image\"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "    \n",
    "    # Segment\n",
    "    instance_mask = ensemble_segment(image)\n",
    "    \n",
    "    # Convert to grayscale for feature extraction\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Classify each nucleus\n",
    "    classified_masks = {\n",
    "        'Epithelial': np.zeros_like(instance_mask),\n",
    "        'Lymphocyte': np.zeros_like(instance_mask),\n",
    "        'Macrophage': np.zeros_like(instance_mask),\n",
    "        'Neutrophil': np.zeros_like(instance_mask)\n",
    "    }\n",
    "    \n",
    "    cell_types = ['Epithelial', 'Lymphocyte', 'Macrophage', 'Neutrophil']\n",
    "    current_ids = {ct: 1 for ct in cell_types}\n",
    "    \n",
    "    for nucleus_id in np.unique(instance_mask):\n",
    "        if nucleus_id == 0:\n",
    "            continue\n",
    "        \n",
    "        # Extract features\n",
    "        feat = extract_nucleus_features(gray, instance_mask, nucleus_id)\n",
    "        if feat is None:\n",
    "            continue\n",
    "        \n",
    "        feat_array = np.array(list(feat.values())).reshape(1, -1)\n",
    "        predicted_label = classifier.predict(feat_array)[0]\n",
    "        cell_type = cell_types[predicted_label]\n",
    "        \n",
    "        # Assign to classified mask\n",
    "        nucleus_region = (instance_mask == nucleus_id)\n",
    "        classified_masks[cell_type][nucleus_region] = current_ids[cell_type]\n",
    "        current_ids[cell_type] += 1\n",
    "    \n",
    "    return classified_masks\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = Path(\"kaggle-data\")\n",
    "    train_dir = data_dir / \"train\"\n",
    "    val_dir = data_dir / \"val\"\n",
    "    test_dir = data_dir / \"test_final\"\n",
    "    \n",
    "    train_csv = data_dir / \"train_ground_truth.csv\"\n",
    "    val_csv = data_dir / \"val_truth.csv\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CELL SEGMENTATION & CLASSIFICATION PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Step 1: Train classifier\n",
    "    print(\"\\n[1/4] Extracting features for classifier training...\")\n",
    "    try:\n",
    "        X_train, y_train = extract_training_features(train_dir, train_csv, train_dir)\n",
    "        \n",
    "        classifier = NucleusClassifier()\n",
    "        print(f\"Training classifier on {len(X_train)} nuclei...\")\n",
    "        classifier.train(X_train, y_train)\n",
    "        classifier.save(\"nucleus_classifier.pkl\")\n",
    "        print(\"✓ Classifier trained and saved\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Classifier training failed: {e}\")\n",
    "        classifier = None\n",
    "    \n",
    "    # Step 2: Validate on validation set\n",
    "    print(\"\\n[2/4] Validating on validation set...\")\n",
    "    try:\n",
    "        val_images = sorted(val_dir.glob(\"*.tif\"))[:3]  # Test on few images\n",
    "        for img_path in val_images:\n",
    "            print(f\"Processing {img_path.stem}...\")\n",
    "            masks = predict_image_with_classification(img_path, None, classifier, device)\n",
    "            print(f\"  Found: {sum(np.max(m) for m in masks.values())} nuclei\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Validation failed: {e}\")\n",
    "    \n",
    "    # Step 3: Generate predictions on test set\n",
    "    print(\"\\n[3/4] Generating predictions on test set...\")\n",
    "    test_images = sorted(test_dir.glob(\"*.tif\"))\n",
    "    \n",
    "    results = []\n",
    "    for img_path in tqdm(test_images, desc=\"Predicting\"):\n",
    "        img_id = img_path.stem\n",
    "        \n",
    "        try:\n",
    "            if classifier and classifier.is_fitted:\n",
    "                masks = predict_image_with_classification(img_path, None, classifier, device)\n",
    "            else:\n",
    "                # Fallback to segmentation only\n",
    "                image = cv2.imread(str(img_path))\n",
    "                instance_mask = ensemble_segment(image)\n",
    "                masks = {\n",
    "                    'Epithelial': instance_mask,\n",
    "                    'Lymphocyte': np.zeros_like(instance_mask),\n",
    "                    'Macrophage': np.zeros_like(instance_mask),\n",
    "                    'Neutrophil': np.zeros_like(instance_mask)\n",
    "                }\n",
    "            \n",
    "            row = {'image_id': img_id}\n",
    "            for cell_type in ['Epithelial', 'Lymphocyte', 'Neutrophil', 'Macrophage']:\n",
    "                row[cell_type] = rle_encode_instance_mask(masks[cell_type])\n",
    "            \n",
    "            results.append(row)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Prediction failed for {img_id}: {e}\")\n",
    "            row = {'image_id': img_id}\n",
    "            for cell_type in ['Epithelial', 'Lymphocyte', 'Neutrophil', 'Macrophage']:\n",
    "                row[cell_type] = \"0\"\n",
    "            results.append(row)\n",
    "    \n",
    "    # Step 4: Save submission\n",
    "    print(\"\\n[4/4] Saving submission...\")\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(f\"✓ Submission saved: {len(results)} images\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
