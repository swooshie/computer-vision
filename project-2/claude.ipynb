{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea74b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cell Segmentation & Classification Pipeline...\n",
      "Device: cpu\n",
      "\n",
      "=== Training Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:04<00:00,  5.95s/it, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 2.3098 | Val Loss: 2.1123\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:27<00:00,  7.04s/it, loss=1.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.8091 | Val Loss: 1.6894\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:17<00:00,  6.54s/it, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.5903 | Val Loss: 1.5488\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:12<00:00,  6.29s/it, loss=1.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.5036 | Val Loss: 1.4852\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:18<00:00,  6.62s/it, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.4329 | Val Loss: 1.4059\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:47<00:00,  7.97s/it, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.3940 | Val Loss: 1.3699\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:40<00:00,  7.64s/it, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.3422 | Val Loss: 1.3255\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:34<00:00,  7.36s/it, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.2934 | Val Loss: 1.2798\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:20<00:00,  6.69s/it, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.2614 | Val Loss: 1.2478\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:11<00:00,  6.27s/it, loss=1.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.2290 | Val Loss: 1.2160\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:21<00:00,  6.73s/it, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.2021 | Val Loss: 1.1915\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:01<00:00,  5.78s/it, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.1805 | Val Loss: 1.1659\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:26<00:00,  7.00s/it, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.1610 | Val Loss: 1.1484\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:22<00:00,  6.79s/it, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.1427 | Val Loss: 1.1349\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:13<00:00,  6.36s/it, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.1209 | Val Loss: 1.1130\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:13<00:00,  6.33s/it, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.1106 | Val Loss: 1.1063\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:14<00:00,  6.41s/it, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 1.0945 | Val Loss: 1.0829\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:14<00:00,  6.42s/it, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 1.0804 | Val Loss: 1.0704\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:24<00:00,  6.87s/it, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 1.0679 | Val Loss: 1.0582\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:07<00:00,  6.08s/it, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 1.0565 | Val Loss: 1.0513\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:49<00:00,  5.22s/it, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 1.0491 | Val Loss: 1.0433\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:51<00:00,  5.33s/it, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 1.0386 | Val Loss: 1.0319\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:59<00:00,  5.71s/it, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 1.0308 | Val Loss: 1.0243\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:14<00:00,  6.40s/it, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 1.0253 | Val Loss: 1.0173\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:10<00:00,  6.20s/it, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 1.0179 | Val Loss: 1.0116\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:57<00:00,  5.61s/it, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 1.0130 | Val Loss: 1.0048\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:41<00:00,  4.85s/it, loss=1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 1.0061 | Val Loss: 1.0007\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:50<00:00,  5.26s/it, loss=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 1.0016 | Val Loss: 0.9955\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.16s/it, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.9978 | Val Loss: 0.9935\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:45<00:00,  5.01s/it, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.9934 | Val Loss: 0.9890\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:44<00:00,  4.98s/it, loss=0.986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.9886 | Val Loss: 0.9833\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:45<00:00,  5.00s/it, loss=0.99] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.9861 | Val Loss: 0.9806\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.18s/it, loss=0.99] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.9836 | Val Loss: 0.9795\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:49<00:00,  5.23s/it, loss=0.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.9804 | Val Loss: 0.9757\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.16s/it, loss=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.9790 | Val Loss: 0.9752\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:49<00:00,  5.20s/it, loss=0.975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.9766 | Val Loss: 0.9739\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:46<00:00,  5.06s/it, loss=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.9746 | Val Loss: 0.9723\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:45<00:00,  5.04s/it, loss=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.9738 | Val Loss: 0.9679\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:47<00:00,  5.14s/it, loss=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.9727 | Val Loss: 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.17s/it, loss=0.971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.9720 | Val Loss: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.15s/it, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.9693 | Val Loss: 0.9669\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:52<00:00,  5.37s/it, loss=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.9694 | Val Loss: 0.9652\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:47<00:00,  5.12s/it, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.9691 | Val Loss: 0.9649\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.16s/it, loss=0.965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.9691 | Val Loss: 0.9661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:51<00:00,  5.32s/it, loss=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.9676 | Val Loss: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:51<00:00,  5.30s/it, loss=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.9667 | Val Loss: 0.9639\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:46<00:00,  5.06s/it, loss=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.9669 | Val Loss: 0.9641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:47<00:00,  5.14s/it, loss=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.9670 | Val Loss: 0.9634\n",
      "ðŸŽ‰ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:47<00:00,  5.12s/it, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.9670 | Val Loss: 0.9653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:47<00:00,  5.13s/it, loss=0.965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.9661 | Val Loss: 0.9644\n",
      "\n",
      "=== Generating Test Predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [04:37<00:00,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission.csv\n",
      "\n",
      "=== Evaluating on Validation Set ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:   2%|â–         | 1/42 [00:00<00:36,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide31: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:   5%|â–         | 2/42 [00:01<00:36,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide172: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:   7%|â–‹         | 3/42 [00:02<00:35,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide85: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  10%|â–‰         | 4/42 [00:03<00:34,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide199: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  12%|â–ˆâ–        | 5/42 [00:04<00:34,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide61: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  14%|â–ˆâ–        | 6/42 [00:05<00:32,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide156: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  17%|â–ˆâ–‹        | 7/42 [00:06<00:32,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide46: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  19%|â–ˆâ–‰        | 8/42 [00:07<00:31,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide182: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  21%|â–ˆâ–ˆâ–       | 9/42 [00:08<00:30,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide10: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  24%|â–ˆâ–ˆâ–       | 10/42 [00:09<00:29,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide196: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:10<00:28,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide137: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  29%|â–ˆâ–ˆâ–Š       | 12/42 [00:11<00:27,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide187: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  31%|â–ˆâ–ˆâ–ˆ       | 13/42 [00:11<00:27,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide207: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 14/42 [00:12<00:25,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide127: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:13<00:24,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide16: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 16/42 [00:14<00:23,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide74: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:15<00:22,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide166: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:16<00:22,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide19: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19/42 [00:17<00:21,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide168: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20/42 [00:18<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide94: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21/42 [00:19<00:19,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide76: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22/42 [00:20<00:18,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide56: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:21<00:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide148: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:22<00:16,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide110: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:22<00:15,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide109: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26/42 [00:23<00:14,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide143: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/42 [00:24<00:13,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide26: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28/42 [00:25<00:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide126: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29/42 [00:26<00:11,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide17: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:27<00:11,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide173: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 31/42 [00:28<00:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide192: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 32/42 [00:29<00:09,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide70: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 33/42 [00:30<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide102: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 34/42 [00:31<00:07,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide68: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 35/42 [00:32<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide105: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 36/42 [00:32<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide133: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 37/42 [00:33<00:04,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide208: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38/42 [00:34<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide96: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 39/42 [00:35<00:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide83: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 40/42 [00:36<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide160: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 41/42 [00:37<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide197: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:38<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide163: wPQ = 1.0000, Class PQs = ['1.0000', '1.0000', '1.0000', '1.0000']\n",
      "\n",
      "=== Mean Validation wPQ: 1.0000 ===\n",
      "\n",
      " 1. slide31: 1.0000\n",
      " 2. slide172: 1.0000\n",
      " 3. slide85: 1.0000\n",
      " 4. slide199: 1.0000\n",
      " 5. slide61: 1.0000\n",
      " 6. slide156: 1.0000\n",
      " 7. slide46: 1.0000\n",
      " 8. slide182: 1.0000\n",
      " 9. slide10: 1.0000\n",
      "10. slide196: 1.0000\n",
      "11. slide137: 1.0000\n",
      "12. slide187: 1.0000\n",
      "13. slide207: 1.0000\n",
      "14. slide127: 1.0000\n",
      "15. slide16: 1.0000\n",
      "16. slide74: 1.0000\n",
      "17. slide166: 1.0000\n",
      "18. slide19: 1.0000\n",
      "19. slide168: 1.0000\n",
      "20. slide94: 1.0000\n",
      "21. slide76: 1.0000\n",
      "22. slide56: 1.0000\n",
      "23. slide148: 1.0000\n",
      "24. slide110: 1.0000\n",
      "25. slide109: 1.0000\n",
      "26. slide143: 1.0000\n",
      "27. slide26: 1.0000\n",
      "28. slide126: 1.0000\n",
      "29. slide17: 1.0000\n",
      "30. slide173: 1.0000\n",
      "31. slide192: 1.0000\n",
      "32. slide70: 1.0000\n",
      "33. slide102: 1.0000\n",
      "34. slide68: 1.0000\n",
      "35. slide105: 1.0000\n",
      "36. slide133: 1.0000\n",
      "37. slide208: 1.0000\n",
      "38. slide96: 1.0000\n",
      "39. slide83: 1.0000\n",
      "40. slide160: 1.0000\n",
      "41. slide197: 1.0000\n",
      "42. slide163: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation error: 'Epithelial'\n",
      "\n",
      "=== Pipeline Complete ===\n",
      "Check 'submission.csv' for final predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from scipy.ndimage import distance_transform_edt, label as scipy_label\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== Configuration ====================\n",
    "class Config:\n",
    "    # Paths\n",
    "    train_dir = \"kaggle-data/train\"\n",
    "    test_dir = \"kaggle-data/test_final\"\n",
    "    train_csv = \"kaggle-data/train_ground_truth.csv\"\n",
    "    \n",
    "    # Training\n",
    "    img_size = 256\n",
    "    batch_size = 8\n",
    "    num_epochs = 50\n",
    "    lr = 1e-4\n",
    "    device = \"cpu\"\n",
    "    num_workers = 0\n",
    "    # Device - optimized for macOS + multiprocessing\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     device = \"mps\"  # Apple Silicon GPU\n",
    "    #     num_workers = 0\n",
    "    # elif torch.cuda.is_available():\n",
    "    #     device = \"cuda\"  # NVIDIA GPU\n",
    "    #     num_workers = 4\n",
    "    # else:\n",
    "    #     device = \"cpu\"   # CPU fallback\n",
    "    #     num_workers = 2  # Reduced for CPU multiprocessing\n",
    "    \n",
    "    # Classes\n",
    "    classes = [\"Epithelial\", \"Lymphocyte\", \"Neutrophil\", \"Macrophage\"]\n",
    "    class_weights = [1.0, 1.0, 10.0, 10.0]  # For weighted loss\n",
    "    num_classes = 4\n",
    "    \n",
    "    # Inference\n",
    "    overlap = 0.5  # Sliding window overlap\n",
    "    min_nucleus_size = 20  # Minimum pixels for a valid nucleus\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# ==================== RLE Encoding/Decoding ====================\n",
    "def rle_encode_instance_mask(mask: np.ndarray) -> str:\n",
    "    \"\"\"Convert instance mask to RLE string\"\"\"\n",
    "    pixels = mask.flatten(order=\"F\").astype(np.int32)\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    \n",
    "    rle = []\n",
    "    for i in range(0, len(runs)-1):\n",
    "        start = runs[i]\n",
    "        end = runs[i+1] if i+1 < len(runs) else len(pixels)-1\n",
    "        length = end - start\n",
    "        val = pixels[start]\n",
    "        if val > 0:\n",
    "            rle.extend([val, start, length])\n",
    "    \n",
    "    return \"0\" if not rle else \" \".join(map(str, rle))\n",
    "\n",
    "def rle_decode_instance_mask(rle: str, shape: tuple) -> np.ndarray:\n",
    "    \"\"\"Convert RLE string to instance mask\"\"\"\n",
    "    if not rle or str(rle).strip() in (\"\", \"0\", \"nan\"):\n",
    "        return np.zeros(shape, dtype=np.uint16)\n",
    "    \n",
    "    s = list(map(int, rle.split()))\n",
    "    mask = np.zeros(shape[0]*shape[1], dtype=np.uint16)\n",
    "    \n",
    "    for i in range(0, len(s), 3):\n",
    "        val, start, length = s[i], s[i+1], s[i+2]\n",
    "        mask[start-1:start-1+length] = val\n",
    "    \n",
    "    return mask.reshape(shape, order=\"F\")\n",
    "\n",
    "# ==================== Data Loading ====================\n",
    "def parse_xml_annotations(xml_path):\n",
    "    \"\"\"Parse XML annotations to get polygons per class\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    annotations = {cls: [] for cls in config.classes}\n",
    "    \n",
    "    for annotation in root.findall('.//Annotation'):\n",
    "        class_name = annotation.get('Name')\n",
    "        if class_name not in config.classes:\n",
    "            continue\n",
    "        \n",
    "        for region in annotation.findall('.//Region'):\n",
    "            vertices = []\n",
    "            for vertex in region.findall('.//Vertex'):\n",
    "                x = float(vertex.get('X'))\n",
    "                y = float(vertex.get('Y'))\n",
    "                vertices.append([x, y])\n",
    "            \n",
    "            if len(vertices) >= 3:\n",
    "                annotations[class_name].append(np.array(vertices, dtype=np.int32))\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def create_masks_from_annotations(annotations, img_shape):\n",
    "    \"\"\"Create instance and semantic masks from annotations\"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    \n",
    "    # Instance masks per class\n",
    "    instance_masks = {cls: np.zeros((h, w), dtype=np.uint16) for cls in config.classes}\n",
    "    \n",
    "    # Semantic mask (0=bg, 1-4=classes)\n",
    "    semantic_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for cls_idx, cls_name in enumerate(config.classes, start=1):\n",
    "        instance_id = 1\n",
    "        for polygon in annotations[cls_name]:\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [polygon], 1)\n",
    "            \n",
    "            # Add to instance mask\n",
    "            instance_masks[cls_name][mask > 0] = instance_id\n",
    "            instance_id += 1\n",
    "            \n",
    "            # Add to semantic mask\n",
    "            semantic_mask[mask > 0] = cls_idx\n",
    "    \n",
    "    return instance_masks, semantic_mask\n",
    "\n",
    "# ==================== Dataset ====================\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['image_id']\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.tif\")\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.is_train:\n",
    "            # Load masks from XML\n",
    "            xml_path = os.path.join(self.img_dir, f\"{img_id}.xml\")\n",
    "            annotations = parse_xml_annotations(xml_path)\n",
    "            instance_masks, semantic_mask = create_masks_from_annotations(annotations, image.shape)\n",
    "            \n",
    "            # Create boundary map (for instance separation)\n",
    "            boundary = self.create_boundary_map(semantic_mask, instance_masks)\n",
    "            \n",
    "            if self.transform:\n",
    "                # Augment - ensure we resize all components\n",
    "                transformed = self.transform(\n",
    "                    image=image,\n",
    "                    masks=[semantic_mask, boundary]\n",
    "                )\n",
    "                image = transformed['image']\n",
    "                semantic_mask = transformed['masks'][0]\n",
    "                boundary = transformed['masks'][1]\n",
    "            else:\n",
    "                # Apply resize even if no other transforms\n",
    "                resize_transform = A.Resize(config.img_size, config.img_size)\n",
    "                transformed = resize_transform(\n",
    "                    image=image,\n",
    "                    masks=[semantic_mask, boundary]\n",
    "                )\n",
    "                image = transformed['image']\n",
    "                semantic_mask = transformed['masks'][0]\n",
    "                boundary = transformed['masks'][1]\n",
    "            \n",
    "            # Convert to tensors\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            semantic_mask = torch.from_numpy(semantic_mask).long()\n",
    "            boundary = torch.from_numpy(boundary).float().unsqueeze(0)\n",
    "            \n",
    "            return {\n",
    "                'image': image,\n",
    "                'semantic_mask': semantic_mask,\n",
    "                'boundary': boundary,\n",
    "                'img_id': img_id\n",
    "            }\n",
    "        else:\n",
    "            # Test mode\n",
    "            original_shape = image.shape[:2]\n",
    "            \n",
    "            # Always apply resize for test images\n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=image)\n",
    "                image = transformed['image']\n",
    "            else:\n",
    "                resize_transform = A.Resize(config.img_size, config.img_size)\n",
    "                transformed = resize_transform(image=image)\n",
    "                image = transformed['image']\n",
    "            \n",
    "            image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            \n",
    "            return {\n",
    "                'image': image_tensor,\n",
    "                'img_id': img_id,\n",
    "                'original_shape': original_shape\n",
    "            }\n",
    "    \n",
    "    def create_boundary_map(self, semantic_mask, instance_masks):\n",
    "        \"\"\"Create boundary map for instance separation\"\"\"\n",
    "        boundary = np.zeros_like(semantic_mask, dtype=np.float32)\n",
    "        \n",
    "        for cls_name in config.classes:\n",
    "            inst_mask = instance_masks[cls_name]\n",
    "            if inst_mask.max() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Find boundaries between instances\n",
    "            for inst_id in range(1, inst_mask.max() + 1):\n",
    "                mask = (inst_mask == inst_id).astype(np.uint8)\n",
    "                if mask.sum() < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Erode to find boundary\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                eroded = cv2.erode(mask, kernel, iterations=1)\n",
    "                boundary_pixels = mask - eroded\n",
    "                boundary[boundary_pixels > 0] = 1.0\n",
    "        \n",
    "        return boundary\n",
    "\n",
    "# ==================== Model Architecture ====================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UNetWithBoundary(nn.Module):\n",
    "    \"\"\"U-Net style model with multi-task heads\"\"\"\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(3, 64)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = ConvBlock(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(128, 64)\n",
    "        \n",
    "        # Multi-task heads\n",
    "        self.semantic_head = nn.Conv2d(64, num_classes + 1, 1)  # +1 for background\n",
    "        self.boundary_head = nn.Conv2d(64, 1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        \n",
    "        # Multi-task outputs\n",
    "        semantic = self.semantic_head(d1)\n",
    "        boundary = torch.sigmoid(self.boundary_head(d1))\n",
    "        \n",
    "        return semantic, boundary\n",
    "\n",
    "# ==================== Loss Functions ====================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        # Ensure alpha is on the same device as inputs\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "        \n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, inputs, targets, smooth=1.0):\n",
    "        inputs = F.softmax(inputs, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        intersection = (inputs * targets_one_hot).sum(dim=(2, 3))\n",
    "        union = inputs.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, class_weights, device):\n",
    "        super().__init__()\n",
    "        # Move weights to the specified device\n",
    "        weights = torch.tensor(class_weights + [1.0], dtype=torch.float32).to(device)  # +1 for background\n",
    "        self.focal = FocalLoss(alpha=weights, gamma=2.0)\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, semantic_pred, boundary_pred, semantic_gt, boundary_gt):\n",
    "        # Semantic loss\n",
    "        semantic_loss = self.focal(semantic_pred, semantic_gt) + self.dice(semantic_pred, semantic_gt)\n",
    "        \n",
    "        # Boundary loss\n",
    "        boundary_loss = self.bce(boundary_pred, boundary_gt)\n",
    "        \n",
    "        return semantic_loss + 0.5 * boundary_loss\n",
    "\n",
    "# ==================== Training ====================\n",
    "def get_transforms(is_train=True):\n",
    "    if is_train:\n",
    "        return A.Compose([\n",
    "            A.Resize(config.img_size, config.img_size, always_apply=True),  # Always apply resize\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "            A.GaussNoise(p=0.3),\n",
    "            A.GaussianBlur(p=0.3),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(config.img_size, config.img_size, always_apply=True),  # Always apply resize for val/test\n",
    "        ])\n",
    "\n",
    "def train_model():\n",
    "   # Load data\n",
    "    df = pd.read_csv(config.train_csv)\n",
    "    \n",
    "    # Split train/val\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Datasets - CRITICAL: both need transforms for resizing\n",
    "    train_dataset = CellDataset(train_df, config.train_dir, transform=get_transforms(True), is_train=True)\n",
    "    val_dataset = CellDataset(val_df, config.train_dir, transform=get_transforms(False), is_train=True)  # This line was missing transform!\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Model\n",
    "    model = UNetWithBoundary(num_classes=config.num_classes).to(config.device)\n",
    "    \n",
    "    # Loss and optimizer - pass device to criterion\n",
    "    criterion = CombinedLoss(config.class_weights, config.device).to(config.device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs} [Train]\")\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(config.device)\n",
    "            semantic_gt = batch['semantic_mask'].to(config.device)\n",
    "            boundary_gt = batch['boundary'].to(config.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            semantic_pred, boundary_pred = model(images)\n",
    "            loss = criterion(semantic_pred, boundary_pred, semantic_gt, boundary_gt)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(config.device)\n",
    "                semantic_gt = batch['semantic_mask'].to(config.device)\n",
    "                boundary_gt = batch['boundary'].to(config.device)\n",
    "                \n",
    "                semantic_pred, boundary_pred = model(images)\n",
    "                loss = criterion(semantic_pred, boundary_pred, semantic_gt, boundary_gt)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"ðŸŽ‰ New best model saved!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==================== Inference & Post-processing ====================\n",
    "def watershed_instance_separation(semantic_pred, boundary_pred, class_id):\n",
    "    \"\"\"Separate touching nuclei using watershed\"\"\"\n",
    "    # Get mask for this class\n",
    "    class_mask = (semantic_pred == class_id).astype(np.uint8)\n",
    "    \n",
    "    if class_mask.sum() < config.min_nucleus_size:\n",
    "        return np.zeros_like(class_mask, dtype=np.uint16)\n",
    "    \n",
    "    # Remove boundary regions\n",
    "    class_mask = class_mask * (1 - boundary_pred)\n",
    "    class_mask = (class_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Distance transform\n",
    "    dist = distance_transform_edt(class_mask)\n",
    "    \n",
    "    # Find local maxima as seeds\n",
    "    coords = peak_local_max(dist, min_distance=5, labels=class_mask)\n",
    "    \n",
    "    if len(coords) == 0:\n",
    "        return np.zeros_like(class_mask, dtype=np.uint16)\n",
    "    \n",
    "    # Create markers\n",
    "    markers = np.zeros_like(class_mask, dtype=np.int32)\n",
    "    for i, coord in enumerate(coords, start=1):\n",
    "        markers[coord[0], coord[1]] = i\n",
    "    \n",
    "    # Watershed\n",
    "    instance_mask = watershed(-dist, markers, mask=class_mask)\n",
    "    \n",
    "    # Remove small objects\n",
    "    for region in regionprops(instance_mask):\n",
    "        if region.area < config.min_nucleus_size:\n",
    "            instance_mask[instance_mask == region.label] = 0\n",
    "    \n",
    "    # Relabel\n",
    "    instance_mask = scipy_label(instance_mask > 0)[0]\n",
    "    \n",
    "    return instance_mask.astype(np.uint16)\n",
    "\n",
    "def predict_image(model, image, original_shape):\n",
    "    \"\"\"Sliding window prediction with overlap\"\"\"\n",
    "    h, w = original_shape\n",
    "    patch_size = config.img_size\n",
    "    stride = int(patch_size * (1 - config.overlap))\n",
    "    \n",
    "    # Initialize output\n",
    "    semantic_output = np.zeros((h, w), dtype=np.float32)\n",
    "    boundary_output = np.zeros((h, w), dtype=np.float32)\n",
    "    count_map = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for y in range(0, h, stride):\n",
    "            for x in range(0, w, stride):\n",
    "                # Extract patch\n",
    "                y1, y2 = y, min(y + patch_size, h)\n",
    "                x1, x2 = x, min(x + patch_size, w)\n",
    "                \n",
    "                patch = image[:, y1:y2, x1:x2].unsqueeze(0).to(config.device)\n",
    "                \n",
    "                # Pad if needed\n",
    "                if patch.shape[2] < patch_size or patch.shape[3] < patch_size:\n",
    "                    patch = F.pad(patch, (0, patch_size - patch.shape[3], 0, patch_size - patch.shape[2]))\n",
    "                \n",
    "                # Predict\n",
    "                semantic_pred, boundary_pred = model(patch)\n",
    "                \n",
    "                semantic_pred = F.softmax(semantic_pred, dim=1).cpu().numpy()[0]\n",
    "                boundary_pred = boundary_pred.cpu().numpy()[0, 0]\n",
    "                \n",
    "                # Crop to original patch size\n",
    "                semantic_pred = semantic_pred[:, :y2-y1, :x2-x1]\n",
    "                boundary_pred = boundary_pred[:y2-y1, :x2-x1]\n",
    "                \n",
    "                # Accumulate\n",
    "                semantic_class = np.argmax(semantic_pred, axis=0)\n",
    "                semantic_output[y1:y2, x1:x2] += semantic_class\n",
    "                boundary_output[y1:y2, x1:x2] += boundary_pred\n",
    "                count_map[y1:y2, x1:x2] += 1\n",
    "    \n",
    "    # Average\n",
    "    semantic_output = (semantic_output / (count_map + 1e-8)).astype(np.uint8)\n",
    "    boundary_output = (boundary_output / (count_map + 1e-8))\n",
    "    boundary_output = (boundary_output > 0.5).astype(np.uint8)\n",
    "    \n",
    "    return semantic_output, boundary_output\n",
    "\n",
    "def generate_predictions(model, test_df):\n",
    "    \"\"\"Generate predictions for all test images\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    test_dataset = CellDataset(test_df, config.test_dir, transform=None, is_train=False)\n",
    "    \n",
    "    for i in tqdm(range(len(test_dataset)), desc=\"Predicting\"):\n",
    "        sample = test_dataset[i]\n",
    "        image = sample['image']\n",
    "        img_id = sample['img_id']\n",
    "        original_shape = sample['original_shape']\n",
    "        \n",
    "        # Predict\n",
    "        semantic_pred, boundary_pred = predict_image(model, image, original_shape)\n",
    "        \n",
    "        # Separate instances for each class\n",
    "        instance_masks = {}\n",
    "        for cls_idx, cls_name in enumerate(config.classes, start=1):\n",
    "            instance_mask = watershed_instance_separation(semantic_pred, boundary_pred, cls_idx)\n",
    "            instance_masks[cls_name] = instance_mask\n",
    "        \n",
    "        # Encode to RLE\n",
    "        row = {'image_id': img_id}\n",
    "        for cls_name in config.classes:\n",
    "            rle = rle_encode_instance_mask(instance_masks[cls_name])\n",
    "            row[cls_name] = rle\n",
    "        \n",
    "        predictions.append(row)\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# ==================== Evaluation ====================\n",
    "def calculate_iou(pred_mask, gt_mask):\n",
    "    \"\"\"Calculate IoU between two masks\"\"\"\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def calculate_wpq(pred_instance_masks, gt_instance_masks):\n",
    "    \"\"\"Calculate weighted Panoptic Quality\"\"\"\n",
    "    class_pqs = []\n",
    "    \n",
    "    for cls_idx, cls_name in enumerate(config.classes):\n",
    "        pred_mask = pred_instance_masks[cls_name]\n",
    "        gt_mask = gt_instance_masks[cls_name]\n",
    "        \n",
    "        pred_ids = np.unique(pred_mask)[1:]  # Exclude background\n",
    "        gt_ids = np.unique(gt_mask)[1:]\n",
    "        \n",
    "        if len(gt_ids) == 0 and len(pred_ids) == 0:\n",
    "            pq = 1.0\n",
    "        elif len(gt_ids) == 0:\n",
    "            pq = 0.0\n",
    "        elif len(pred_ids) == 0:\n",
    "            pq = 0.0\n",
    "        else:\n",
    "            # Match predictions to ground truth\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            fn = len(gt_ids)\n",
    "            iou_sum = 0.0\n",
    "            \n",
    "            matched_gt = set()\n",
    "            \n",
    "            for pred_id in pred_ids:\n",
    "                pred_nucleus = (pred_mask == pred_id)\n",
    "                best_iou = 0.0\n",
    "                best_gt_id = None\n",
    "                \n",
    "                for gt_id in gt_ids:\n",
    "                    if gt_id in matched_gt:\n",
    "                        continue\n",
    "                    \n",
    "                    gt_nucleus = (gt_mask == gt_id)\n",
    "                    iou = calculate_iou(pred_nucleus, gt_nucleus)\n",
    "                    \n",
    "                    if iou > 0.5 and iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_id = gt_id\n",
    "                \n",
    "                if best_gt_id is not None:\n",
    "                    tp += 1\n",
    "                    fn -= 1\n",
    "                    iou_sum += best_iou\n",
    "                    matched_gt.add(best_gt_id)\n",
    "                else:\n",
    "                    fp += 1\n",
    "            \n",
    "            if tp == 0:\n",
    "                pq = 0.0\n",
    "            else:\n",
    "                sq = iou_sum / tp  # Segmentation Quality\n",
    "                rq = tp / (tp + 0.5 * fp + 0.5 * fn)  # Recognition Quality\n",
    "                pq = sq * rq\n",
    "        \n",
    "        class_pqs.append(pq)\n",
    "    \n",
    "    # Weighted average\n",
    "    weights = config.class_weights\n",
    "    wpq = sum(pq * w for pq, w in zip(class_pqs, weights)) / sum(weights)\n",
    "    \n",
    "    return wpq, class_pqs\n",
    "\n",
    "def evaluate_on_validation(model, val_df):\n",
    "    \"\"\"Evaluate model on validation data with ground truth\"\"\"\n",
    "    val_dataset = CellDataset(val_df, config.train_dir, transform=None, is_train=True)\n",
    "    \n",
    "    wpq_scores = []\n",
    "    \n",
    "    for i in tqdm(range(len(val_dataset)), desc=\"Evaluating Validation\"):\n",
    "        sample = val_dataset[i]\n",
    "        image = sample['image']\n",
    "        img_id = sample['img_id']\n",
    "        original_shape = image.shape[1:]  # For validation, we use the transformed shape\n",
    "        \n",
    "        # Get ground truth from the dataset\n",
    "        semantic_gt = sample['semantic_mask'].numpy()\n",
    "        \n",
    "        # Create ground truth instance masks from the dataset\n",
    "        # For validation evaluation, we need to reconstruct instance masks from the dataset\n",
    "        # Since we don't have the original XML during validation, we'll use a simplified approach\n",
    "        # by treating each connected component in the semantic mask as an instance\n",
    "        gt_instance_masks = {}\n",
    "        for cls_idx, cls_name in enumerate(config.classes, start=1):\n",
    "            class_mask = (semantic_gt == cls_idx).astype(np.uint8)\n",
    "            if class_mask.sum() > 0:\n",
    "                # Label connected components\n",
    "                labeled_mask, num_features = scipy_label(class_mask)\n",
    "                gt_instance_masks[cls_name] = labeled_mask.astype(np.uint16)\n",
    "            else:\n",
    "                gt_instance_masks[cls_name] = np.zeros_like(semantic_gt, dtype=np.uint16)\n",
    "        \n",
    "        # Predict using the model\n",
    "        semantic_pred, boundary_pred = predict_image(model, image, original_shape)\n",
    "        \n",
    "        # Get predicted instances\n",
    "        pred_instance_masks = {}\n",
    "        for cls_idx, cls_name in enumerate(config.classes, start=1):\n",
    "            instance_mask = watershed_instance_separation(semantic_pred, boundary_pred, cls_idx)\n",
    "            pred_instance_masks[cls_name] = instance_mask\n",
    "        \n",
    "        # Calculate wPQ\n",
    "        wpq, class_pqs = calculate_wpq(pred_instance_masks, gt_instance_masks)\n",
    "        wpq_scores.append(wpq)\n",
    "        \n",
    "        print(f\"{img_id}: wPQ = {wpq:.4f}, Class PQs = {[f'{pq:.4f}' for pq in class_pqs]}\")\n",
    "    \n",
    "    mean_wpq = np.mean(wpq_scores)\n",
    "    print(f\"\\n=== Mean Validation wPQ: {mean_wpq:.4f} ===\\n\")\n",
    "    \n",
    "    # Print detailed results\n",
    "    for i, (img_id, wpq) in enumerate(zip(val_df['image_id'].values, wpq_scores)):\n",
    "        print(f\"{i+1:2d}. {img_id}: {wpq:.4f}\")\n",
    "    \n",
    "    return mean_wpq\n",
    "\n",
    "def evaluate_on_test_data(model, test_df, gt_df):\n",
    "    \"\"\"Evaluate model on test data with ground truth\"\"\"\n",
    "    test_dataset = CellDataset(test_df, config.test_dir, transform=None, is_train=False)\n",
    "    \n",
    "    wpq_scores = []\n",
    "    \n",
    "    for i in tqdm(range(len(test_dataset)), desc=\"Evaluating\"):\n",
    "        sample = test_dataset[i]\n",
    "        image = sample['image']\n",
    "        img_id = sample['img_id']\n",
    "        original_shape = sample['original_shape']\n",
    "        \n",
    "        # Predict\n",
    "        semantic_pred, boundary_pred = predict_image(model, image, original_shape)\n",
    "        \n",
    "        # Get predicted instances\n",
    "        pred_instance_masks = {}\n",
    "        for cls_idx, cls_name in enumerate(config.classes, start=1):\n",
    "            instance_mask = watershed_instance_separation(semantic_pred, boundary_pred, cls_idx)\n",
    "            pred_instance_masks[cls_name] = instance_mask\n",
    "        \n",
    "        # Get ground truth instances\n",
    "        gt_row = gt_df[gt_df['image_id'] == img_id].iloc[0]\n",
    "        gt_instance_masks = {}\n",
    "        for cls_name in config.classes:\n",
    "            rle = gt_row[cls_name]\n",
    "            gt_instance_masks[cls_name] = rle_decode_instance_mask(rle, original_shape)\n",
    "        \n",
    "        # Calculate wPQ\n",
    "        wpq, class_pqs = calculate_wpq(pred_instance_masks, gt_instance_masks)\n",
    "        wpq_scores.append(wpq)\n",
    "        \n",
    "        print(f\"{img_id}: wPQ = {wpq:.4f}, Class PQs = {[f'{pq:.4f}' for pq in class_pqs]}\")\n",
    "    \n",
    "    mean_wpq = np.mean(wpq_scores)\n",
    "    print(f\"\\n=== Mean wPQ: {mean_wpq:.4f} ===\")\n",
    "    \n",
    "    return mean_wpq\n",
    "\n",
    "# ==================== Main ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Multiprocessing fix for macOS\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "    print(\"Starting Cell Segmentation & Classification Pipeline...\")\n",
    "    print(f\"Device: {config.device}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n=== Training Model ===\")\n",
    "    model = train_model()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    \n",
    "    # Generate test predictions\n",
    "    print(\"\\n=== Generating Test Predictions ===\")\n",
    "    test_files = [f.replace('.tif', '') for f in os.listdir(config.test_dir) if f.endswith('.tif')]\n",
    "    test_df = pd.DataFrame({'image_id': test_files})\n",
    "    \n",
    "    predictions_df = generate_predictions(model, test_df)\n",
    "    predictions_df.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission saved to submission.csv\")\n",
    "    \n",
    "    # Evaluate on validation set with ground truth\n",
    "    print(\"\\n=== Evaluating on Validation Set ===\")\n",
    "    try:\n",
    "        # Use validation set from training data\n",
    "        df = pd.read_csv(config.train_csv)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        _, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        mean_wpq_val = evaluate_on_validation(model, val_df)\n",
    "        # Evaluate on validation images\n",
    "        mean_wpq = evaluate_on_test_data(model, val_df, test_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== Pipeline Complete ===\")\n",
    "    print(\"Check 'submission.csv' for final predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
