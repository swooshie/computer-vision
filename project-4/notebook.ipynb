{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Silicon (MPS) detected. Using GPU acceleration.\n",
      "Data Split: 52784 Training, 13196 Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MODE: CONTINUING TRAINING ---\n",
      "--> Loading checkpoint 'best_model.pth'...\n",
      "--> Loaded. Resuming from Epoch 5 with Best Val Loss 1.9849\n",
      "Starting training loop from epoch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|██████████| 1650/1650 [08:07<00:00,  3.38it/s, trn_loss=2.35]\n",
      "Epoch 6 [Val]: 100%|██████████| 413/413 [01:25<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train Loss: 1.7624 | Val Loss: 1.9507 | LR: 0.001000\n",
      "--> SAVING BEST MODEL (Val Loss: 1.9507) to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100%|██████████| 1650/1650 [08:59<00:00,  3.06it/s, trn_loss=1.21] \n",
      "Epoch 7 [Val]: 100%|██████████| 413/413 [01:14<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train Loss: 1.5793 | Val Loss: 1.9149 | LR: 0.001000\n",
      "--> SAVING BEST MODEL (Val Loss: 1.9149) to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100%|██████████| 1650/1650 [07:45<00:00,  3.55it/s, trn_loss=1.83] \n",
      "Epoch 8 [Val]: 100%|██████████| 413/413 [01:24<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train Loss: 1.4067 | Val Loss: 1.9009 | LR: 0.001000\n",
      "--> SAVING BEST MODEL (Val Loss: 1.9009) to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 1650/1650 [07:51<00:00,  3.50it/s, trn_loss=0.792]\n",
      "Epoch 9 [Val]: 100%|██████████| 413/413 [01:25<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train Loss: 1.2440 | Val Loss: 2.0210 | LR: 0.001000\n",
      "Val Loss did not improve (Best: 1.9009).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 1650/1650 [07:55<00:00,  3.47it/s, trn_loss=1.71] \n",
      "Epoch 10 [Val]: 100%|██████████| 413/413 [01:25<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train Loss: 1.0691 | Val Loss: 2.1858 | LR: 0.001000\n",
      "Val Loss did not improve (Best: 1.9009).\n",
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0.65137\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & FLAGS\n",
    "# ==========================================\n",
    "# --- USER MODES (Set ONE to True) ---\n",
    "START_TRAINING    = False    # Start fresh, split data, train from scratch\n",
    "CONTINUE_TRAINING = True     # Load best_model.pth, use SAME split, resume training\n",
    "INFERENCE_ONLY    = False    # Load best_model.pth, predict on test_images\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = './data/kaggle_dataset'\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train_images')\n",
    "TEST_IMG_DIR = os.path.join(BASE_DIR, 'test_images')\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, 'train_ground_truth.csv')\n",
    "SAMPLE_SUB_CSV = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "MODEL_SAVE_PATH = 'best_model.pth'\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 5 \n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_WORKERS = 0  \n",
    "\n",
    "# --- DEVICE SETUP FOR M3 PRO ---\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Apple Silicon (MPS) detected. Using GPU acceleration.\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"CUDA GPU detected.\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"GPU not found. Using CPU (slower).\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATASET CLASS\n",
    "# ==========================================\n",
    "class GeoGuessrDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        sample_id = row['sample_id']\n",
    "        \n",
    "        # Load 4 images\n",
    "        directions = ['north', 'east', 'south', 'west']\n",
    "        images = []\n",
    "        for d in directions:\n",
    "            fname = f\"img_{sample_id:06d}_{d}.jpg\"\n",
    "            img_path = os.path.join(self.img_dir, fname)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "            except FileNotFoundError:\n",
    "                img = Image.new('RGB', (256, 256))\n",
    "            images.append(img)\n",
    "\n",
    "        # Stitch 2x2\n",
    "        w, h = images[0].size\n",
    "        stitched_img = Image.new('RGB', (w * 2, h * 2))\n",
    "        stitched_img.paste(images[0], (0, 0))      # North\n",
    "        stitched_img.paste(images[1], (w, 0))      # East\n",
    "        stitched_img.paste(images[3], (0, h))      # West\n",
    "        stitched_img.paste(images[2], (w, h))      # South\n",
    "\n",
    "        if self.transform:\n",
    "            stitched_img = self.transform(stitched_img)\n",
    "\n",
    "        if self.is_test:\n",
    "            return stitched_img, sample_id\n",
    "        else:\n",
    "            state_idx = int(row['state_idx'])\n",
    "            # Normalize GPS\n",
    "            lat_norm = row['latitude'] / 90.0\n",
    "            lon_norm = row['longitude'] / 180.0\n",
    "            gps_target = torch.tensor([lat_norm, lon_norm], dtype=torch.float32)\n",
    "            return stitched_img, state_idx, gps_target\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL DEFINITION\n",
    "# ==========================================\n",
    "class MultiTaskGeoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskGeoNet, self).__init__()\n",
    "        # ResNet18 is light and fast\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 50)\n",
    "        )\n",
    "        \n",
    "        self.gps_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        state_logits = self.cls_head(features)\n",
    "        gps_pred = self.gps_head(features)\n",
    "        return state_logits, gps_pred\n",
    "\n",
    "# ==========================================\n",
    "# 4. CHECKPOINT HELPERS\n",
    "# ==========================================\n",
    "def save_checkpoint(model, optimizer, scheduler, val_loss, epoch, filename):\n",
    "    print(f\"--> SAVING BEST MODEL (Val Loss: {val_loss:.4f}) to {filename}\")\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict(),\n",
    "        'best_val_loss': val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        print(f\"--> Loading checkpoint '{filename}'...\")\n",
    "        checkpoint = torch.load(filename, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        \n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        if scheduler and 'scheduler_state' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "            \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        print(f\"--> Loaded. Resuming from Epoch {start_epoch} with Best Val Loss {best_val_loss:.4f}\")\n",
    "        return start_epoch, best_val_loss\n",
    "    else:\n",
    "        print(f\"--> No checkpoint found at '{filename}'. Starting fresh.\")\n",
    "        return 0, float('inf')\n",
    "\n",
    "# ==========================================\n",
    "# 5. DATA SETUP\n",
    "# ==========================================\n",
    "if not INFERENCE_ONLY:\n",
    "    full_df = pd.read_csv(TRAIN_CSV)\n",
    "    train_df, val_df = train_test_split(full_df, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "    print(f\"Data Split: {len(train_df)} Training, {len(val_df)} Validation\")\n",
    "\n",
    "    train_dataset = GeoGuessrDataset(train_df, TRAIN_IMG_DIR, transform=transform)\n",
    "    val_dataset = GeoGuessrDataset(val_df, TRAIN_IMG_DIR, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                              num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                            num_workers=NUM_WORKERS)\n",
    "\n",
    "# ==========================================\n",
    "# 6. INIT & MODE SELECTION\n",
    "# ==========================================\n",
    "model = MultiTaskGeoNet().to(DEVICE)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_gps = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "current_best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "if START_TRAINING:\n",
    "    print(\"--- MODE: STARTING FRESH TRAINING ---\")\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        os.remove(MODEL_SAVE_PATH)\n",
    "\n",
    "elif CONTINUE_TRAINING:\n",
    "    print(\"--- MODE: CONTINUING TRAINING ---\")\n",
    "    start_epoch, current_best_val_loss = load_checkpoint(model, optimizer, scheduler, MODEL_SAVE_PATH)\n",
    "\n",
    "elif INFERENCE_ONLY:\n",
    "    print(\"--- MODE: INFERENCE ONLY ---\")\n",
    "    load_checkpoint(model, None, None, MODEL_SAVE_PATH)\n",
    "\n",
    "# ==========================================\n",
    "# 7. TRAINING LOOP\n",
    "# ==========================================\n",
    "if not INFERENCE_ONLY:\n",
    "    print(f\"Starting training loop from epoch {start_epoch+1}...\")\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + EPOCHS):\n",
    "        # --- TRAIN ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "        \n",
    "        for images, states, gps_targets in progress_bar:\n",
    "            images, states, gps_targets = images.to(DEVICE), states.to(DEVICE), gps_targets.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            state_logits, gps_pred = model(images)\n",
    "            \n",
    "            loss_cls = criterion_cls(state_logits, states)\n",
    "            loss_gps = criterion_gps(gps_pred, gps_targets)\n",
    "            loss = loss_cls + (10.0 * loss_gps)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'trn_loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # --- VALIDATE ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, states, gps_targets in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "                images, states, gps_targets = images.to(DEVICE), states.to(DEVICE), gps_targets.to(DEVICE)\n",
    "                \n",
    "                state_logits, gps_pred = model(images)\n",
    "                loss_cls = criterion_cls(state_logits, states)\n",
    "                loss_gps = criterion_gps(gps_pred, gps_targets)\n",
    "                loss = loss_cls + (10.0 * loss_gps)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {current_lr:.6f}\")\n",
    "\n",
    "        # Update Scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Save Best Model\n",
    "        if avg_val_loss < current_best_val_loss:\n",
    "            current_best_val_loss = avg_val_loss\n",
    "            save_checkpoint(model, optimizer, scheduler, current_best_val_loss, epoch, MODEL_SAVE_PATH)\n",
    "        else:\n",
    "            print(f\"Val Loss did not improve (Best: {current_best_val_loss:.4f}).\")\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "\n",
    "# ==========================================\n",
    "# 8. SUBMISSION GENERATOR\n",
    "# ==========================================\n",
    "if INFERENCE_ONLY:\n",
    "    print(\"\\nGenerating submission using the BEST saved model...\")\n",
    "    sub_df = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "    test_dataset = GeoGuessrDataset(sub_df, TEST_IMG_DIR, transform=transform, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                             num_workers=NUM_WORKERS)\n",
    "\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, sample_ids in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(DEVICE)\n",
    "            state_logits, gps_pred = model(images)\n",
    "            \n",
    "            top5_indices = torch.argsort(state_logits, dim=1, descending=True)[:, :5]\n",
    "            pred_lat = gps_pred[:, 0] * 90.0\n",
    "            pred_lon = gps_pred[:, 1] * 180.0\n",
    "            \n",
    "            for i in range(len(sample_ids)):\n",
    "                sid = sample_ids[i].item()\n",
    "                states = top5_indices[i].cpu().numpy()\n",
    "                lat = float(pred_lat[i].cpu().item())\n",
    "                lon = float(pred_lon[i].cpu().item())\n",
    "                \n",
    "                lat = max(min(lat, 90), -90)\n",
    "                lon = max(min(lon, 180), -180)\n",
    "                \n",
    "                entry = {\n",
    "                    'sample_id': sid,\n",
    "                    'predicted_state_idx_1': states[0],\n",
    "                    'predicted_state_idx_2': states[1],\n",
    "                    'predicted_state_idx_3': states[2],\n",
    "                    'predicted_state_idx_4': states[3],\n",
    "                    'predicted_state_idx_5': states[4],\n",
    "                    'predicted_latitude': lat,\n",
    "                    'predicted_longitude': lon\n",
    "                }\n",
    "                results.append(entry)\n",
    "\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    template_df = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "    final_df = template_df.copy()\n",
    "\n",
    "    for idx, row in submission_df.iterrows():\n",
    "        mask = final_df['sample_id'] == row['sample_id']\n",
    "        final_df.loc[mask, 'predicted_state_idx_1'] = row['predicted_state_idx_1']\n",
    "        final_df.loc[mask, 'predicted_state_idx_2'] = row['predicted_state_idx_2']\n",
    "        final_df.loc[mask, 'predicted_state_idx_3'] = row['predicted_state_idx_3']\n",
    "        final_df.loc[mask, 'predicted_state_idx_4'] = row['predicted_state_idx_4']\n",
    "        final_df.loc[mask, 'predicted_state_idx_5'] = row['predicted_state_idx_5']\n",
    "        final_df.loc[mask, 'predicted_latitude'] = row['predicted_latitude']\n",
    "        final_df.loc[mask, 'predicted_longitude'] = row['predicted_longitude']\n",
    "\n",
    "    final_df.to_csv('submission.csv', index=False)\n",
    "    print(f\"Submission saved to 'submission.csv' with {len(final_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba7124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Silicon (MPS) detected. Using GPU acceleration.\n",
      "Data Split: 52784 Training, 13196 Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MODE: CONTINUING TRAINING ---\n",
      "--> Loading checkpoint 'best_model_2.pth'...\n",
      "Starting training loop from epoch 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 1650/1650 [08:32<00:00,  3.22it/s, loss=4.64]\n",
      "Epoch 9 [Val]: 100%|██████████| 413/413 [01:04<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train Loss: 3.6865 | Val Loss: 4.9491\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 1650/1650 [08:04<00:00,  3.40it/s, loss=4.47]\n",
      "Epoch 10 [Val]: 100%|██████████| 413/413 [01:02<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train Loss: 3.4444 | Val Loss: 5.0725\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100%|██████████| 1650/1650 [08:19<00:00,  3.30it/s, loss=3.21]\n",
      "Epoch 11 [Val]: 100%|██████████| 413/413 [01:23<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Train Loss: 3.2074 | Val Loss: 5.0177\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100%|██████████| 1650/1650 [08:14<00:00,  3.33it/s, loss=4.38]\n",
      "Epoch 12 [Val]: 100%|██████████| 413/413 [01:22<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Train Loss: 2.6384 | Val Loss: 5.0589\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100%|██████████| 1650/1650 [08:23<00:00,  3.28it/s, loss=2.53]\n",
      "Epoch 13 [Val]: 100%|██████████| 413/413 [01:19<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Train Loss: 2.3351 | Val Loss: 5.5350\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100%|██████████| 1650/1650 [08:13<00:00,  3.34it/s, loss=2.73]\n",
      "Epoch 14 [Val]: 100%|██████████| 413/413 [01:17<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Train Loss: 2.1336 | Val Loss: 5.8574\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100%|██████████| 1650/1650 [08:10<00:00,  3.37it/s, loss=1.56]\n",
      "Epoch 15 [Val]: 100%|██████████| 413/413 [01:11<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: Train Loss: 1.8389 | Val Loss: 6.1133\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100%|██████████| 1650/1650 [08:24<00:00,  3.27it/s, loss=2.7]  \n",
      "Epoch 16 [Val]: 100%|██████████| 413/413 [01:10<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: Train Loss: 1.6452 | Val Loss: 6.7881\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100%|██████████| 1650/1650 [08:19<00:00,  3.30it/s, loss=1.81] \n",
      "Epoch 17 [Val]: 100%|██████████| 413/413 [01:24<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: Train Loss: 1.5271 | Val Loss: 7.0991\n",
      "Val Loss did not improve (Best: 4.6096).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100%|██████████| 1650/1650 [08:11<00:00,  3.35it/s, loss=1.78] \n",
      "Epoch 18 [Val]: 100%|██████████| 413/413 [01:24<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: Train Loss: 1.3927 | Val Loss: 7.5259\n",
      "Val Loss did not improve (Best: 4.6096).\n",
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & FLAGS\n",
    "# ==========================================\n",
    "# --- USER MODES ---\n",
    "START_TRAINING    = False   \n",
    "CONTINUE_TRAINING = True    \n",
    "INFERENCE_ONLY    = False   \n",
    "\n",
    "# Paths\n",
    "BASE_DIR = './data/kaggle_dataset'\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train_images')\n",
    "TEST_IMG_DIR = os.path.join(BASE_DIR, 'test_images')\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, 'train_ground_truth.csv')\n",
    "SAMPLE_SUB_CSV = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "MODEL_SAVE_PATH = 'best_model_2.pth'\n",
    "\n",
    "# Hyperparameters & Grid Config\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.00005 # Lower LR for deeper heads\n",
    "EPOCHS = 10\n",
    "VALIDATION_SPLIT = 0.2\n",
    "GRID_SIZE = 25  # 25x25 grid = 625 distinct regions (Classes)\n",
    "\n",
    "# M3 Pro Settings\n",
    "NUM_WORKERS = 0 \n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Apple Silicon (MPS) detected. Using GPU acceleration.\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. GRID SYSTEM HELPER\n",
    "# ==========================================\n",
    "class GridSystem:\n",
    "    \"\"\"\n",
    "    Divides the map into a grid of tiles (cells) based on the paper's approach.\n",
    "    Converts Lat/Lon <-> Class Index.\n",
    "    \"\"\"\n",
    "    def __init__(self, df=None, grid_size=25):\n",
    "        self.grid_size = grid_size\n",
    "        if df is not None:\n",
    "            # Determine bounds from training data\n",
    "            self.min_lat = df['latitude'].min()\n",
    "            self.max_lat = df['latitude'].max()\n",
    "            self.min_lon = df['longitude'].min()\n",
    "            self.max_lon = df['longitude'].max()\n",
    "            # Add small buffer to avoid edge cases\n",
    "            self.lat_step = (self.max_lat - self.min_lat + 1e-5) / grid_size\n",
    "            self.lon_step = (self.max_lon - self.min_lon + 1e-5) / grid_size\n",
    "            \n",
    "    def save_state(self):\n",
    "        return {\n",
    "            'bounds': (self.min_lat, self.max_lat, self.min_lon, self.max_lon),\n",
    "            'steps': (self.lat_step, self.lon_step),\n",
    "            'grid_size': self.grid_size\n",
    "        }\n",
    "    \n",
    "    def load_state(self, state):\n",
    "        self.min_lat, self.max_lat, self.min_lon, self.max_lon = state['bounds']\n",
    "        self.lat_step, self.lon_step = state['steps']\n",
    "        self.grid_size = state['grid_size']\n",
    "\n",
    "    def coords_to_grid(self, lat, lon):\n",
    "        # Calculate row and col\n",
    "        row = int((lat - self.min_lat) / self.lat_step)\n",
    "        col = int((lon - self.min_lon) / self.lon_step)\n",
    "        # Clip to ensure validity\n",
    "        row = max(0, min(row, self.grid_size - 1))\n",
    "        col = max(0, min(col, self.grid_size - 1))\n",
    "        # Convert 2D -> 1D class index\n",
    "        return row * self.grid_size + col\n",
    "\n",
    "    def grid_to_coords(self, grid_idx):\n",
    "        # Convert 1D -> 2D\n",
    "        row = grid_idx // self.grid_size\n",
    "        col = grid_idx % self.grid_size\n",
    "        # Return center of the tile\n",
    "        center_lat = self.min_lat + (row + 0.5) * self.lat_step\n",
    "        center_lon = self.min_lon + (col + 0.5) * self.lon_step\n",
    "        return center_lat, center_lon\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATASET CLASS\n",
    "# ==========================================\n",
    "class GeoGuessrDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, grid_system, transform=None, is_test=False):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.grid_system = grid_system\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        sample_id = row['sample_id']\n",
    "        \n",
    "        # Load 4 images and stitch\n",
    "        directions = ['north', 'east', 'south', 'west']\n",
    "        images = []\n",
    "        for d in directions:\n",
    "            fname = f\"img_{sample_id:06d}_{d}.jpg\"\n",
    "            img_path = os.path.join(self.img_dir, fname)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "            except FileNotFoundError:\n",
    "                img = Image.new('RGB', (256, 256))\n",
    "            images.append(img)\n",
    "\n",
    "        # 2x2 Stitch\n",
    "        w, h = images[0].size\n",
    "        stitched_img = Image.new('RGB', (w * 2, h * 2))\n",
    "        stitched_img.paste(images[0], (0, 0))\n",
    "        stitched_img.paste(images[1], (w, 0))\n",
    "        stitched_img.paste(images[3], (0, h))\n",
    "        stitched_img.paste(images[2], (w, h))\n",
    "\n",
    "        if self.transform:\n",
    "            stitched_img = self.transform(stitched_img)\n",
    "\n",
    "        if self.is_test:\n",
    "            return stitched_img, sample_id\n",
    "        else:\n",
    "            state_idx = int(row['state_idx'])\n",
    "            # Convert Lat/Lon to Grid Class ID\n",
    "            lat, lon = row['latitude'], row['longitude']\n",
    "            grid_label = self.grid_system.coords_to_grid(lat, lon)\n",
    "            \n",
    "            return stitched_img, state_idx, grid_label\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL DEFINITION (Improved Heads)\n",
    "# ==========================================\n",
    "class DeepGeoNet(nn.Module):\n",
    "    def __init__(self, num_grid_classes):\n",
    "        super(DeepGeoNet, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Improved Head Structure from Paper: \n",
    "        # Dense(1024) -> Drop -> Dense(512) -> Drop -> Dense(100) -> Drop -> Output\n",
    "        \n",
    "        # Head 1: State Classification\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 50) # 50 States\n",
    "        )\n",
    "        \n",
    "        # Head 2: Grid Classification (Paper's preferred method)\n",
    "        self.grid_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, num_grid_classes) # e.g. 625 tiles\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        state_logits = self.cls_head(features)\n",
    "        grid_logits = self.grid_head(features)\n",
    "        return state_logits, grid_logits\n",
    "\n",
    "# ==========================================\n",
    "# 5. CHECKPOINT HELPERS\n",
    "# ==========================================\n",
    "def save_checkpoint(model, optimizer, scheduler, grid_system, val_loss, epoch, filename):\n",
    "    print(f\"--> SAVING BEST MODEL (Val Loss: {val_loss:.4f}) to {filename}\")\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict(),\n",
    "        'grid_system_state': grid_system.save_state(), # Save grid definitions\n",
    "        'best_val_loss': val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, grid_system, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        print(f\"--> Loading checkpoint '{filename}'...\")\n",
    "        \n",
    "        # Added weights_only=False to allow loading the grid system and numpy values\n",
    "        checkpoint = torch.load(filename, map_location=DEVICE, weights_only=False)\n",
    "        \n",
    "        # Load Grid System first to ensure model matches\n",
    "        if 'grid_system_state' in checkpoint:\n",
    "            grid_system.load_state(checkpoint['grid_system_state'])\n",
    "            \n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        \n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        if scheduler and 'scheduler_state' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "            \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        return start_epoch, best_val_loss\n",
    "    else:\n",
    "        print(f\"--> No checkpoint found at '{filename}'. Starting fresh.\")\n",
    "        return 0, float('inf')\n",
    "\n",
    "# ==========================================\n",
    "# 6. SETUP & DATA PREP\n",
    "# ==========================================\n",
    "grid_system = GridSystem(grid_size=GRID_SIZE)\n",
    "\n",
    "if not INFERENCE_ONLY:\n",
    "    full_df = pd.read_csv(TRAIN_CSV)\n",
    "    \n",
    "    # Initialize Grid System with ALL training data\n",
    "    grid_system = GridSystem(full_df, grid_size=GRID_SIZE)\n",
    "    \n",
    "    train_df, val_df = train_test_split(full_df, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "    print(f\"Data Split: {len(train_df)} Training, {len(val_df)} Validation\")\n",
    "\n",
    "    train_dataset = GeoGuessrDataset(train_df, TRAIN_IMG_DIR, grid_system, transform=transform)\n",
    "    val_dataset = GeoGuessrDataset(val_df, TRAIN_IMG_DIR, grid_system, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ==========================================\n",
    "# 7. INITIALIZATION\n",
    "# ==========================================\n",
    "num_grid_classes = GRID_SIZE * GRID_SIZE\n",
    "model = DeepGeoNet(num_grid_classes=num_grid_classes).to(DEVICE)\n",
    "\n",
    "# Both tasks are now Classification (CrossEntropy)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_grid = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "current_best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "if START_TRAINING:\n",
    "    print(\"--- MODE: STARTING FRESH TRAINING ---\")\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        os.remove(MODEL_SAVE_PATH)\n",
    "\n",
    "elif CONTINUE_TRAINING:\n",
    "    print(\"--- MODE: CONTINUING TRAINING ---\")\n",
    "    start_epoch, current_best_val_loss = load_checkpoint(model, optimizer, scheduler, grid_system, MODEL_SAVE_PATH)\n",
    "\n",
    "elif INFERENCE_ONLY:\n",
    "    print(\"--- MODE: INFERENCE ONLY ---\")\n",
    "    # We must load the grid system state to know how to decode the predictions\n",
    "    load_checkpoint(model, None, None, grid_system, MODEL_SAVE_PATH)\n",
    "\n",
    "# ==========================================\n",
    "# 8. TRAINING LOOP\n",
    "# ==========================================\n",
    "if not INFERENCE_ONLY:\n",
    "    print(f\"Starting training loop from epoch {start_epoch+1}...\")\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + EPOCHS):\n",
    "        # --- TRAIN ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "        \n",
    "        for images, states, grid_targets in progress_bar:\n",
    "            images, states, grid_targets = images.to(DEVICE), states.to(DEVICE), grid_targets.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            state_logits, grid_logits = model(images)\n",
    "            \n",
    "            # Loss: State Classification + Grid Classification\n",
    "            loss_cls = criterion_cls(state_logits, states)\n",
    "            loss_grid = criterion_grid(grid_logits, grid_targets)\n",
    "            \n",
    "            # Balance the two classification tasks\n",
    "            loss = loss_cls + loss_grid \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # --- VALIDATE ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, states, grid_targets in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "                images, states, grid_targets = images.to(DEVICE), states.to(DEVICE), grid_targets.to(DEVICE)\n",
    "                \n",
    "                state_logits, grid_logits = model(images)\n",
    "                \n",
    "                loss_cls = criterion_cls(state_logits, states)\n",
    "                loss_grid = criterion_grid(grid_logits, grid_targets)\n",
    "                loss = loss_cls + loss_grid\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < current_best_val_loss:\n",
    "            current_best_val_loss = avg_val_loss\n",
    "            save_checkpoint(model, optimizer, scheduler, grid_system, current_best_val_loss, epoch, MODEL_SAVE_PATH)\n",
    "        else:\n",
    "            print(f\"Val Loss did not improve (Best: {current_best_val_loss:.4f}).\")\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "\n",
    "# ==========================================\n",
    "# 9. SUBMISSION GENERATOR\n",
    "# ==========================================\n",
    "if INFERENCE_ONLY:\n",
    "    print(\"\\nGenerating submission using the BEST saved model...\")\n",
    "    sub_df = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "    test_dataset = GeoGuessrDataset(sub_df, TEST_IMG_DIR, grid_system, transform=transform, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, sample_ids in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(DEVICE)\n",
    "            state_logits, grid_logits = model(images)\n",
    "            \n",
    "            # 1. State Prediction (Top 5)\n",
    "            top5_indices = torch.argsort(state_logits, dim=1, descending=True)[:, :5]\n",
    "            \n",
    "            # 2. Grid Prediction (Top 1) -> Convert to Lat/Lon\n",
    "            grid_preds = torch.argmax(grid_logits, dim=1)\n",
    "            \n",
    "            for i in range(len(sample_ids)):\n",
    "                sid = sample_ids[i].item()\n",
    "                states = top5_indices[i].cpu().numpy()\n",
    "                grid_idx = grid_preds[i].item()\n",
    "                \n",
    "                # Decoder: Grid ID -> Center Lat/Lon\n",
    "                pred_lat, pred_lon = grid_system.grid_to_coords(grid_idx)\n",
    "                \n",
    "                entry = {\n",
    "                    'sample_id': sid,\n",
    "                    'predicted_state_idx_1': states[0],\n",
    "                    'predicted_state_idx_2': states[1],\n",
    "                    'predicted_state_idx_3': states[2],\n",
    "                    'predicted_state_idx_4': states[3],\n",
    "                    'predicted_state_idx_5': states[4],\n",
    "                    'predicted_latitude': pred_lat,\n",
    "                    'predicted_longitude': pred_lon\n",
    "                }\n",
    "                results.append(entry)\n",
    "\n",
    "    # Save to CSV (matches original template)\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    template_df = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "    final_df = template_df.copy()\n",
    "\n",
    "    for idx, row in submission_df.iterrows():\n",
    "        mask = final_df['sample_id'] == row['sample_id']\n",
    "        for k in row.keys():\n",
    "            if k != 'sample_id':\n",
    "                final_df.loc[mask, k] = row[k]\n",
    "\n",
    "    final_df.to_csv('submission_2.csv', index=False)\n",
    "    print(f\"Submission saved to 'submission_2.csv' with {len(final_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c2b1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Resumed at epoch 9\n",
      "Training begins\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de95abbfdf849419f43646d42d1a590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dddf39f7284ab4aa4af1cc9c3eda41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | train_loss=0.9672 acc=0.9305 | val_loss=1.5360 acc=0.8128 dist=332.0 km\n",
      "  Saved new best model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deac2a34a29b4004ad46e53c600d6984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 269\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining begins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, NUM_EPOCHS):\n\u001b[0;32m--> 269\u001b[0m     tl, tcls, treg, tacc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     vl, vcls, vreg, vacc, vdist \u001b[38;5;241m=\u001b[39m eval_epoch(model, val_loader, ce, regr)\n\u001b[1;32m    271\u001b[0m     sched\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[19], line 159\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optim, ce, regr)\u001b[0m\n\u001b[1;32m    157\u001b[0m lr \u001b[38;5;241m=\u001b[39m regr(pred, coords)\n\u001b[1;32m    158\u001b[0m loss \u001b[38;5;241m=\u001b[39m lc \u001b[38;5;241m+\u001b[39m WEIGHT_REG \u001b[38;5;241m*\u001b[39m lr\n\u001b[0;32m--> 159\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    162\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m views\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GeoGuessr CS-GY 6643 pipeline: train / resume / infer\n",
    "# Modes:\n",
    "#   \"train\"   -> train from scratch\n",
    "#   \"resume\"  -> resume training\n",
    "#   \"infer\"   -> run inference only and create submission.csv\n",
    "\n",
    "MODE = \"resume\"   # change to \"resume\" or \"infer\"\n",
    "\n",
    "DATA_ROOT = \"./data/kaggle_dataset\"\n",
    "TRAIN_CSV = f\"{DATA_ROOT}/train_ground_truth.csv\"\n",
    "SAMPLE_SUB_CSV = f\"{DATA_ROOT}/sample_submission.csv\"\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "BEST_CKPT_PATH = f\"{CHECKPOINT_DIR}/best_model.pth\"\n",
    "SUBMISSION_OUT = \"./submission_gpt.csv\"\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LR = 3e-4\n",
    "VAL_SPLIT = 0.1\n",
    "WEIGHT_REG = 0.5\n",
    "NUM_WORKERS = 0\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "import os\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# Device: prefer MPS\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "\n",
    "class GeoDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, state2internal=None, with_labels=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.with_labels = with_labels\n",
    "        self.state2internal = state2internal\n",
    "\n",
    "    def load_img(self, fname):\n",
    "        p = os.path.join(self.img_dir, fname)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        imgs = [\n",
    "            self.load_img(row[\"image_north\"]),\n",
    "            self.load_img(row[\"image_east\"]),\n",
    "            self.load_img(row[\"image_south\"]),\n",
    "            self.load_img(row[\"image_west\"]),\n",
    "        ]\n",
    "        views = torch.stack(imgs, dim=0)\n",
    "\n",
    "        if self.with_labels:\n",
    "            st = self.state2internal[int(row[\"state_idx\"])]\n",
    "            coords = torch.tensor([row[\"latitude\"], row[\"longitude\"]], dtype=torch.float32)\n",
    "            return views, st, coords\n",
    "\n",
    "        return (\n",
    "            views,\n",
    "            int(row[\"sample_id\"]),\n",
    "            row[\"image_north\"],\n",
    "            row[\"image_east\"],\n",
    "            row[\"image_south\"],\n",
    "            row[\"image_west\"],\n",
    "        )\n",
    "\n",
    "# ============================================================\n",
    "# Model\n",
    "# ============================================================\n",
    "\n",
    "class GeoModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        fd = base.fc.in_features\n",
    "        base.fc = nn.Identity()\n",
    "        self.encoder = base\n",
    "        self.class_head = nn.Linear(fd, num_classes)\n",
    "        self.reg_head = nn.Linear(fd, 2)\n",
    "\n",
    "    def forward(self, views):\n",
    "        B, V, C, H, W = views.shape\n",
    "        x = views.view(B * V, C, H, W)\n",
    "        f = self.encoder(x)                 # [B*V, F]\n",
    "        f = f.view(B, V, -1).mean(dim=1)    # [B, F]\n",
    "        return self.class_head(f), self.reg_head(f)\n",
    "\n",
    "# ============================================================\n",
    "# Haversine\n",
    "# ============================================================\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1 = torch.deg2rad(lat1)\n",
    "    lat2 = torch.deg2rad(lat2)\n",
    "    lon1 = torch.deg2rad(lon1)\n",
    "    lon2 = torch.deg2rad(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = torch.sin(dlat/2)**2 + torch.cos(lat1)*torch.cos(lat2)*torch.sin(dlon/2)**2\n",
    "    return 2 * R * torch.atan2(torch.sqrt(a), torch.sqrt(1 - a))\n",
    "\n",
    "# ============================================================\n",
    "# Train helpers\n",
    "# ============================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optim, ce, regr):\n",
    "    model.train()\n",
    "    total, correct = 0, 0\n",
    "    loss_sum, cls_sum, reg_sum = 0, 0, 0\n",
    "\n",
    "    for views, labels, coords in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        views = views.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        coords = coords.to(DEVICE)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        logits, pred = model(views)\n",
    "\n",
    "        lc = ce(logits, labels)\n",
    "        lr = regr(pred, coords)\n",
    "        loss = lc + WEIGHT_REG * lr\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loss_sum += loss.item() * views.size(0)\n",
    "        cls_sum += lc.item() * views.size(0)\n",
    "        reg_sum += lr.item() * views.size(0)\n",
    "\n",
    "        correct += (logits.argmax(1) == labels).sum().item()\n",
    "        total += views.size(0)\n",
    "\n",
    "    return (\n",
    "        loss_sum / total,\n",
    "        cls_sum / total,\n",
    "        reg_sum / total,\n",
    "        correct / total,\n",
    "    )\n",
    "\n",
    "def eval_epoch(model, loader, ce, regr):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    loss_sum, cls_sum, reg_sum = 0, 0, 0\n",
    "    dists = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for views, labels, coords in tqdm(loader, desc=\"Val\", leave=False):\n",
    "            views = views.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            coords = coords.to(DEVICE)\n",
    "\n",
    "            logits, pred = model(views)\n",
    "\n",
    "            lc = ce(logits, labels)\n",
    "            lr = regr(pred, coords)\n",
    "            loss = lc + WEIGHT_REG * lr\n",
    "\n",
    "            loss_sum += loss.item() * views.size(0)\n",
    "            cls_sum += lc.item() * views.size(0)\n",
    "            reg_sum += lr.item() * views.size(0)\n",
    "\n",
    "            correct += (logits.argmax(1) == labels).sum().item()\n",
    "            total += views.size(0)\n",
    "\n",
    "            dists.append(haversine(coords[:,0], coords[:,1], pred[:,0], pred[:,1]).cpu())\n",
    "\n",
    "    if dists:\n",
    "        d = torch.cat(dists).mean().item()\n",
    "    else:\n",
    "        d = float(\"nan\")\n",
    "\n",
    "    return loss_sum/total, cls_sum/total, reg_sum/total, correct/total, d\n",
    "\n",
    "# ============================================================\n",
    "# Data setup\n",
    "# ============================================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "states = sorted(train_df.state_idx.unique())\n",
    "state2internal = {s:i for i,s in enumerate(states)}\n",
    "internal2state = {i:s for s,i in state2internal.items()}\n",
    "num_classes = len(states)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((256,256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "full_ds = GeoDataset(train_df, f\"{DATA_ROOT}/train_images\", transform, state2internal)\n",
    "val_sz = int(len(full_ds)*VAL_SPLIT)\n",
    "train_sz = len(full_ds) - val_sz\n",
    "\n",
    "train_ds, val_ds = random_split(full_ds, [train_sz, val_sz])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ============================================================\n",
    "# Model + optim\n",
    "# ============================================================\n",
    "\n",
    "model = GeoModel(num_classes).to(DEVICE)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=NUM_EPOCHS)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "regr = nn.SmoothL1Loss()\n",
    "\n",
    "start_epoch = 0\n",
    "best_val = float(\"inf\")\n",
    "\n",
    "# Resume\n",
    "if MODE in [\"resume\",\"infer\"] and os.path.exists(BEST_CKPT_PATH):\n",
    "    ck = torch.load(BEST_CKPT_PATH, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(ck[\"model\"])\n",
    "    if MODE == \"resume\":\n",
    "        optim.load_state_dict(ck[\"optim\"])\n",
    "        sched.load_state_dict(ck[\"sched\"])\n",
    "        start_epoch = ck[\"epoch\"]+1\n",
    "        best_val = ck[\"best\"]\n",
    "        print(\"Resumed at epoch\", start_epoch)\n",
    "    else:\n",
    "        print(\"Loaded model for inference\")\n",
    "\n",
    "# ============================================================\n",
    "# Training\n",
    "# ============================================================\n",
    "\n",
    "if MODE in [\"train\",\"resume\"]:\n",
    "    print(\"Training begins\")\n",
    "    for ep in range(start_epoch, NUM_EPOCHS):\n",
    "        tl, tcls, treg, tacc = train_one_epoch(model, train_loader, optim, ce, regr)\n",
    "        vl, vcls, vreg, vacc, vdist = eval_epoch(model, val_loader, ce, regr)\n",
    "        sched.step()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{NUM_EPOCHS} | \"\n",
    "              f\"train_loss={tl:.4f} acc={tacc:.4f} | \"\n",
    "              f\"val_loss={vl:.4f} acc={vacc:.4f} dist={vdist:.1f} km\")\n",
    "\n",
    "        if vl < best_val:\n",
    "            best_val = vl\n",
    "            torch.save({\n",
    "                \"epoch\": ep,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optim\": optim.state_dict(),\n",
    "                \"sched\": sched.state_dict(),\n",
    "                \"best\": best_val,\n",
    "                \"states\": states\n",
    "            }, BEST_CKPT_PATH)\n",
    "            print(\"  Saved new best model\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# Inference\n",
    "# ============================================================\n",
    "if MODE in [\"infer\",\"train\",\"resume\"]:\n",
    "    print(\"Running inference...\")\n",
    "\n",
    "    ck = torch.load(BEST_CKPT_PATH, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(ck[\"model\"])\n",
    "    states = ck[\"states\"]\n",
    "    internal2state = {i:s for i,s in enumerate(states)}\n",
    "\n",
    "    sub = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "    test_df = sub[[\"sample_id\",\"image_north\",\"image_east\",\"image_south\",\"image_west\"]].copy()\n",
    "\n",
    "    test_ds = GeoDataset(\n",
    "        test_df,\n",
    "        f\"{DATA_ROOT}/test_images\",\n",
    "        transform,\n",
    "        state2internal,\n",
    "        with_labels=False\n",
    "    )\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    preds = {}\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Infer\"):\n",
    "        views, sids, *_ = batch\n",
    "        views = views.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, pred = model(views)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            top5 = probs.topk(5, dim=1).indices.cpu()\n",
    "\n",
    "        for i, sid in enumerate(sids):\n",
    "            sid = int(sid)\n",
    "            ints = top5[i].tolist()\n",
    "            mapped = [internal2state[j] for j in ints]\n",
    "\n",
    "            lat = float(pred[i,0].item())\n",
    "            lon = float(pred[i,1].item())\n",
    "\n",
    "            lat = max(-90,min(90,lat))\n",
    "            lon = max(-180,min(180,lon))\n",
    "\n",
    "            preds[sid] = {\n",
    "                \"state1\": mapped[0],\n",
    "                \"state2\": mapped[1],\n",
    "                \"state3\": mapped[2],\n",
    "                \"state4\": mapped[3],\n",
    "                \"state5\": mapped[4],\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon\n",
    "            }\n",
    "\n",
    "    out = sub.copy()\n",
    "    out[\"predicted_state_idx_1\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"state1\"])\n",
    "    out[\"predicted_state_idx_2\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"state2\"])\n",
    "    out[\"predicted_state_idx_3\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"state3\"])\n",
    "    out[\"predicted_state_idx_4\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"state4\"])\n",
    "    out[\"predicted_state_idx_5\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"state5\"])\n",
    "    out[\"predicted_latitude\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"lat\"])\n",
    "    out[\"predicted_longitude\"] = out[\"sample_id\"].apply(lambda x: preds[x][\"lon\"])\n",
    "\n",
    "    out.to_csv(SUBMISSION_OUT, index=False)\n",
    "    print(\"Saved:\", SUBMISSION_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
