{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483d6532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "Zones mapped: {np.float64(1.0): 0, np.float64(2.0): 1, np.float64(3.0): 2, np.float64(4.0): 3, np.float64(5.0): 4, np.float64(6.0): 5, np.float64(7.0): 6, np.float64(8.0): 7, np.float64(9.0): 8, np.float64(11.0): 9, np.float64(12.0): 10, np.float64(13.0): 11, np.float64(14.0): 12}\n",
      "\n",
      "Starting Training with Physics-Informed Multi-Task Learning...\n",
      "Epoch 1: Loss 3.546 | Class Acc: 0.509 | Zone Acc: 0.216\n",
      "Epoch 2: Loss 3.059 | Class Acc: 0.517 | Zone Acc: 0.229\n",
      "Epoch 3: Loss 3.033 | Class Acc: 0.506 | Zone Acc: 0.216\n",
      "Epoch 4: Loss 2.996 | Class Acc: 0.518 | Zone Acc: 0.230\n",
      "Epoch 5: Loss 3.004 | Class Acc: 0.530 | Zone Acc: 0.220\n",
      "Epoch 6: Loss 2.970 | Class Acc: 0.521 | Zone Acc: 0.217\n",
      "Epoch 7: Loss 2.965 | Class Acc: 0.524 | Zone Acc: 0.228\n",
      "Epoch 8: Loss 2.954 | Class Acc: 0.522 | Zone Acc: 0.212\n",
      "Epoch 9: Loss 2.953 | Class Acc: 0.516 | Zone Acc: 0.220\n",
      "Epoch 10: Loss 2.939 | Class Acc: 0.503 | Zone Acc: 0.220\n",
      "Epoch 11: Loss 2.924 | Class Acc: 0.522 | Zone Acc: 0.232\n",
      "Epoch 12: Loss 2.920 | Class Acc: 0.510 | Zone Acc: 0.233\n",
      "Epoch 13: Loss 2.906 | Class Acc: 0.504 | Zone Acc: 0.227\n",
      "Epoch 14: Loss 2.888 | Class Acc: 0.527 | Zone Acc: 0.223\n",
      "Epoch 15: Loss 2.886 | Class Acc: 0.513 | Zone Acc: 0.230\n",
      "Epoch 16: Loss 2.885 | Class Acc: 0.507 | Zone Acc: 0.226\n",
      "Epoch 17: Loss 2.883 | Class Acc: 0.519 | Zone Acc: 0.214\n",
      "Epoch 18: Loss 2.868 | Class Acc: 0.504 | Zone Acc: 0.232\n",
      "Epoch 19: Loss 2.849 | Class Acc: 0.521 | Zone Acc: 0.228\n",
      "Epoch 20: Loss 2.854 | Class Acc: 0.517 | Zone Acc: 0.220\n",
      "Epoch 21: Loss 2.835 | Class Acc: 0.529 | Zone Acc: 0.233\n",
      "Epoch 22: Loss 2.829 | Class Acc: 0.523 | Zone Acc: 0.230\n",
      "Epoch 23: Loss 2.818 | Class Acc: 0.517 | Zone Acc: 0.232\n",
      "Epoch 24: Loss 2.827 | Class Acc: 0.516 | Zone Acc: 0.218\n",
      "Epoch 25: Loss 2.814 | Class Acc: 0.503 | Zone Acc: 0.214\n",
      "\n",
      "Predicting on Test Set...\n",
      "Success! Submission saved to submission_gemini.csv\n",
      "     file_name pitch_class  zone\n",
      "0   pitch2.mp4      strike     4\n",
      "1   pitch6.mp4        ball    11\n",
      "2   pitch7.mp4      strike    11\n",
      "3   pitch9.mp4      strike    11\n",
      "4  pitch10.mp4      strike    12\n"
     ]
    }
   ],
   "source": [
    "# score: \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. FILE PATHS (FROM YOUR INPUT)\n",
    "# ==========================================\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATS_PATH = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "SAMPLE_SUB_PATH = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "OUTPUT_PATH = \"submission_gemini.csv\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'epochs': 25,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'hidden_dim': 256,\n",
    "    # Loss Weights\n",
    "    'w_class': 1.0,  # Importance of Strike/Ball\n",
    "    'w_zone': 0.5,   # Importance of correct Zone ID\n",
    "    'w_loc': 1.5     # Importance of Physics (plate_x, plate_z) - High priority!\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(CONFIG['seed'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATA PROCESSING\n",
    "# ==========================================\n",
    "def load_and_process_data():\n",
    "    print(\"Loading data...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    df_test = pd.read_csv(TEST_FEATS_PATH)\n",
    "    \n",
    "    # Drop missing labels in train\n",
    "    df_train = df_train.dropna(subset=['pitch_class', 'zone', 'plate_x', 'plate_z'])\n",
    "\n",
    "    # Features that define the physics of the pitch\n",
    "    # Note: 'sz_top' and 'sz_bot' are crucial as they define the target box height\n",
    "    feature_cols = [\n",
    "        'release_speed', 'effective_speed', 'release_spin_rate',\n",
    "        'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "        'release_extension', 'pfx_x', 'pfx_z', \n",
    "        'sz_top', 'sz_bot'\n",
    "    ]\n",
    "    \n",
    "    # Categorical Features\n",
    "    cat_cols = ['stand', 'p_throws']\n",
    "    \n",
    "    # Handling Missing Values (Imputation)\n",
    "    for col in feature_cols:\n",
    "        mean_val = df_train[col].mean()\n",
    "        df_train[col] = df_train[col].fillna(mean_val)\n",
    "        df_test[col] = df_test[col].fillna(mean_val)\n",
    "\n",
    "    # Encode Categoricals (L/R -> 0/1)\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([df_train[col], df_test[col]])\n",
    "        le.fit(combined)\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        feature_cols.append(col)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_full = scaler.fit_transform(df_train[feature_cols])\n",
    "    X_test = scaler.transform(df_test[feature_cols])\n",
    "\n",
    "    # --- TARGET PREPARATION ---\n",
    "    \n",
    "    # 1. Pitch Class (Binary): Strike=1, Ball=0\n",
    "    class_map = {'strike': 1, 'ball': 0}\n",
    "    y_class_full = df_train['pitch_class'].map(class_map).values.astype(np.float32)\n",
    "    \n",
    "    # 2. Location (Regression): plate_x, plate_z\n",
    "    # This forces the model to learn the trajectory logic\n",
    "    y_loc_full = df_train[['plate_x', 'plate_z']].values.astype(np.float32)\n",
    "\n",
    "    # 3. Zone (Multi-Class): Map 1-14 to 0-N indices\n",
    "    unique_zones = sorted(df_train['zone'].unique())\n",
    "    zone_to_idx = {z: i for i, z in enumerate(unique_zones)}\n",
    "    idx_to_zone = {i: z for z, i in zone_to_idx.items()}\n",
    "    y_zone_full = df_train['zone'].map(zone_to_idx).values.astype(np.int64)\n",
    "\n",
    "    print(f\"Zones mapped: {zone_to_idx}\")\n",
    "\n",
    "    # Split Train/Validation\n",
    "    # We stratify by Zone to ensure all zones represent in Val\n",
    "    X_train, X_val, yc_train, yc_val, yz_train, yz_val, yloc_train, yloc_val = train_test_split(\n",
    "        X_train_full, y_class_full, y_zone_full, y_loc_full, \n",
    "        test_size=0.15, random_state=CONFIG['seed'], stratify=y_zone_full\n",
    "    )\n",
    "    \n",
    "    data_pack = {\n",
    "        'train': (X_train, yc_train, yz_train, yloc_train),\n",
    "        'val': (X_val, yc_val, yz_val, yloc_val),\n",
    "        'test': (X_test, df_test['file_name'].values),\n",
    "        'mappings': (idx_to_zone, len(unique_zones)),\n",
    "        'input_dim': X_train.shape[1]\n",
    "    }\n",
    "    \n",
    "    return data_pack\n",
    "\n",
    "# ==========================================\n",
    "# 4. PYTORCH DATASET\n",
    "# ==========================================\n",
    "class PitchDataset(Dataset):\n",
    "    def __init__(self, features, y_class=None, y_zone=None, y_loc=None, mode='train'):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.mode = mode\n",
    "        if mode != 'test':\n",
    "            self.y_class = torch.FloatTensor(y_class).unsqueeze(1)\n",
    "            self.y_zone = torch.LongTensor(y_zone)\n",
    "            self.y_loc = torch.FloatTensor(y_loc) # [N, 2] for plate_x, plate_z\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'test':\n",
    "            return self.features[idx]\n",
    "        else:\n",
    "            return self.features[idx], self.y_class[idx], self.y_zone[idx], self.y_loc[idx]\n",
    "\n",
    "# ==========================================\n",
    "# 5. PHYSICS-INFORMED MODEL\n",
    "# ==========================================\n",
    "class PhysicsPitchModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_zones):\n",
    "        super(PhysicsPitchModel, self).__init__()\n",
    "        \n",
    "        # Main Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Head 1: Trajectory Estimator (Regression)\n",
    "        # Predicts exactly where the ball is at the plate (x, z)\n",
    "        self.loc_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2) # Output: plate_x, plate_z\n",
    "        )\n",
    "        \n",
    "        # Head 2: Pitch Call (Classification)\n",
    "        # Takes physics features + predicted location info implicitly\n",
    "        self.class_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "        \n",
    "        # Head 3: Zone Classifier\n",
    "        self.zone_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_zones) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feats = self.encoder(x)\n",
    "        \n",
    "        # Predict everything\n",
    "        loc_preds = self.loc_head(feats)\n",
    "        class_logits = self.class_head(feats)\n",
    "        zone_logits = self.zone_head(feats)\n",
    "        \n",
    "        return class_logits, zone_logits, loc_preds\n",
    "\n",
    "# ==========================================\n",
    "# 6. TRAINING LOOP\n",
    "# ==========================================\n",
    "def train_engine():\n",
    "    data = load_and_process_data()\n",
    "    X_train, yc_train, yz_train, yloc_train = data['train']\n",
    "    X_val, yc_val, yz_val, yloc_val = data['val']\n",
    "    \n",
    "    train_ds = PitchDataset(X_train, yc_train, yz_train, yloc_train, mode='train')\n",
    "    val_ds = PitchDataset(X_val, yc_val, yz_val, yloc_val, mode='train')\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "    \n",
    "    model = PhysicsPitchModel(data['input_dim'], CONFIG['hidden_dim'], data['mappings'][1]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    \n",
    "    # Loss Functions\n",
    "    crit_class = nn.BCEWithLogitsLoss()\n",
    "    crit_zone = nn.CrossEntropyLoss()\n",
    "    crit_loc = nn.MSELoss() # For physics coordinates\n",
    "    \n",
    "    print(\"\\nStarting Training with Physics-Informed Multi-Task Learning...\")\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for bx, byc, byz, byloc in train_loader:\n",
    "            bx, byc, byz, byloc = bx.to(device), byc.to(device), byz.to(device), byloc.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred_c, pred_z, pred_loc = model(bx)\n",
    "            \n",
    "            loss_c = crit_class(pred_c, byc)\n",
    "            loss_z = crit_zone(pred_z, byz)\n",
    "            loss_l = crit_loc(pred_loc, byloc)\n",
    "            \n",
    "            # Weighted Sum Loss\n",
    "            loss = (CONFIG['w_class'] * loss_c) + \\\n",
    "                   (CONFIG['w_zone'] * loss_z) + \\\n",
    "                   (CONFIG['w_loc'] * loss_l)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_c, correct_z, total = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for bx, byc, byz, _ in val_loader:\n",
    "                bx, byc, byz = bx.to(device), byc.to(device), byz.to(device)\n",
    "                pred_c, pred_z, _ = model(bx)\n",
    "                \n",
    "                # Class Acc\n",
    "                pred_labels_c = (torch.sigmoid(pred_c) > 0.5).float()\n",
    "                correct_c += (pred_labels_c == byc).sum().item()\n",
    "                \n",
    "                # Zone Acc\n",
    "                _, pred_labels_z = torch.max(pred_z, 1)\n",
    "                correct_z += (pred_labels_z == byz).sum().item()\n",
    "                \n",
    "                total += byc.size(0)\n",
    "                \n",
    "        print(f\"Epoch {epoch+1}: Loss {total_loss/len(train_loader):.3f} | \"\n",
    "              f\"Class Acc: {correct_c/total:.3f} | Zone Acc: {correct_z/total:.3f}\")\n",
    "        \n",
    "    return model, data\n",
    "\n",
    "# ==========================================\n",
    "# 7. SUBMISSION GENERATION\n",
    "# ==========================================\n",
    "def generate_submission():\n",
    "    model, data = train_engine()\n",
    "    X_test, file_names = data['test']\n",
    "    idx_to_zone = data['mappings'][0]\n",
    "    \n",
    "    test_ds = PitchDataset(X_test, mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    c_preds_final = []\n",
    "    z_preds_final = []\n",
    "    \n",
    "    print(\"\\nPredicting on Test Set...\")\n",
    "    with torch.no_grad():\n",
    "        for bx in test_loader:\n",
    "            bx = bx.to(device)\n",
    "            pc, pz, _ = model(bx) # We ignore loc prediction for submission, but it helped train\n",
    "            \n",
    "            # Class\n",
    "            c_probs = torch.sigmoid(pc).cpu().numpy().flatten()\n",
    "            c_preds_final.extend((c_probs > 0.5).astype(int))\n",
    "            \n",
    "            # Zone\n",
    "            z_idxs = torch.max(pz, 1)[1].cpu().numpy().flatten()\n",
    "            z_preds_final.extend([idx_to_zone[i] for i in z_idxs])\n",
    "            \n",
    "    # Create DataFrame\n",
    "    df_sub = pd.DataFrame({\n",
    "        'file_name': file_names,\n",
    "        'pitch_class': ['strike' if x == 1 else 'ball' for x in c_preds_final],\n",
    "        'zone': z_preds_final\n",
    "    })\n",
    "    \n",
    "    # Ensure order matches template if possible\n",
    "    try:\n",
    "        if os.path.exists(SAMPLE_SUB_PATH):\n",
    "            template = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "            # Left join to enforce order\n",
    "            final_df = template[['file_name']].merge(df_sub, on='file_name', how='left')\n",
    "            # Fill na if any mismatches (shouldn't happen)\n",
    "            final_df['pitch_class'] = final_df['pitch_class'].fillna('ball')\n",
    "            final_df['zone'] = final_df['zone'].fillna(14).astype(int)\n",
    "        else:\n",
    "            final_df = df_sub\n",
    "            \n",
    "        final_df.to_csv(OUTPUT_PATH, index=False)\n",
    "        print(f\"Success! Submission saved to {OUTPUT_PATH}\")\n",
    "        print(final_df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving submission: {e}\")\n",
    "        # Fallback save\n",
    "        df_sub.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab813957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: MPS (Apple Silicon Acceleration)\n",
      "Processing CSV Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth\" to /Users/swooshie/.cache/torch/hub/checkpoints/r2plus1d_18-91a641e6.pth\n",
      "100%|██████████| 120M/120M [00:02<00:00, 55.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training on 5100 samples ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 638/638 [48:51<00:00,  4.60s/it, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [02:29<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Val Loss: 3.0156 | Class Acc: 0.599 | Zone Acc: 0.233\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 638/638 [43:40<00:00,  4.11s/it, loss=3.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [02:20<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Val Loss: 2.7250 | Class Acc: 0.642 | Zone Acc: 0.276\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 638/638 [43:34<00:00,  4.10s/it, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [02:22<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Val Loss: 2.6282 | Class Acc: 0.672 | Zone Acc: 0.307\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 638/638 [43:28<00:00,  4.09s/it, loss=2.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [02:03<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Val Loss: 2.8175 | Class Acc: 0.641 | Zone Acc: 0.292\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 638/638 [46:16<00:00,  4.35s/it, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:58<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Val Loss: 2.7102 | Class Acc: 0.661 | Zone Acc: 0.302\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Generating Submission ---\n",
      "Loaded best model for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 500/500 [08:50<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Saved to submission_hybrid_best_gemini.csv\n"
     ]
    }
   ],
   "source": [
    "# score: 0.56\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models.video import R2Plus1D_18_Weights \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. FILE PATHS\n",
    "# ==========================================\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATS_PATH = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "SAMPLE_SUB_PATH = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "OUTPUT_PATH = \"submission_hybrid_best_gemini.csv\"\n",
    "MODEL_SAVE_PATH = \"best_pitch_model.pth\" # <--- NEW: Where we save the weights\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 8,  \n",
    "    'lr': 1e-4,\n",
    "    'frames': 16,\n",
    "    'img_size': 112,\n",
    "    'hidden_dim': 256,\n",
    "    'load_checkpoint': False  # <--- SET TO TRUE TO SKIP TRAIN AND RUN INFERENCE\n",
    "}\n",
    "\n",
    "# Device Selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using device: MPS (Apple Silicon Acceleration)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: CPU\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS & DATA LOADING\n",
    "# ==========================================\n",
    "def load_video_clip(path, num_frames=16, resize=(112, 112)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.zeros(3, num_frames, resize[0], resize[1])\n",
    "\n",
    "    indices = np.linspace(0, len(frames) - 1, num_frames).astype(int)\n",
    "    sampled_frames = np.array([frames[i] for i in indices])\n",
    "\n",
    "    tensor = torch.from_numpy(sampled_frames).permute(3, 0, 1, 2).float() / 255.0\n",
    "    mean = torch.tensor([0.43216, 0.394666, 0.37645]).view(3, 1, 1, 1)\n",
    "    std = torch.tensor([0.22803, 0.22145, 0.216989]).view(3, 1, 1, 1)\n",
    "    tensor = (tensor - mean) / std\n",
    "    return tensor\n",
    "\n",
    "def get_data_splits():\n",
    "    print(\"Processing CSV Data...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH).dropna(subset=['pitch_class', 'zone', 'plate_x', 'plate_z'])\n",
    "    df_test = pd.read_csv(TEST_FEATS_PATH)\n",
    "\n",
    "    phy_cols = [\n",
    "        'release_speed', 'effective_speed', 'release_spin_rate',\n",
    "        'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "        'pfx_x', 'pfx_z', 'sz_top', 'sz_bot'\n",
    "    ]\n",
    "    \n",
    "    for col in ['stand', 'p_throws']:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([df_train[col], df_test[col]]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        phy_cols.append(col)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_train[phy_cols] = scaler.fit_transform(df_train[phy_cols].fillna(0))\n",
    "    df_test[phy_cols] = scaler.transform(df_test[phy_cols].fillna(0))\n",
    "\n",
    "    class_map = {'strike': 1, 'ball': 0}\n",
    "    df_train['label_class'] = df_train['pitch_class'].map(class_map)\n",
    "    \n",
    "    zones = sorted(df_train['zone'].unique())\n",
    "    zone_map = {z: i for i, z in enumerate(zones)}\n",
    "    idx_to_zone = {i: z for z, i in zone_map.items()}\n",
    "    df_train['label_zone'] = df_train['zone'].map(zone_map)\n",
    "\n",
    "    train_idx, val_idx = train_test_split(df_train.index, test_size=0.15, random_state=CONFIG['seed'])\n",
    "    \n",
    "    return {\n",
    "        'train': df_train.loc[train_idx],\n",
    "        'val': df_train.loc[val_idx],\n",
    "        'test': df_test,\n",
    "        'phy_cols': phy_cols,\n",
    "        'idx_to_zone': idx_to_zone,\n",
    "        'num_zones': len(zones)\n",
    "    }\n",
    "\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, df, video_dir, phy_cols, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.video_dir = video_dir\n",
    "        self.phy_cols = phy_cols\n",
    "        self.mode = mode\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        physics_vec = torch.tensor(row[self.phy_cols].values.astype(np.float32))\n",
    "        vid_path = os.path.join(self.video_dir, row['file_name'])\n",
    "        video_tensor = load_video_clip(vid_path, num_frames=CONFIG['frames'], resize=(CONFIG['img_size'], CONFIG['img_size']))\n",
    "        if self.mode == 'test': return video_tensor, physics_vec\n",
    "        else: return video_tensor, physics_vec, torch.tensor(row['label_class'], dtype=torch.float).unsqueeze(0), torch.tensor(row['label_zone'], dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "class PitchHybridModel(nn.Module):\n",
    "    def __init__(self, physics_dim, num_zones):\n",
    "        super(PitchHybridModel, self).__init__()\n",
    "        \n",
    "        # Using R2Plus1D (Best 18-layer available)\n",
    "        weights = R2Plus1D_18_Weights.DEFAULT\n",
    "        self.video_backbone = models.video.r2plus1d_18(weights=weights)\n",
    "        \n",
    "        vid_out_dim = self.video_backbone.fc.in_features\n",
    "        self.video_backbone.fc = nn.Identity() \n",
    "        \n",
    "        self.video_fc = nn.Sequential(\n",
    "            nn.Linear(vid_out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.physics_net = nn.Sequential(\n",
    "            nn.Linear(physics_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        combined_dim = 256 + 128\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.head_class = nn.Linear(256, 1)\n",
    "        self.head_zone = nn.Linear(256, num_zones)\n",
    "        \n",
    "    def forward(self, video, physics):\n",
    "        v_feat = self.video_backbone(video)\n",
    "        v_feat = self.video_fc(v_feat)\n",
    "        p_feat = self.physics_net(physics)\n",
    "        combined = torch.cat((v_feat, p_feat), dim=1)\n",
    "        fused = self.fusion_layer(combined)\n",
    "        return self.head_class(fused), self.head_zone(fused)\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN PIPELINE\n",
    "# ==========================================\n",
    "def run_pipeline():\n",
    "    data = get_data_splits()\n",
    "    model = PitchHybridModel(physics_dim=len(data['phy_cols']), num_zones=data['num_zones']).to(device)\n",
    "    \n",
    "    # --- LOAD CHECKPOINT IF REQUESTED ---\n",
    "    if CONFIG['load_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"\\nLoading model weights from {MODEL_SAVE_PATH}...\")\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    \n",
    "    # --- TRAINING PHASE ---\n",
    "    if not CONFIG['load_checkpoint']:\n",
    "        train_ds = HybridDataset(data['train'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        val_ds = HybridDataset(data['val'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
    "        crit_c = nn.BCEWithLogitsLoss()\n",
    "        crit_z = nn.CrossEntropyLoss()\n",
    "        \n",
    "        best_val_loss = float('inf') # Track best loss\n",
    "        \n",
    "        print(f\"\\n--- Starting Training on {len(train_ds)} samples ---\")\n",
    "        \n",
    "        for epoch in range(CONFIG['epochs']):\n",
    "            model.train()\n",
    "            train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\", leave=True)\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            for vid, phy, lc, lz in train_loop:\n",
    "                vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out_c, out_z = model(vid, phy)\n",
    "                loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item()\n",
    "                train_loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            acc_c_num, acc_z_num, total = 0, 0, 0\n",
    "            \n",
    "            print(\"Validating...\")\n",
    "            with torch.no_grad():\n",
    "                for vid, phy, lc, lz in tqdm(val_loader, desc=\"Val\"):\n",
    "                    vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                    out_c, out_z = model(vid, phy)\n",
    "                    \n",
    "                    # Calculate Loss\n",
    "                    batch_loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                    val_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate Accuracy\n",
    "                    pred_c = (torch.sigmoid(out_c) > 0.5).float()\n",
    "                    acc_c_num += (pred_c == lc).sum().item()\n",
    "                    pred_z = torch.argmax(out_z, dim=1)\n",
    "                    acc_z_num += (pred_z == lz).sum().item()\n",
    "                    total += lc.size(0)\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f} | Class Acc: {acc_c_num/total:.3f} | Zone Acc: {acc_z_num/total:.3f}\")\n",
    "            \n",
    "            # --- SAVE BEST MODEL ---\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "                print(f\"Saved New Best Model to {MODEL_SAVE_PATH}!\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # --- INFERENCE PHASE ---\n",
    "    print(\"\\n--- Generating Submission ---\")\n",
    "    # Ensure we are using the best weights for inference\n",
    "    if not CONFIG['load_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "        print(\"Loaded best model for inference.\")\n",
    "\n",
    "    test_ds = HybridDataset(data['test'], TEST_VIDEO_DIR, data['phy_cols'], mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval()\n",
    "    final_classes = []\n",
    "    final_zones = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vid, phy in tqdm(test_loader, desc=\"Inference\"):\n",
    "            vid, phy = vid.to(device), phy.to(device)\n",
    "            out_c, out_z = model(vid, phy)\n",
    "            \n",
    "            c_probs = torch.sigmoid(out_c).cpu().numpy().flatten()\n",
    "            z_idxs = torch.argmax(out_z, dim=1).cpu().numpy().flatten()\n",
    "            \n",
    "            final_classes.extend(['strike' if p > 0.5 else 'ball' for p in c_probs])\n",
    "            final_zones.extend([data['idx_to_zone'][z] for z in z_idxs])\n",
    "            \n",
    "    df_sub = pd.DataFrame({'file_name': data['test']['file_name'], 'pitch_class': final_classes, 'zone': final_zones})\n",
    "    \n",
    "    if os.path.exists(SAMPLE_SUB_PATH):\n",
    "        template = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        df_sub = template[['file_name']].merge(df_sub, on='file_name', how='left')\n",
    "        df_sub['pitch_class'] = df_sub['pitch_class'].fillna('ball')\n",
    "        df_sub['zone'] = df_sub['zone'].fillna(14).astype(int)\n",
    "\n",
    "    df_sub.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"Submission Saved to {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0507de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: MPS (Apple Silicon Acceleration)\n",
      "Processing CSV Data...\n",
      "\n",
      "--- Starting Training on 5100 samples ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 638/638 [37:53<00:00,  3.56s/it, loss=3.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:59<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Val Loss: 3.2195 | Class Acc: 0.563 | Zone Acc: 0.238\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 638/638 [36:16<00:00,  3.41s/it, loss=3.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:58<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Val Loss: 2.7670 | Class Acc: 0.597 | Zone Acc: 0.290\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 638/638 [36:22<00:00,  3.42s/it, loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:57<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Val Loss: 2.6488 | Class Acc: 0.616 | Zone Acc: 0.310\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 638/638 [36:13<00:00,  3.41s/it, loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:57<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Val Loss: 2.6791 | Class Acc: 0.628 | Zone Acc: 0.351\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 638/638 [36:14<00:00,  3.41s/it, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [02:00<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Val Loss: 2.4503 | Class Acc: 0.676 | Zone Acc: 0.374\n",
      "Saved New Best Model to best_pitch_model.pth!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 638/638 [36:15<00:00,  3.41s/it, loss=5.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:57<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Val Loss: 2.5703 | Class Acc: 0.707 | Zone Acc: 0.348\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 638/638 [36:16<00:00,  3.41s/it, loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:59<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Val Loss: 2.9495 | Class Acc: 0.640 | Zone Acc: 0.341\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 638/638 [36:12<00:00,  3.41s/it, loss=1.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:58<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Val Loss: 2.7870 | Class Acc: 0.687 | Zone Acc: 0.372\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 638/638 [36:15<00:00,  3.41s/it, loss=3.77] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:58<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Val Loss: 3.3288 | Class Acc: 0.686 | Zone Acc: 0.303\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 638/638 [36:13<00:00,  3.41s/it, loss=3.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 113/113 [01:58<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Val Loss: 3.0233 | Class Acc: 0.691 | Zone Acc: 0.360\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Generating Submission ---\n",
      "Loaded best model for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 500/500 [08:42<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Saved to submission_hybrid_best_gemini.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# score: 0.59915\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models.video import R2Plus1D_18_Weights \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. FILE PATHS\n",
    "# ==========================================\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATS_PATH = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "SAMPLE_SUB_PATH = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "OUTPUT_PATH = \"submission_hybrid_best_gemini.csv\"\n",
    "MODEL_SAVE_PATH = \"best_pitch_model.pth\" # <--- NEW: Where we save the weights\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 8,  \n",
    "    'lr': 1e-4,\n",
    "    'frames': 16,\n",
    "    'img_size': 112,\n",
    "    'hidden_dim': 256,\n",
    "    'load_checkpoint': False  # <--- SET TO TRUE TO SKIP TRAIN AND RUN INFERENCE\n",
    "}\n",
    "\n",
    "# Device Selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using device: MPS (Apple Silicon Acceleration)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: CPU\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS & DATA LOADING\n",
    "# ==========================================\n",
    "def load_video_clip(path, num_frames=16, resize=(112, 112)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.zeros(3, num_frames, resize[0], resize[1])\n",
    "\n",
    "    indices = np.linspace(0, len(frames) - 1, num_frames).astype(int)\n",
    "    sampled_frames = np.array([frames[i] for i in indices])\n",
    "\n",
    "    tensor = torch.from_numpy(sampled_frames).permute(3, 0, 1, 2).float() / 255.0\n",
    "    mean = torch.tensor([0.43216, 0.394666, 0.37645]).view(3, 1, 1, 1)\n",
    "    std = torch.tensor([0.22803, 0.22145, 0.216989]).view(3, 1, 1, 1)\n",
    "    tensor = (tensor - mean) / std\n",
    "    return tensor\n",
    "\n",
    "def get_data_splits():\n",
    "    print(\"Processing CSV Data...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH).dropna(subset=['pitch_class', 'zone', 'plate_x', 'plate_z'])\n",
    "    df_test = pd.read_csv(TEST_FEATS_PATH)\n",
    "\n",
    "    phy_cols = [\n",
    "        'release_speed', 'effective_speed', 'release_spin_rate',\n",
    "        'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "        'pfx_x', 'pfx_z', 'sz_top', 'sz_bot'\n",
    "    ]\n",
    "    \n",
    "    for col in ['stand', 'p_throws']:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([df_train[col], df_test[col]]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        phy_cols.append(col)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_train[phy_cols] = scaler.fit_transform(df_train[phy_cols].fillna(0))\n",
    "    df_test[phy_cols] = scaler.transform(df_test[phy_cols].fillna(0))\n",
    "\n",
    "    class_map = {'strike': 1, 'ball': 0}\n",
    "    df_train['label_class'] = df_train['pitch_class'].map(class_map)\n",
    "    \n",
    "    zones = sorted(df_train['zone'].unique())\n",
    "    zone_map = {z: i for i, z in enumerate(zones)}\n",
    "    idx_to_zone = {i: z for z, i in zone_map.items()}\n",
    "    df_train['label_zone'] = df_train['zone'].map(zone_map)\n",
    "\n",
    "    train_idx, val_idx = train_test_split(df_train.index, test_size=0.15, random_state=CONFIG['seed'])\n",
    "    \n",
    "    return {\n",
    "        'train': df_train.loc[train_idx],\n",
    "        'val': df_train.loc[val_idx],\n",
    "        'test': df_test,\n",
    "        'phy_cols': phy_cols,\n",
    "        'idx_to_zone': idx_to_zone,\n",
    "        'num_zones': len(zones)\n",
    "    }\n",
    "\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, df, video_dir, phy_cols, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.video_dir = video_dir\n",
    "        self.phy_cols = phy_cols\n",
    "        self.mode = mode\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        physics_vec = torch.tensor(row[self.phy_cols].values.astype(np.float32))\n",
    "        vid_path = os.path.join(self.video_dir, row['file_name'])\n",
    "        video_tensor = load_video_clip(vid_path, num_frames=CONFIG['frames'], resize=(CONFIG['img_size'], CONFIG['img_size']))\n",
    "        if self.mode == 'test': return video_tensor, physics_vec\n",
    "        else: return video_tensor, physics_vec, torch.tensor(row['label_class'], dtype=torch.float).unsqueeze(0), torch.tensor(row['label_zone'], dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "class PitchHybridModel(nn.Module):\n",
    "    def __init__(self, physics_dim, num_zones):\n",
    "        super(PitchHybridModel, self).__init__()\n",
    "        \n",
    "        # Using R2Plus1D (Best 18-layer available)\n",
    "        weights = R2Plus1D_18_Weights.DEFAULT\n",
    "        self.video_backbone = models.video.r2plus1d_18(weights=weights)\n",
    "        \n",
    "        vid_out_dim = self.video_backbone.fc.in_features\n",
    "        self.video_backbone.fc = nn.Identity() \n",
    "        \n",
    "        self.video_fc = nn.Sequential(\n",
    "            nn.Linear(vid_out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.physics_net = nn.Sequential(\n",
    "            nn.Linear(physics_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        combined_dim = 256 + 128\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.head_class = nn.Linear(256, 1)\n",
    "        self.head_zone = nn.Linear(256, num_zones)\n",
    "        \n",
    "    def forward(self, video, physics):\n",
    "        v_feat = self.video_backbone(video)\n",
    "        v_feat = self.video_fc(v_feat)\n",
    "        p_feat = self.physics_net(physics)\n",
    "        combined = torch.cat((v_feat, p_feat), dim=1)\n",
    "        fused = self.fusion_layer(combined)\n",
    "        return self.head_class(fused), self.head_zone(fused)\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN PIPELINE\n",
    "# ==========================================\n",
    "def run_pipeline():\n",
    "    data = get_data_splits()\n",
    "    model = PitchHybridModel(physics_dim=len(data['phy_cols']), num_zones=data['num_zones']).to(device)\n",
    "    \n",
    "    # --- LOAD CHECKPOINT IF REQUESTED ---\n",
    "    if CONFIG['load_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"\\nLoading model weights from {MODEL_SAVE_PATH}...\")\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    \n",
    "    # --- TRAINING PHASE ---\n",
    "    if not CONFIG['load_checkpoint']:\n",
    "        train_ds = HybridDataset(data['train'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        val_ds = HybridDataset(data['val'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
    "        crit_c = nn.BCEWithLogitsLoss()\n",
    "        crit_z = nn.CrossEntropyLoss()\n",
    "        \n",
    "        best_val_loss = float('inf') # Track best loss\n",
    "        \n",
    "        print(f\"\\n--- Starting Training on {len(train_ds)} samples ---\")\n",
    "        \n",
    "        for epoch in range(CONFIG['epochs']):\n",
    "            model.train()\n",
    "            train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\", leave=True)\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            for vid, phy, lc, lz in train_loop:\n",
    "                vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out_c, out_z = model(vid, phy)\n",
    "                loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item()\n",
    "                train_loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            acc_c_num, acc_z_num, total = 0, 0, 0\n",
    "            \n",
    "            print(\"Validating...\")\n",
    "            with torch.no_grad():\n",
    "                for vid, phy, lc, lz in tqdm(val_loader, desc=\"Val\"):\n",
    "                    vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                    out_c, out_z = model(vid, phy)\n",
    "                    \n",
    "                    # Calculate Loss\n",
    "                    batch_loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                    val_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate Accuracy\n",
    "                    pred_c = (torch.sigmoid(out_c) > 0.5).float()\n",
    "                    acc_c_num += (pred_c == lc).sum().item()\n",
    "                    pred_z = torch.argmax(out_z, dim=1)\n",
    "                    acc_z_num += (pred_z == lz).sum().item()\n",
    "                    total += lc.size(0)\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f} | Class Acc: {acc_c_num/total:.3f} | Zone Acc: {acc_z_num/total:.3f}\")\n",
    "            \n",
    "            # --- SAVE BEST MODEL ---\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "                print(f\"Saved New Best Model to {MODEL_SAVE_PATH}!\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # --- INFERENCE PHASE ---\n",
    "    print(\"\\n--- Generating Submission ---\")\n",
    "    # Ensure we are using the best weights for inference\n",
    "    if not CONFIG['load_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "        print(\"Loaded best model for inference.\")\n",
    "\n",
    "    test_ds = HybridDataset(data['test'], TEST_VIDEO_DIR, data['phy_cols'], mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval()\n",
    "    final_classes = []\n",
    "    final_zones = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vid, phy in tqdm(test_loader, desc=\"Inference\"):\n",
    "            vid, phy = vid.to(device), phy.to(device)\n",
    "            out_c, out_z = model(vid, phy)\n",
    "            \n",
    "            c_probs = torch.sigmoid(out_c).cpu().numpy().flatten()\n",
    "            z_idxs = torch.argmax(out_z, dim=1).cpu().numpy().flatten()\n",
    "            \n",
    "            final_classes.extend(['strike' if p > 0.5 else 'ball' for p in c_probs])\n",
    "            final_zones.extend([data['idx_to_zone'][z] for z in z_idxs])\n",
    "            \n",
    "    df_sub = pd.DataFrame({'file_name': data['test']['file_name'], 'pitch_class': final_classes, 'zone': final_zones})\n",
    "    \n",
    "    if os.path.exists(SAMPLE_SUB_PATH):\n",
    "        template = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        df_sub = template[['file_name']].merge(df_sub, on='file_name', how='left')\n",
    "        df_sub['pitch_class'] = df_sub['pitch_class'].fillna('ball')\n",
    "        df_sub['zone'] = df_sub['zone'].fillna(14).astype(int)\n",
    "\n",
    "    df_sub.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"Submission Saved to {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e6b6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: MPS (Apple Silicon Acceleration)\n",
      "Processing CSV Data...\n",
      "\n",
      "[INFO] Found checkpoint at best_pitch_model.pth. Loading weights...\n",
      "[INFO] Weights loaded successfully! Continuing from best model.\n",
      "\n",
      "--- Generating Submission ---\n",
      "Loaded best model weights for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 500/500 [08:48<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Saved to submission_hybrid_best_gemini_better.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# score: 0.61080\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models.video import R2Plus1D_18_Weights \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. FILE PATHS\n",
    "# ==========================================\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATS_PATH = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "SAMPLE_SUB_PATH = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "OUTPUT_PATH = \"submission_hybrid_best_gemini_better.csv\"\n",
    "MODEL_SAVE_PATH = \"best_pitch_model.pth\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'epochs': 15,          # Set how many MORE epochs you want to train\n",
    "    'batch_size': 8,  \n",
    "    'lr': 1e-4,           # Keep low if resuming (fine-tuning)\n",
    "    'frames': 16,\n",
    "    'img_size': 112,\n",
    "    'hidden_dim': 256,\n",
    "    \n",
    "    # --- CONTROL FLAGS ---\n",
    "    'resume_checkpoint': True,  # If True: Loads best_pitch_model.pth (if it exists) before starting\n",
    "    'train_model': False         # If True: Runs the training loop. If False: Jumps to Inference.\n",
    "}\n",
    "\n",
    "# Device Selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using device: MPS (Apple Silicon Acceleration)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: CPU\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS & DATA LOADING\n",
    "# ==========================================\n",
    "def load_video_clip(path, num_frames=16, resize=(112, 112)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.zeros(3, num_frames, resize[0], resize[1])\n",
    "\n",
    "    indices = np.linspace(0, len(frames) - 1, num_frames).astype(int)\n",
    "    sampled_frames = np.array([frames[i] for i in indices])\n",
    "\n",
    "    tensor = torch.from_numpy(sampled_frames).permute(3, 0, 1, 2).float() / 255.0\n",
    "    mean = torch.tensor([0.43216, 0.394666, 0.37645]).view(3, 1, 1, 1)\n",
    "    std = torch.tensor([0.22803, 0.22145, 0.216989]).view(3, 1, 1, 1)\n",
    "    tensor = (tensor - mean) / std\n",
    "    return tensor\n",
    "\n",
    "def get_data_splits():\n",
    "    print(\"Processing CSV Data...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH).dropna(subset=['pitch_class', 'zone', 'plate_x', 'plate_z'])\n",
    "    df_test = pd.read_csv(TEST_FEATS_PATH)\n",
    "\n",
    "    phy_cols = [\n",
    "        'release_speed', 'effective_speed', 'release_spin_rate',\n",
    "        'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "        'pfx_x', 'pfx_z', 'sz_top', 'sz_bot'\n",
    "    ]\n",
    "    \n",
    "    for col in ['stand', 'p_throws']:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([df_train[col], df_test[col]]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        phy_cols.append(col)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_train[phy_cols] = scaler.fit_transform(df_train[phy_cols].fillna(0))\n",
    "    df_test[phy_cols] = scaler.transform(df_test[phy_cols].fillna(0))\n",
    "\n",
    "    class_map = {'strike': 1, 'ball': 0}\n",
    "    df_train['label_class'] = df_train['pitch_class'].map(class_map)\n",
    "    \n",
    "    zones = sorted(df_train['zone'].unique())\n",
    "    zone_map = {z: i for i, z in enumerate(zones)}\n",
    "    idx_to_zone = {i: z for z, i in zone_map.items()}\n",
    "    df_train['label_zone'] = df_train['zone'].map(zone_map)\n",
    "\n",
    "    train_idx, val_idx = train_test_split(df_train.index, test_size=0.15, random_state=CONFIG['seed'])\n",
    "    \n",
    "    return {\n",
    "        'train': df_train.loc[train_idx],\n",
    "        'val': df_train.loc[val_idx],\n",
    "        'test': df_test,\n",
    "        'phy_cols': phy_cols,\n",
    "        'idx_to_zone': idx_to_zone,\n",
    "        'num_zones': len(zones)\n",
    "    }\n",
    "\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, df, video_dir, phy_cols, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.video_dir = video_dir\n",
    "        self.phy_cols = phy_cols\n",
    "        self.mode = mode\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        physics_vec = torch.tensor(row[self.phy_cols].values.astype(np.float32))\n",
    "        vid_path = os.path.join(self.video_dir, row['file_name'])\n",
    "        video_tensor = load_video_clip(vid_path, num_frames=CONFIG['frames'], resize=(CONFIG['img_size'], CONFIG['img_size']))\n",
    "        if self.mode == 'test': return video_tensor, physics_vec\n",
    "        else: return video_tensor, physics_vec, torch.tensor(row['label_class'], dtype=torch.float).unsqueeze(0), torch.tensor(row['label_zone'], dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "class PitchHybridModel(nn.Module):\n",
    "    def __init__(self, physics_dim, num_zones):\n",
    "        super(PitchHybridModel, self).__init__()\n",
    "        \n",
    "        weights = R2Plus1D_18_Weights.DEFAULT\n",
    "        self.video_backbone = models.video.r2plus1d_18(weights=weights)\n",
    "        \n",
    "        vid_out_dim = self.video_backbone.fc.in_features\n",
    "        self.video_backbone.fc = nn.Identity() \n",
    "        \n",
    "        self.video_fc = nn.Sequential(\n",
    "            nn.Linear(vid_out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.physics_net = nn.Sequential(\n",
    "            nn.Linear(physics_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        combined_dim = 256 + 128\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.head_class = nn.Linear(256, 1)\n",
    "        self.head_zone = nn.Linear(256, num_zones)\n",
    "        \n",
    "    def forward(self, video, physics):\n",
    "        v_feat = self.video_backbone(video)\n",
    "        v_feat = self.video_fc(v_feat)\n",
    "        p_feat = self.physics_net(physics)\n",
    "        combined = torch.cat((v_feat, p_feat), dim=1)\n",
    "        fused = self.fusion_layer(combined)\n",
    "        return self.head_class(fused), self.head_zone(fused)\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN PIPELINE\n",
    "# ==========================================\n",
    "def run_pipeline():\n",
    "    data = get_data_splits()\n",
    "    model = PitchHybridModel(physics_dim=len(data['phy_cols']), num_zones=data['num_zones']).to(device)\n",
    "    \n",
    "    # --- STEP 1: LOAD WEIGHTS (Logic: Resume or Inference) ---\n",
    "    if CONFIG['resume_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"\\n[INFO] Found checkpoint at {MODEL_SAVE_PATH}. Loading weights...\")\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "            print(\"[INFO] Weights loaded successfully! Continuing from best model.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not load weights: {e}. Starting from scratch.\")\n",
    "    else:\n",
    "        if CONFIG['resume_checkpoint']:\n",
    "            print(f\"\\n[INFO] No checkpoint found at {MODEL_SAVE_PATH}. Training from scratch.\")\n",
    "\n",
    "    # --- STEP 2: TRAINING LOOP (Optional) ---\n",
    "    if CONFIG['train_model']:\n",
    "        train_ds = HybridDataset(data['train'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        val_ds = HybridDataset(data['val'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
    "        crit_c = nn.BCEWithLogitsLoss()\n",
    "        crit_z = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # best_val_loss = float('inf') \n",
    "        best_score = 0.0\n",
    "        \n",
    "        print(f\"\\n--- Starting Training ({CONFIG['epochs']} epochs) ---\")\n",
    "        \n",
    "        for epoch in range(CONFIG['epochs']):\n",
    "            model.train()\n",
    "            train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\", leave=True)\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            for vid, phy, lc, lz in train_loop:\n",
    "                vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out_c, out_z = model(vid, phy)\n",
    "                loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item()\n",
    "                train_loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            acc_c_num, acc_z_num, total = 0, 0, 0\n",
    "            \n",
    "            print(\"Validating...\")\n",
    "            with torch.no_grad():\n",
    "                for vid, phy, lc, lz in tqdm(val_loader, desc=\"Val\"):\n",
    "                    vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                    out_c, out_z = model(vid, phy)\n",
    "                    \n",
    "                    batch_loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                    val_loss += batch_loss.item()\n",
    "                    \n",
    "                    pred_c = (torch.sigmoid(out_c) > 0.5).float()\n",
    "                    acc_c_num += (pred_c == lc).sum().item()\n",
    "                    pred_z = torch.argmax(out_z, dim=1)\n",
    "                    acc_z_num += (pred_z == lz).sum().item()\n",
    "                    total += lc.size(0)\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            current_class_acc = acc_c_num / total\n",
    "            current_zone_acc = acc_z_num / total\n",
    "            \n",
    "            # Save Best Model\n",
    "            # if avg_val_loss < best_val_loss:\n",
    "            #     best_val_loss = avg_val_loss\n",
    "            #     torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            #     print(f\"Saved New Best Model to {MODEL_SAVE_PATH}!\")\n",
    "            # print(\"-\" * 50)\n",
    "            # ... inside the validation loop ...\n",
    "            \n",
    "            \n",
    "            \n",
    "            # CALCULATE KAGGLE SCORE\n",
    "            # Rule: 0.7 * PitchClass + 0.3 * Zone\n",
    "            current_score = (0.7 * current_class_acc) + (0.3 * current_zone_acc)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} | Loss: {avg_val_loss:.4f} | Class Acc: {current_class_acc:.3f} | Zone Acc: {current_zone_acc:.3f} | Score: {current_score:.4f}\")\n",
    "            \n",
    "            # SAVE IF SCORE IMPROVES (Ignore Loss)\n",
    "            # Initialize best_score = 0.0 at the start of the function instead of best_val_loss\n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "                print(f\"Saved New Best Model (Score: {best_score:.4f}) to {MODEL_SAVE_PATH}!\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # --- STEP 3: INFERENCE ---\n",
    "    print(\"\\n--- Generating Submission ---\")\n",
    "    \n",
    "    # Ensure we use the best weights found (either from loaded file or recent training)\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "        print(\"Loaded best model weights for inference.\")\n",
    "\n",
    "    test_ds = HybridDataset(data['test'], TEST_VIDEO_DIR, data['phy_cols'], mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval()\n",
    "    final_classes = []\n",
    "    final_zones = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vid, phy in tqdm(test_loader, desc=\"Inference\"):\n",
    "            vid, phy = vid.to(device), phy.to(device)\n",
    "            out_c, out_z = model(vid, phy)\n",
    "            \n",
    "            c_probs = torch.sigmoid(out_c).cpu().numpy().flatten()\n",
    "            z_idxs = torch.argmax(out_z, dim=1).cpu().numpy().flatten()\n",
    "            \n",
    "            final_classes.extend(['strike' if p > 0.5 else 'ball' for p in c_probs])\n",
    "            final_zones.extend([data['idx_to_zone'][z] for z in z_idxs])\n",
    "            \n",
    "    df_sub = pd.DataFrame({'file_name': data['test']['file_name'], 'pitch_class': final_classes, 'zone': final_zones})\n",
    "    \n",
    "    if os.path.exists(SAMPLE_SUB_PATH):\n",
    "        template = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        df_sub = template[['file_name']].merge(df_sub, on='file_name', how='left')\n",
    "        df_sub['pitch_class'] = df_sub['pitch_class'].fillna('ball')\n",
    "        df_sub['zone'] = df_sub['zone'].fillna(14).astype(int)\n",
    "\n",
    "    df_sub.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"Submission Saved to {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae1a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Processing CSV Data...\n",
      "\n",
      "[INFO] Found checkpoint at best_pitch_model.pth. Loading weights...\n",
      "[INFO] Calculating Baseline Score of loaded model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [02:16<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Resuming with Baseline Score: 0.6228 (Class: 0.724, Zone: 0.386)\n",
      "\n",
      "--- Starting Training (10 new epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 319/319 [1:24:14<00:00, 15.84s/it, loss=0.245]\n",
      "Validating: 100%|██████████| 57/57 [02:03<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.4239 | Class Acc: 0.710 | Zone Acc: 0.390 | SCORE: 0.6140\n",
      " ... No improvement (Best: 0.6228)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 319/319 [3:17:33<00:00, 37.16s/it, loss=0.288]    \n",
      "Validating: 100%|██████████| 57/57 [02:19<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 3.5017 | Class Acc: 0.687 | Zone Acc: 0.361 | SCORE: 0.5890\n",
      " ... No improvement (Best: 0.6228)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 319/319 [9:08:12<00:00, 103.11s/it, loss=0.382]   \n",
      "Validating: 100%|██████████| 57/57 [02:12<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 3.3565 | Class Acc: 0.709 | Zone Acc: 0.368 | SCORE: 0.6066\n",
      " ... No improvement (Best: 0.6228)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  88%|████████▊ | 282/319 [10:57:05<1:26:12, 139.81s/it, loss=0.175]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 315\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmission Saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 261\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m     loss \u001b[38;5;241m=\u001b[39m crit_c(out_c, lc) \u001b[38;5;241m+\u001b[39m crit_z(out_z, lz)\n\u001b[1;32m    260\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 261\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     train_loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Use Helper Function for Validation\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adamw.py:405\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    402\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m device \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    409\u001b[0m device \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# score: 0.61080\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models.video import R2Plus1D_18_Weights \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. FILE PATHS\n",
    "# ==========================================\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATS_PATH = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "SAMPLE_SUB_PATH = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "OUTPUT_PATH = \"submission_hybrid_final_gemini_lower_lr5e6.csv\"\n",
    "MODEL_SAVE_PATH = \"best_pitch_model.pth\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'epochs': 10,         # Number of NEW epochs to run\n",
    "    'batch_size': 16,  \n",
    "    'lr': 5e-5,\n",
    "    'frames': 16,\n",
    "    'img_size': 112,\n",
    "    'hidden_dim': 256,\n",
    "    \n",
    "    'resume_checkpoint': True, # Set to True to load previous best\n",
    "    'train_model': True\n",
    "}\n",
    "\n",
    "# Device Selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS & DATA LOADING\n",
    "# ==========================================\n",
    "def load_video_clip(path, num_frames=16, resize=(112, 112)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.zeros(3, num_frames, resize[0], resize[1])\n",
    "\n",
    "    indices = np.linspace(0, len(frames) - 1, num_frames).astype(int)\n",
    "    sampled_frames = np.array([frames[i] for i in indices])\n",
    "\n",
    "    tensor = torch.from_numpy(sampled_frames).permute(3, 0, 1, 2).float() / 255.0\n",
    "    mean = torch.tensor([0.43216, 0.394666, 0.37645]).view(3, 1, 1, 1)\n",
    "    std = torch.tensor([0.22803, 0.22145, 0.216989]).view(3, 1, 1, 1)\n",
    "    tensor = (tensor - mean) / std\n",
    "    return tensor\n",
    "\n",
    "def get_data_splits():\n",
    "    print(\"Processing CSV Data...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH).dropna(subset=['pitch_class', 'zone', 'plate_x', 'plate_z'])\n",
    "    df_test = pd.read_csv(TEST_FEATS_PATH)\n",
    "\n",
    "    phy_cols = [\n",
    "        'release_speed', 'effective_speed', 'release_spin_rate',\n",
    "        'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "        'pfx_x', 'pfx_z', 'sz_top', 'sz_bot'\n",
    "    ]\n",
    "    \n",
    "    for col in ['stand', 'p_throws']:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([df_train[col], df_test[col]]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        phy_cols.append(col)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_train[phy_cols] = scaler.fit_transform(df_train[phy_cols].fillna(0))\n",
    "    df_test[phy_cols] = scaler.transform(df_test[phy_cols].fillna(0))\n",
    "\n",
    "    class_map = {'strike': 1, 'ball': 0}\n",
    "    df_train['label_class'] = df_train['pitch_class'].map(class_map)\n",
    "    \n",
    "    zones = sorted(df_train['zone'].unique())\n",
    "    zone_map = {z: i for i, z in enumerate(zones)}\n",
    "    idx_to_zone = {i: z for z, i in zone_map.items()}\n",
    "    df_train['label_zone'] = df_train['zone'].map(zone_map)\n",
    "\n",
    "    train_idx, val_idx = train_test_split(df_train.index, test_size=0.15, random_state=CONFIG['seed'])\n",
    "    \n",
    "    return {\n",
    "        'train': df_train.loc[train_idx],\n",
    "        'val': df_train.loc[val_idx],\n",
    "        'test': df_test,\n",
    "        'phy_cols': phy_cols,\n",
    "        'idx_to_zone': idx_to_zone,\n",
    "        'num_zones': len(zones)\n",
    "    }\n",
    "\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, df, video_dir, phy_cols, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.video_dir = video_dir\n",
    "        self.phy_cols = phy_cols\n",
    "        self.mode = mode\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        physics_vec = torch.tensor(row[self.phy_cols].values.astype(np.float32))\n",
    "        vid_path = os.path.join(self.video_dir, row['file_name'])\n",
    "        video_tensor = load_video_clip(vid_path, num_frames=CONFIG['frames'], resize=(CONFIG['img_size'], CONFIG['img_size']))\n",
    "        if self.mode == 'test': return video_tensor, physics_vec\n",
    "        else: return video_tensor, physics_vec, torch.tensor(row['label_class'], dtype=torch.float).unsqueeze(0), torch.tensor(row['label_zone'], dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "class PitchHybridModel(nn.Module):\n",
    "    def __init__(self, physics_dim, num_zones):\n",
    "        super(PitchHybridModel, self).__init__()\n",
    "        \n",
    "        weights = R2Plus1D_18_Weights.DEFAULT\n",
    "        self.video_backbone = models.video.r2plus1d_18(weights=weights)\n",
    "        \n",
    "        vid_out_dim = self.video_backbone.fc.in_features\n",
    "        self.video_backbone.fc = nn.Identity() \n",
    "        \n",
    "        self.video_fc = nn.Sequential(\n",
    "            nn.Linear(vid_out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.physics_net = nn.Sequential(\n",
    "            nn.Linear(physics_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        combined_dim = 256 + 128\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.head_class = nn.Linear(256, 1)\n",
    "        self.head_zone = nn.Linear(256, num_zones)\n",
    "        \n",
    "    def forward(self, video, physics):\n",
    "        v_feat = self.video_backbone(video)\n",
    "        v_feat = self.video_fc(v_feat)\n",
    "        p_feat = self.physics_net(physics)\n",
    "        combined = torch.cat((v_feat, p_feat), dim=1)\n",
    "        fused = self.fusion_layer(combined)\n",
    "        return self.head_class(fused), self.head_zone(fused)\n",
    "\n",
    "# ==========================================\n",
    "# 5. VALIDATION HELPER (Used for Baseline & Loop)\n",
    "# ==========================================\n",
    "def validate(model, val_loader, crit_c, crit_z):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    acc_c_num, acc_z_num, total = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vid, phy, lc, lz in tqdm(val_loader, desc=\"Validating\"):\n",
    "            vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "            out_c, out_z = model(vid, phy)\n",
    "            \n",
    "            batch_loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "            val_loss += batch_loss.item()\n",
    "            \n",
    "            pred_c = (torch.sigmoid(out_c) > 0.5).float()\n",
    "            acc_c_num += (pred_c == lc).sum().item()\n",
    "            pred_z = torch.argmax(out_z, dim=1)\n",
    "            acc_z_num += (pred_z == lz).sum().item()\n",
    "            total += lc.size(0)\n",
    "    \n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    acc_c = acc_c_num / total\n",
    "    acc_z = acc_z_num / total\n",
    "    score = (0.7 * acc_c) + (0.3 * acc_z)\n",
    "    \n",
    "    return avg_loss, acc_c, acc_z, score\n",
    "\n",
    "# ==========================================\n",
    "# 6. MAIN PIPELINE\n",
    "# ==========================================\n",
    "def run_pipeline():\n",
    "    data = get_data_splits()\n",
    "    model = PitchHybridModel(physics_dim=len(data['phy_cols']), num_zones=data['num_zones']).to(device)\n",
    "    \n",
    "    # Loaders\n",
    "    train_ds = HybridDataset(data['train'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "    val_ds = HybridDataset(data['val'], TRAIN_VIDEO_DIR, data['phy_cols'], mode='train')\n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    crit_c = nn.BCEWithLogitsLoss()\n",
    "    crit_z = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "    # --- RESUME LOGIC (FIXED) ---\n",
    "    best_score = 0.0\n",
    "    \n",
    "    if CONFIG['resume_checkpoint'] and os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"\\n[INFO] Found checkpoint at {MODEL_SAVE_PATH}. Loading weights...\")\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "        \n",
    "        print(\"[INFO] Calculating Baseline Score of loaded model...\")\n",
    "        _, start_c_acc, start_z_acc, start_score = validate(model, val_loader, crit_c, crit_z)\n",
    "        \n",
    "        best_score = start_score\n",
    "        print(f\"[INFO] Resuming with Baseline Score: {best_score:.4f} (Class: {start_c_acc:.3f}, Zone: {start_z_acc:.3f})\")\n",
    "    else:\n",
    "        print(\"[INFO] Starting from scratch (Best Score = 0.0)\")\n",
    "\n",
    "    # --- TRAINING ---\n",
    "    if CONFIG['train_model']:\n",
    "        print(f\"\\n--- Starting Training ({CONFIG['epochs']} new epochs) ---\")\n",
    "        \n",
    "        for epoch in range(CONFIG['epochs']):\n",
    "            model.train()\n",
    "            train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\", leave=True)\n",
    "            \n",
    "            for vid, phy, lc, lz in train_loop:\n",
    "                vid, phy, lc, lz = vid.to(device), phy.to(device), lc.to(device), lz.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out_c, out_z = model(vid, phy)\n",
    "                loss = crit_c(out_c, lc) + crit_z(out_z, lz)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            # Use Helper Function for Validation\n",
    "            val_loss, val_c, val_z, val_score = validate(model, val_loader, crit_c, crit_z)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} | Loss: {val_loss:.4f} | Class Acc: {val_c:.3f} | Zone Acc: {val_z:.3f} | SCORE: {val_score:.4f}\")\n",
    "            \n",
    "            # Save if BETTER than current best (Loaded or New)\n",
    "            if val_score > best_score:\n",
    "                print(f\" >>> IMPROVEMENT ({best_score:.4f} -> {val_score:.4f}). Saving Model...\")\n",
    "                best_score = val_score\n",
    "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            else:\n",
    "                print(f\" ... No improvement (Best: {best_score:.4f})\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # --- INFERENCE ---\n",
    "    print(\"\\n--- Generating Submission ---\")\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(\"Loading BEST model for prediction...\")\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "\n",
    "    test_ds = HybridDataset(data['test'], TEST_VIDEO_DIR, data['phy_cols'], mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval()\n",
    "    final_classes = []\n",
    "    final_zones = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vid, phy in tqdm(test_loader, desc=\"Inference\"):\n",
    "            vid, phy = vid.to(device), phy.to(device)\n",
    "            out_c, out_z = model(vid, phy)\n",
    "            \n",
    "            c_probs = torch.sigmoid(out_c).cpu().numpy().flatten()\n",
    "            z_idxs = torch.argmax(out_z, dim=1).cpu().numpy().flatten()\n",
    "            123\n",
    "            final_classes.extend(['strike' if p > 0.5 else 'ball' for p in c_probs])\n",
    "            final_zones.extend([data['idx_to_zone'][z] for z in z_idxs])\n",
    "            \n",
    "    df_sub = pd.DataFrame({'file_name': data['test']['file_name'], 'pitch_class': final_classes, 'zone': final_zones})\n",
    "    \n",
    "    if os.path.exists(SAMPLE_SUB_PATH):\n",
    "        template = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        df_sub = template[['file_name']].merge(df_sub, on='file_name', how='left')\n",
    "        df_sub['pitch_class'] = df_sub['pitch_class'].fillna('ball')\n",
    "        df_sub['zone'] = df_sub['zone'].fillna(14).astype(int)\n",
    "\n",
    "    df_sub.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"Submission Saved to {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
