{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6000, 18)\n",
      "Test shape: (4000, 14)\n",
      "Template shape: (4000, 3)\n",
      "\n",
      "Training pitch_class model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(median_val, inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_full[col].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/3y/x88zbv4n0b18f8cg1qcv1my40000gn/T/ipykernel_90696/1876240585.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_full[col].fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training zone model...\n",
      "\n",
      "Validation pitch_class accuracy: 0.5433\n",
      "Validation zone accuracy:       0.1925\n",
      "Validation competition score:   0.4381\n",
      "\n",
      "Retraining pitch_class model on full training data...\n",
      "Retraining zone model on full training data...\n",
      "\n",
      "Predicting on test set...\n",
      "\n",
      "Submission file written to: submission_baseball_tabular_baseline.csv\n",
      "     file_name pitch_class  zone\n",
      "0   pitch2.mp4        ball    12\n",
      "1   pitch6.mp4      strike    11\n",
      "2   pitch7.mp4        ball    12\n",
      "3   pitch9.mp4      strike     6\n",
      "4  pitch10.mp4        ball    12\n"
     ]
    }
   ],
   "source": [
    "# 0.45895\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths (update if needed)\n",
    "# ---------------------------------------------------------------------\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATURES_CSV = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "\n",
    "TEST_TEMPLATE_CSV = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "\n",
    "# (Videos are not used in this baseline, but paths are here for reference)\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------------------------------------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_FEATURES_CSV)\n",
    "template_df = pd.read_csv(TEST_TEMPLATE_CSV)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Template shape:\", template_df.shape)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Features and targets\n",
    "# ---------------------------------------------------------------------\n",
    "numeric_features = [\n",
    "    \"sz_top\",\n",
    "    \"sz_bot\",\n",
    "    \"release_speed\",\n",
    "    \"effective_speed\",\n",
    "    \"release_spin_rate\",\n",
    "    \"release_pos_x\",\n",
    "    \"release_pos_y\",\n",
    "    \"release_pos_z\",\n",
    "    \"release_extension\",\n",
    "    \"pfx_x\",\n",
    "    \"pfx_z\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"stand\",\n",
    "    \"p_throws\",\n",
    "]\n",
    "\n",
    "# X and y for train\n",
    "X_train_full = train_df[numeric_features + categorical_features].copy()\n",
    "y_class = train_df[\"pitch_class\"].copy()  # \"strike\" or \"ball\"\n",
    "y_zone = train_df[\"zone\"].copy().astype(int)  # 1 to 14\n",
    "\n",
    "# X for test\n",
    "X_test_full = test_df[numeric_features + categorical_features].copy()\n",
    "\n",
    "# Basic cleaning: fill missing numeric with median, categorical with \"Unknown\"\n",
    "for col in numeric_features:\n",
    "    median_val = X_train_full[col].median()\n",
    "    X_train_full[col].fillna(median_val, inplace=True)\n",
    "    X_test_full[col].fillna(median_val, inplace=True)\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train_full[col].fillna(\"Unknown\", inplace=True)\n",
    "    X_test_full[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Preprocessing and model definitions\n",
    "# ---------------------------------------------------------------------\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def make_pipeline(random_state=42, n_estimators=300, max_depth=None):\n",
    "    \"\"\"Return a fresh pipeline (preprocess + RandomForest).\"\"\"\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        class_weight=None,\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Train validation split to get a sense of performance\n",
    "# ---------------------------------------------------------------------\n",
    "X_tr, X_val, y_class_tr, y_class_val, y_zone_tr, y_zone_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_class,\n",
    "    y_zone,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_class,  # stratify on pitch class to keep class balance\n",
    ")\n",
    "\n",
    "# Pipelines for each target (fresh preprocess for each)\n",
    "pipe_class = make_pipeline(random_state=42, n_estimators=300, max_depth=None)\n",
    "pipe_zone = make_pipeline(random_state=43, n_estimators=400, max_depth=None)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Train models\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\nTraining pitch_class model...\")\n",
    "pipe_class.fit(X_tr, y_class_tr)\n",
    "\n",
    "print(\"Training zone model...\")\n",
    "pipe_zone.fit(X_tr, y_zone_tr)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Validation metrics (simple check, not used in Kaggle submission)\n",
    "# ---------------------------------------------------------------------\n",
    "y_class_val_pred = pipe_class.predict(X_val)\n",
    "y_zone_val_pred = pipe_zone.predict(X_val)\n",
    "\n",
    "acc_class = accuracy_score(y_class_val, y_class_val_pred)\n",
    "acc_zone = accuracy_score(y_zone_val, y_zone_val_pred)\n",
    "overall_score = 0.7 * acc_class + 0.3 * acc_zone\n",
    "\n",
    "print(f\"\\nValidation pitch_class accuracy: {acc_class:.4f}\")\n",
    "print(f\"Validation zone accuracy:       {acc_zone:.4f}\")\n",
    "print(f\"Validation competition score:   {overall_score:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Retrain on full training data for final models (optional but better)\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\nRetraining pitch_class model on full training data...\")\n",
    "pipe_class_full = make_pipeline(random_state=42, n_estimators=300, max_depth=None)\n",
    "pipe_class_full.fit(X_train_full, y_class)\n",
    "\n",
    "print(\"Retraining zone model on full training data...\")\n",
    "pipe_zone_full = make_pipeline(random_state=43, n_estimators=400, max_depth=None)\n",
    "pipe_zone_full.fit(X_train_full, y_zone)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Predict on test data\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\nPredicting on test set...\")\n",
    "test_pitch_class_pred = pipe_class_full.predict(X_test_full)\n",
    "test_zone_pred = pipe_zone_full.predict(X_test_full)\n",
    "\n",
    "# Ensure zone is integer from 1 to 14\n",
    "test_zone_pred = test_zone_pred.astype(int)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Build submission based on template file\n",
    "# ---------------------------------------------------------------------\n",
    "submission = template_df.copy()\n",
    "\n",
    "# Join predictions by file_name, to be safe with order\n",
    "pred_df = pd.DataFrame(\n",
    "    {\n",
    "        \"file_name\": test_df[\"file_name\"],\n",
    "        \"pitch_class\": test_pitch_class_pred,\n",
    "        \"zone\": test_zone_pred,\n",
    "    }\n",
    ")\n",
    "\n",
    "submission = submission.drop(columns=[\"pitch_class\", \"zone\"], errors=\"ignore\")\n",
    "submission = submission.merge(pred_df, on=\"file_name\", how=\"left\")\n",
    "\n",
    "# Safety checks\n",
    "missing_rows = submission[\"pitch_class\"].isna().sum() + submission[\"zone\"].isna().sum()\n",
    "if missing_rows > 0:\n",
    "    print(f\"Warning: there are {missing_rows} missing predictions in the submission.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Save submission\n",
    "# ---------------------------------------------------------------------\n",
    "OUTPUT_SUBMISSION_PATH = \"submission_baseball_tabular_baseline.csv\"\n",
    "submission.to_csv(OUTPUT_SUBMISSION_PATH, index=False)\n",
    "print(f\"\\nSubmission file written to: {OUTPUT_SUBMISSION_PATH}\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Train shape: (6000, 18)\n",
      "Test shape: (4000, 14)\n",
      "Template shape: (4000, 3)\n",
      "Tabular dim: 15\n",
      "Train size: 4800\n",
      "Val size: 1200\n",
      "\n",
      "Training with validation split...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [04:44<00:00,  4.22it/s]\n",
      "100%|██████████| 300/300 [00:45<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2957 | Class Acc: 0.5858 | Zone Acc: 0.1567 | Score: 0.4571\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [04:25<00:00,  4.53it/s]\n",
      "100%|██████████| 300/300 [01:23<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2301 | Class Acc: 0.5550 | Zone Acc: 0.1700 | Score: 0.4395\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [06:03<00:00,  3.30it/s]\n",
      "100%|██████████| 300/300 [01:39<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1986 | Class Acc: 0.5642 | Zone Acc: 0.1933 | Score: 0.4529\n",
      "\n",
      "\n",
      "Training on full dataset...\n",
      "\n",
      "Full Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [08:09<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2910\n",
      "\n",
      "Full Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [07:54<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2292\n",
      "\n",
      "Full Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [06:59<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2139\n",
      "\n",
      "Full Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [06:43<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2024\n",
      "\n",
      "Full Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [05:01<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:43<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_baseball_hybrid_macos.csv\n",
      "     file_name  pitch_class_x  zone_x pitch_class_y  zone_y\n",
      "0   pitch2.mp4            NaN     NaN          ball      11\n",
      "1   pitch6.mp4            NaN     NaN        strike      11\n",
      "2   pitch7.mp4            NaN     NaN          ball      11\n",
      "3   pitch9.mp4            NaN     NaN        strike      11\n",
      "4  pitch10.mp4            NaN     NaN          ball      11\n"
     ]
    }
   ],
   "source": [
    "# 0.46890\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Device selection (macOS friendly)\n",
    "# =========================================================\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Paths\n",
    "# =========================================================\n",
    "\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATURES_CSV = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "\n",
    "TRAIN_VIDEO_DIR = os.path.join(BASE_DIR, \"train_trimmed\")\n",
    "TEST_VIDEO_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "TEST_TEMPLATE_CSV = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "\n",
    "OUTPUT_SUBMISSION = \"submission_baseball_hybrid_macos.csv\"\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Settings optimized for macOS (lower memory)\n",
    "# =========================================================\n",
    "\n",
    "SEED = 42\n",
    "NUM_FRAMES = 6         # slightly lower to avoid RAM issues\n",
    "IMG_SIZE = 112\n",
    "BATCH_SIZE = 4         # smaller batches recommended on mac\n",
    "EPOCHS_VAL = 3\n",
    "EPOCHS_FULL = 5\n",
    "LR = 1e-4\n",
    "WEIGHT_CLASS = 0.7\n",
    "WEIGHT_ZONE = 0.3\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Reproducibility\n",
    "# =========================================================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Load Data\n",
    "# =========================================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_FEATURES_CSV)\n",
    "template_df = pd.read_csv(TEST_TEMPLATE_CSV)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Template shape:\", template_df.shape)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Tabular preprocessing\n",
    "# =========================================================\n",
    "\n",
    "numeric_features = [\n",
    "    \"sz_top\", \"sz_bot\", \"release_speed\", \"effective_speed\",\n",
    "    \"release_spin_rate\", \"release_pos_x\", \"release_pos_y\",\n",
    "    \"release_pos_z\", \"release_extension\", \"pfx_x\", \"pfx_z\",\n",
    "]\n",
    "\n",
    "categorical_features = [\"stand\", \"p_throws\"]\n",
    "\n",
    "X_train_tab_raw = train_df[numeric_features + categorical_features].copy()\n",
    "X_test_tab_raw  = test_df[numeric_features + categorical_features].copy()\n",
    "\n",
    "# Fill missing values safely\n",
    "for col in numeric_features:\n",
    "    median_val = X_train_tab_raw[col].median()\n",
    "    X_train_tab_raw[col] = X_train_tab_raw[col].fillna(median_val)\n",
    "    X_test_tab_raw[col] = X_test_tab_raw[col].fillna(median_val)\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train_tab_raw[col] = X_train_tab_raw[col].fillna(\"Unknown\")\n",
    "    X_test_tab_raw[col] = X_test_tab_raw[col].fillna(\"Unknown\")\n",
    "\n",
    "# Prepare transformer\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_tab = preprocess.fit_transform(X_train_tab_raw)\n",
    "X_test_tab = preprocess.transform(X_test_tab_raw)\n",
    "\n",
    "# ensure numpy arrays\n",
    "X_train_tab = np.asarray(X_train_tab, dtype=np.float32)\n",
    "X_test_tab = np.asarray(X_test_tab, dtype=np.float32)\n",
    "\n",
    "tabular_dim = X_train_tab.shape[1]\n",
    "print(\"Tabular dim:\", tabular_dim)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Targets\n",
    "# =========================================================\n",
    "\n",
    "class_to_idx = {\"ball\": 0, \"strike\": 1}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "y_class = np.array([class_to_idx[c] for c in train_df[\"pitch_class\"]], dtype=np.int64)\n",
    "y_zone  = train_df[\"zone\"].values.astype(np.int64) - 1   # 0..13\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Train/Val split indices\n",
    "# =========================================================\n",
    "\n",
    "indices = np.arange(len(train_df))\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=SEED, stratify=y_class\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_idx)}\")\n",
    "print(f\"Val size: {len(val_idx)}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Video loader (macOS safe)\n",
    "# =========================================================\n",
    "\n",
    "def load_video_frames(path, num_frames=NUM_FRAMES, img_size=IMG_SIZE):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        return np.zeros((num_frames, 3, img_size, img_size), dtype=\"float32\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (img_size, img_size))\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        frames = [np.zeros((img_size, img_size, 3), dtype=np.uint8)] * num_frames\n",
    "\n",
    "    idxs = np.linspace(0, len(frames)-1, num_frames).astype(int)\n",
    "    sampled = [frames[i] for i in idxs]\n",
    "\n",
    "    arr = np.stack(sampled).astype(\"float32\") / 255.0\n",
    "    arr = np.transpose(arr, (0, 3, 1, 2))\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Dataset\n",
    "# =========================================================\n",
    "\n",
    "class PitchDataset(Dataset):\n",
    "    def __init__(self, df, tab, video_dir, indices, y_class=None, y_zone=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.tab = tab\n",
    "        self.video_dir = video_dir\n",
    "        self.indices = indices\n",
    "        self.y_class = y_class\n",
    "        self.y_zone = y_zone\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # ImageNet normalization\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "        self.std  = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        row = self.df.iloc[real_idx]\n",
    "        file_name = row[\"file_name\"]\n",
    "        path = os.path.join(self.video_dir, file_name)\n",
    "\n",
    "        frames_np = load_video_frames(path)\n",
    "        frames = torch.from_numpy(frames_np)\n",
    "        frames = (frames - self.mean) / self.std\n",
    "\n",
    "        tab_tensor = torch.from_numpy(self.tab[real_idx].astype(\"float32\"))\n",
    "\n",
    "        if self.is_train:\n",
    "            c = torch.tensor(self.y_class[real_idx], dtype=torch.long)\n",
    "            z = torch.tensor(self.y_zone[real_idx], dtype=torch.long)\n",
    "            return frames, tab_tensor, c, z\n",
    "\n",
    "        else:\n",
    "            return frames, tab_tensor, file_name\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Model (unchanged)\n",
    "# =========================================================\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, tabular_dim, num_zones=14):\n",
    "        super().__init__()\n",
    "\n",
    "        res = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.cnn = nn.Sequential(*list(res.children())[:-1])  # remove final FC\n",
    "        video_dim = 512\n",
    "\n",
    "        self.tab_mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(video_dim + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256)\n",
    "        )\n",
    "\n",
    "        self.class_head = nn.Linear(256, 2)\n",
    "        self.zone_head  = nn.Linear(256, num_zones)\n",
    "\n",
    "    def forward(self, video, tab):\n",
    "        B, T, C, H, W = video.shape\n",
    "\n",
    "        # --- IMPORTANT FIX FOR macOS / MPS ---\n",
    "        # Flatten time dimension safely\n",
    "        video = video.reshape(B * T, C, H, W).contiguous()\n",
    "\n",
    "        # Make sure it's contiguous for CNN (ResNet has internal view ops)\n",
    "        video = video.contiguous()\n",
    "\n",
    "        # CNN\n",
    "        feat = self.cnn(video)  # (B*T, 512, 1, 1)\n",
    "\n",
    "        # Ensure the CNN output is contiguous before reshaping\n",
    "        feat = feat.contiguous()\n",
    "\n",
    "        # Reshape back to (B, T, 512)\n",
    "        feat = feat.reshape(B, T, -1).mean(dim=1)\n",
    "\n",
    "        # Tabular branch\n",
    "        tab_feat = self.tab_mlp(tab)\n",
    "\n",
    "        # Fusion\n",
    "        fused = torch.cat([feat, tab_feat], dim=1)\n",
    "        shared = self.shared(fused)\n",
    "\n",
    "        return self.class_head(shared), self.zone_head(shared)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Dataloaders (mac-safe)\n",
    "# =========================================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    PitchDataset(train_df, X_train_tab, TRAIN_VIDEO_DIR, train_idx, y_class, y_zone),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,       # macOS: must be 0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    PitchDataset(train_df, X_train_tab, TRAIN_VIDEO_DIR, val_idx, y_class, y_zone),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Train one epoch\n",
    "# =========================================================\n",
    "\n",
    "def train_one_epoch(model, loader, opt, c_loss, z_loss):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for frames, tab_vec, c, z in tqdm(loader):\n",
    "        frames = frames.to(device)\n",
    "        tab_vec = tab_vec.to(device)\n",
    "        c = c.to(device)\n",
    "        z = z.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        out_c, out_z = model(frames, tab_vec)\n",
    "\n",
    "        lc = c_loss(out_c, c)\n",
    "        lz = z_loss(out_z, z)\n",
    "        loss = WEIGHT_CLASS*lc + WEIGHT_ZONE*lz\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * frames.size(0)\n",
    "        total += frames.size(0)\n",
    "\n",
    "    return total_loss/total\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct_c, correct_z, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frames, tab_vec, c, z in tqdm(loader):\n",
    "            frames = frames.to(device)\n",
    "            tab_vec = tab_vec.to(device)\n",
    "            c = c.to(device)\n",
    "            z = z.to(device)\n",
    "\n",
    "            out_c, out_z = model(frames, tab_vec)\n",
    "\n",
    "            pc = out_c.argmax(1)\n",
    "            pz = out_z.argmax(1)\n",
    "\n",
    "            correct_c += (pc == c).sum().item()\n",
    "            correct_z += (pz == z).sum().item()\n",
    "            total += frames.size(0)\n",
    "\n",
    "    acc_c = correct_c / total\n",
    "    acc_z = correct_z / total\n",
    "    score = WEIGHT_CLASS*acc_c + WEIGHT_ZONE*acc_z\n",
    "    return acc_c, acc_z, score\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Stage 1: Train with val split\n",
    "# =========================================================\n",
    "\n",
    "model = HybridModel(tabular_dim).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=LR)\n",
    "c_loss = nn.CrossEntropyLoss()\n",
    "z_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nTraining with validation split...\\n\")\n",
    "for e in range(1, EPOCHS_VAL+1):\n",
    "    print(f\"Epoch {e}/{EPOCHS_VAL}\")\n",
    "    loss = train_one_epoch(model, train_loader, opt, c_loss, z_loss)\n",
    "    ac, az, sc = evaluate(model, val_loader)\n",
    "    print(f\"Loss: {loss:.4f} | Class Acc: {ac:.4f} | Zone Acc: {az:.4f} | Score: {sc:.4f}\\n\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Stage 2: Full training\n",
    "# =========================================================\n",
    "\n",
    "full_loader = DataLoader(\n",
    "    PitchDataset(train_df, X_train_tab, TRAIN_VIDEO_DIR, np.arange(len(train_df)), y_class, y_zone),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model_final = HybridModel(tabular_dim).to(device)\n",
    "opt2 = optim.Adam(model_final.parameters(), lr=LR)\n",
    "\n",
    "print(\"\\nTraining on full dataset...\\n\")\n",
    "for e in range(1, EPOCHS_FULL+1):\n",
    "    print(f\"Full Epoch {e}/{EPOCHS_FULL}\")\n",
    "    loss = train_one_epoch(model_final, full_loader, opt2, c_loss, z_loss)\n",
    "    print(f\"Loss: {loss:.4f}\\n\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Inference\n",
    "# =========================================================\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    PitchDataset(test_df, X_test_tab, TEST_VIDEO_DIR, np.arange(len(test_df)), is_train=False),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model_final.eval()\n",
    "\n",
    "file_names = []\n",
    "pred_class = []\n",
    "pred_zone = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for frames, tab_vec, names in tqdm(test_loader):\n",
    "        frames = frames.to(device)\n",
    "        tab_vec = tab_vec.to(device)\n",
    "\n",
    "        out_c, out_z = model_final(frames, tab_vec)\n",
    "\n",
    "        pc = out_c.argmax(1).cpu().numpy()\n",
    "        pz = out_z.argmax(1).cpu().numpy() + 1\n",
    "\n",
    "        file_names += list(names)\n",
    "        pred_class += [idx_to_class[i] for i in pc]\n",
    "        pred_zone += list(pz)\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"file_name\": file_names,\n",
    "    \"pitch_class\": pred_class,\n",
    "    \"zone\": pred_zone,\n",
    "})\n",
    "\n",
    "submission = template_df.merge(pred_df, on=\"file_name\", how=\"left\")\n",
    "submission.to_csv(OUTPUT_SUBMISSION, index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_SUBMISSION)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277aac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     file_name pitch_class  zone\n",
      "0   pitch2.mp4        ball    11\n",
      "1   pitch6.mp4      strike    11\n",
      "2   pitch7.mp4        ball    11\n",
      "3   pitch9.mp4      strike    11\n",
      "4  pitch10.mp4        ball    11\n"
     ]
    }
   ],
   "source": [
    "submission_clean = submission.copy()\n",
    "\n",
    "submission_clean = submission_clean[[\"file_name\", \"pitch_class_y\", \"zone_y\"]]\n",
    "\n",
    "# Rename to Kaggle-required format\n",
    "submission_clean = submission_clean.rename(columns={\n",
    "    \"pitch_class_y\": \"pitch_class\",\n",
    "    \"zone_y\": \"zone\"\n",
    "})\n",
    "\n",
    "# Save clean file\n",
    "submission_clean.to_csv(\"submission_final_2.csv\", index=False)\n",
    "\n",
    "print(submission_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00858fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be3488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6000, 18)\n",
      "Test shape: (4000, 14)\n",
      "Template shape: (4000, 3)\n",
      "\n",
      "Train columns: ['file_name', 'plate_x', 'plate_z', 'sz_top', 'sz_bot', 'release_speed', 'effective_speed', 'release_spin_rate', 'release_pos_x', 'release_pos_y', 'release_pos_z', 'release_extension', 'pfx_x', 'pfx_z', 'stand', 'p_throws', 'pitch_class', 'zone']\n",
      "Test columns: ['file_name', 'sz_top', 'sz_bot', 'release_speed', 'effective_speed', 'release_spin_rate', 'release_pos_x', 'release_pos_y', 'release_pos_z', 'release_extension', 'pfx_x', 'pfx_z', 'stand', 'p_throws']\n",
      "\n",
      "Using features:\n",
      " - sz_top\n",
      " - sz_bot\n",
      " - release_speed\n",
      " - effective_speed\n",
      " - release_spin_rate\n",
      " - release_pos_x\n",
      " - release_pos_y\n",
      " - release_pos_z\n",
      " - release_extension\n",
      " - pfx_x\n",
      " - pfx_z\n",
      " - sz_height\n",
      " - sz_center\n",
      " - break_mag\n",
      " - abs_pfx_x\n",
      " - abs_pfx_z\n",
      " - ext_speed\n",
      " - eff_ratio\n",
      " - stand_enc\n",
      " - p_throws_enc\n",
      " - same_side\n",
      "\n",
      "Train samples: 4800\n",
      "Validation samples: 1200\n",
      "\n",
      "Training XGBoost model for pitch_class...\n",
      "[0]\ttrain-logloss:0.69094\tval-logloss:0.69279\n",
      "[20]\ttrain-logloss:0.66016\tval-logloss:0.69013\n",
      "[40]\ttrain-logloss:0.63918\tval-logloss:0.68949\n",
      "[60]\ttrain-logloss:0.61933\tval-logloss:0.68859\n",
      "[74]\ttrain-logloss:0.60940\tval-logloss:0.68930\n",
      "\n",
      "Validation pitch_class accuracy: 0.5367\n",
      "\n",
      "Training XGBoost model for zone...\n",
      "[0]\ttrain-mlogloss:2.57131\tval-mlogloss:2.59887\n",
      "[20]\ttrain-mlogloss:1.99935\tval-mlogloss:2.46565\n",
      "[40]\ttrain-mlogloss:1.65224\tval-mlogloss:2.42288\n",
      "[60]\ttrain-mlogloss:1.40796\tval-mlogloss:2.41189\n",
      "[80]\ttrain-mlogloss:1.22676\tval-mlogloss:2.41259\n",
      "[97]\ttrain-mlogloss:1.09945\tval-mlogloss:2.42196\n",
      "\n",
      "Validation zone accuracy: 0.2042\n",
      "Validation combined score (0.7 * class + 0.3 * zone): 0.4369\n",
      "\n",
      "Retraining on full training set for final models...\n",
      "\n",
      "Predicting on test set...\n",
      "\n",
      "Saved submission to: submission_xgb_tabular_strikezone.csv\n",
      "     file_name pitch_class  zone\n",
      "0   pitch2.mp4        ball    12\n",
      "1   pitch6.mp4        ball    11\n",
      "2   pitch7.mp4        ball    11\n",
      "3   pitch9.mp4      strike     6\n",
      "4  pitch10.mp4        ball    12\n"
     ]
    }
   ],
   "source": [
    "# 0.44605\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# =========================================================\n",
    "# Paths\n",
    "# =========================================================\n",
    "\n",
    "BASE_DIR = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATURES_CSV = os.path.join(BASE_DIR, \"data\", \"test_features.csv\")\n",
    "TEMPLATE_CSV = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "\n",
    "OUTPUT_SUBMISSION = \"submission_xgb_tabular_strikezone.csv\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Load data\n",
    "# =========================================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_FEATURES_CSV)\n",
    "template_df = pd.read_csv(TEMPLATE_CSV)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Template shape:\", template_df.shape)\n",
    "\n",
    "# =========================================================\n",
    "# Basic sanity check on columns\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"Test columns:\", test_df.columns.tolist())\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Feature engineering\n",
    "# Only use features that exist in BOTH train_ground_truth and test_features\n",
    "# =========================================================\n",
    "\n",
    "base_numeric = [\n",
    "    \"sz_top\",\n",
    "    \"sz_bot\",\n",
    "    \"release_speed\",\n",
    "    \"effective_speed\",\n",
    "    \"release_spin_rate\",\n",
    "    \"release_pos_x\",\n",
    "    \"release_pos_y\",\n",
    "    \"release_pos_z\",\n",
    "    \"release_extension\",\n",
    "    \"pfx_x\",\n",
    "    \"pfx_z\",\n",
    "]\n",
    "\n",
    "categorical = [\"stand\", \"p_throws\"]\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    # Fill numeric missing values with median from train (we do this after computing medians)\n",
    "    pass\n",
    "\n",
    "# Compute medians from train for numeric columns\n",
    "medians = {col: train_df[col].median() for col in base_numeric}\n",
    "\n",
    "# Fill missing numeric values\n",
    "for col in base_numeric:\n",
    "    train_df[col] = train_df[col].fillna(medians[col])\n",
    "    test_df[col] = test_df[col].fillna(medians[col])\n",
    "\n",
    "# Fill categorical nulls with \"Unknown\"\n",
    "for col in categorical:\n",
    "    train_df[col] = train_df[col].fillna(\"Unknown\")\n",
    "    test_df[col] = test_df[col].fillna(\"Unknown\")\n",
    "\n",
    "# Derived numeric features (must be computable in both train and test)\n",
    "for df in [train_df, test_df]:\n",
    "    # Height of strike zone\n",
    "    df[\"sz_height\"] = df[\"sz_top\"] - df[\"sz_bot\"]\n",
    "    # Center of strike zone\n",
    "    df[\"sz_center\"] = 0.5 * (df[\"sz_top\"] + df[\"sz_bot\"])\n",
    "    # Break magnitude\n",
    "    df[\"break_mag\"] = np.sqrt(df[\"pfx_x\"] ** 2 + df[\"pfx_z\"] ** 2)\n",
    "    # Absolute break components\n",
    "    df[\"abs_pfx_x\"] = df[\"pfx_x\"].abs()\n",
    "    df[\"abs_pfx_z\"] = df[\"pfx_z\"].abs()\n",
    "    # Extension-speed interaction\n",
    "    df[\"ext_speed\"] = df[\"release_speed\"] * df[\"release_extension\"]\n",
    "    # Effective speed ratio (guard against div by zero)\n",
    "    safe_release_speed = df[\"release_speed\"].replace(0, medians[\"release_speed\"])\n",
    "    df[\"eff_ratio\"] = df[\"effective_speed\"] / safe_release_speed\n",
    "\n",
    "# Map categoricals manually: stand, p_throws\n",
    "# L -> 0, R -> 1, Unknown -> -1\n",
    "map_hand = {\"L\": 0, \"R\": 1}\n",
    "for df in [train_df, test_df]:\n",
    "    df[\"stand_enc\"] = df[\"stand\"].map(map_hand).fillna(-1).astype(int)\n",
    "    df[\"p_throws_enc\"] = df[\"p_throws\"].map(map_hand).fillna(-1).astype(int)\n",
    "    # Same-side vs opposite-side (batter vs pitcher)\n",
    "    df[\"same_side\"] = (df[\"stand_enc\"] == df[\"p_throws_enc\"]).astype(int)\n",
    "\n",
    "# Final feature list\n",
    "feature_cols = (\n",
    "    base_numeric\n",
    "    + [\n",
    "        \"sz_height\",\n",
    "        \"sz_center\",\n",
    "        \"break_mag\",\n",
    "        \"abs_pfx_x\",\n",
    "        \"abs_pfx_z\",\n",
    "        \"ext_speed\",\n",
    "        \"eff_ratio\",\n",
    "        \"stand_enc\",\n",
    "        \"p_throws_enc\",\n",
    "        \"same_side\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nUsing features:\")\n",
    "for c in feature_cols:\n",
    "    print(\" -\", c)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Targets\n",
    "# =========================================================\n",
    "\n",
    "# pitch_class: \"strike\"/\"ball\"\n",
    "class_to_idx = {\"ball\": 0, \"strike\": 1}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "y_class = train_df[\"pitch_class\"].map(class_to_idx).astype(int).values\n",
    "\n",
    "# zone: 1..14 -> 0..13 for XGBoost\n",
    "y_zone_raw = train_df[\"zone\"].astype(int).values\n",
    "y_zone = (y_zone_raw - 1).astype(int)\n",
    "\n",
    "# Features matrix\n",
    "X_all = train_df[feature_cols].astype(float).values\n",
    "X_test = test_df[feature_cols].astype(float).values\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Train/validation split\n",
    "# =========================================================\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(train_df)),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y_class,\n",
    ")\n",
    "\n",
    "X_tr = X_all[train_idx]\n",
    "X_val = X_all[val_idx]\n",
    "y_class_tr = y_class[train_idx]\n",
    "y_class_val = y_class[val_idx]\n",
    "y_zone_tr = y_zone[train_idx]\n",
    "y_zone_val = y_zone[val_idx]\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_idx)}\")\n",
    "print(f\"Validation samples: {len(val_idx)}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# XGBoost: pitch_class model (binary)\n",
    "# =========================================================\n",
    "\n",
    "dtrain_class = xgb.DMatrix(X_tr, label=y_class_tr)\n",
    "dval_class = xgb.DMatrix(X_val, label=y_class_val)\n",
    "\n",
    "params_class = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"seed\": SEED,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost model for pitch_class...\")\n",
    "evals = [(dtrain_class, \"train\"), (dval_class, \"val\")]\n",
    "bst_class = xgb.train(\n",
    "    params_class,\n",
    "    dtrain_class,\n",
    "    num_boost_round=200,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=20,\n",
    ")\n",
    "\n",
    "# Validation predictions for pitch_class\n",
    "y_class_val_pred_proba = bst_class.predict(dval_class)\n",
    "y_class_val_pred = (y_class_val_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "acc_class = accuracy_score(y_class_val, y_class_val_pred)\n",
    "print(f\"\\nValidation pitch_class accuracy: {acc_class:.4f}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# XGBoost: zone model (multiclass 14 zones)\n",
    "# =========================================================\n",
    "\n",
    "dtrain_zone = xgb.DMatrix(X_tr, label=y_zone_tr)\n",
    "dval_zone = xgb.DMatrix(X_val, label=y_zone_val)\n",
    "\n",
    "params_zone = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"num_class\": 14,\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 7,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"lambda\": 1.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"seed\": SEED,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost model for zone...\")\n",
    "evals_zone = [(dtrain_zone, \"train\"), (dval_zone, \"val\")]\n",
    "bst_zone = xgb.train(\n",
    "    params_zone,\n",
    "    dtrain_zone,\n",
    "    num_boost_round=300,\n",
    "    evals=evals_zone,\n",
    "    early_stopping_rounds=25,\n",
    "    verbose_eval=20,\n",
    ")\n",
    "\n",
    "# Validation predictions for zone\n",
    "y_zone_val_proba = bst_zone.predict(dval_zone)  # shape (N_val, 14)\n",
    "y_zone_val_pred = np.argmax(y_zone_val_proba, axis=1)  # 0..13\n",
    "\n",
    "acc_zone = accuracy_score(y_zone_val, y_zone_val_pred)\n",
    "print(f\"\\nValidation zone accuracy: {acc_zone:.4f}\")\n",
    "\n",
    "# Combined competition metric\n",
    "score_combined = 0.7 * acc_class + 0.3 * acc_zone\n",
    "print(f\"Validation combined score (0.7 * class + 0.3 * zone): {score_combined:.4f}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Retrain on FULL data\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\nRetraining on full training set for final models...\")\n",
    "\n",
    "dall_class = xgb.DMatrix(X_all, label=y_class)\n",
    "bst_class_full = xgb.train(\n",
    "    params_class,\n",
    "    dall_class,\n",
    "    num_boost_round=bst_class.best_iteration + 20,  # small buffer\n",
    ")\n",
    "\n",
    "dall_zone = xgb.DMatrix(X_all, label=y_zone)\n",
    "bst_zone_full = xgb.train(\n",
    "    params_zone,\n",
    "    dall_zone,\n",
    "    num_boost_round=bst_zone.best_iteration + 30,\n",
    ")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Predict on test set\n",
    "# =========================================================\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "print(\"\\nPredicting on test set...\")\n",
    "\n",
    "test_class_proba = bst_class_full.predict(dtest)\n",
    "test_class_pred = (test_class_proba >= 0.5).astype(int)\n",
    "test_class_str = [idx_to_class[i] for i in test_class_pred]\n",
    "\n",
    "test_zone_proba = bst_zone_full.predict(dtest)  # (N_test, 14)\n",
    "test_zone_pred_idx = np.argmax(test_zone_proba, axis=1)  # 0..13\n",
    "test_zone_pred = (test_zone_pred_idx + 1).astype(int)  # 1..14\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Build submission\n",
    "# =========================================================\n",
    "\n",
    "pred_df = pd.DataFrame(\n",
    "    {\n",
    "        \"file_name\": test_df[\"file_name\"].values,\n",
    "        \"pitch_class\": test_class_str,\n",
    "        \"zone\": test_zone_pred,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge with template to ensure exact ordering and no missing files\n",
    "submission = template_df.drop(columns=[\"pitch_class\", \"zone\"], errors=\"ignore\")\n",
    "submission = submission.merge(pred_df, on=\"file_name\", how=\"left\")\n",
    "\n",
    "missing = submission[\"pitch_class\"].isna().sum() + submission[\"zone\"].isna().sum()\n",
    "if missing > 0:\n",
    "    print(f\"Warning: {missing} missing predictions in submission\")\n",
    "\n",
    "submission.to_csv(OUTPUT_SUBMISSION, index=False)\n",
    "print(\"\\nSaved submission to:\", OUTPUT_SUBMISSION)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Extracting trajectory features for TRAIN videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [06:24<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_video_features_nn.csv\n",
      "Extracting trajectory features for TEST videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [04:28<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test_video_features_nn.csv\n",
      "Tabular feature dimension: 37\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.3086 | Val loss: 1.2907\n",
      "Val pitch_class acc: 0.5625, Val zone acc: 0.1500, Combined: 0.4387\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2473 | Val loss: 1.2564\n",
      "Val pitch_class acc: 0.6117, Val zone acc: 0.1933, Combined: 0.4862\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2077 | Val loss: 1.2414\n",
      "Val pitch_class acc: 0.5675, Val zone acc: 0.1867, Combined: 0.4532\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1792 | Val loss: 1.1950\n",
      "Val pitch_class acc: 0.5858, Val zone acc: 0.2133, Combined: 0.4741\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1356 | Val loss: 1.1550\n",
      "Val pitch_class acc: 0.6400, Val zone acc: 0.2133, Combined: 0.5120\n",
      "\n",
      "Best validation combined score: 0.5120\n",
      "\n",
      "Fine-tuning on full training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune epoch 1, loss: 1.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune epoch 2, loss: 1.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission written to: submission_hybrid_video_tabular_nn.csv\n",
      "     file_name pitch_class  zone\n",
      "0   pitch2.mp4        ball    12\n",
      "1   pitch6.mp4      strike     4\n",
      "2   pitch7.mp4        ball    11\n",
      "3   pitch9.mp4      strike    11\n",
      "4  pitch10.mp4      strike    14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 0.49630\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ============================================================\n",
    "# PATHS / CONFIG\n",
    "# ============================================================\n",
    "\n",
    "BASE = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_VID_DIR = os.path.join(BASE, \"train_trimmed\")\n",
    "TEST_VID_DIR  = os.path.join(BASE, \"test\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATURES_CSV = os.path.join(BASE, \"data\", \"test_features.csv\")\n",
    "TEMPLATE_CSV = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "\n",
    "TRAIN_VIDEO_FEATS = \"train_video_features_nn.csv\"\n",
    "TEST_VIDEO_FEATS  = \"test_video_features_nn.csv\"\n",
    "\n",
    "SUBMISSION_OUT = \"submission_hybrid_video_tabular_nn.csv\"\n",
    "\n",
    "SEED = 42\n",
    "N_FRAMES = 16       # frames per clip for CNN\n",
    "BATCH_SIZE = 4     # keep small for macOS MPS\n",
    "EPOCHS = 10         # you can increase once it runs\n",
    "LR = 1e-4\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device (MPS-friendly)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================================================\n",
    "# BALL DETECTION / TRAJECTORY FEATURES (NO CLICKING)\n",
    "# ============================================================\n",
    "\n",
    "def detect_ball(frame, prev=None, max_dist=60):\n",
    "    \"\"\"\n",
    "    Simple ball detector: white-ish blob + proximity to previous.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 0, 200])\n",
    "    upper = np.array([180, 40, 255])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    best = None\n",
    "    best_dist = 1e9\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        area = w * h\n",
    "        if 8 < area < 500:  # small bright blob\n",
    "            cx = x + w / 2.0\n",
    "            cy = y + h / 2.0\n",
    "            if prev is None:\n",
    "                return (cx, cy)\n",
    "            dist = np.hypot(cx - prev[0], cy - prev[1])\n",
    "            if dist < best_dist and dist < max_dist:\n",
    "                best_dist = dist\n",
    "                best = (cx, cy)\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def safe_polyfit(x, y, deg):\n",
    "    \"\"\"\n",
    "    Robust polyfit wrapper that never fails and always returns a fixed-length\n",
    "    coefficient list [a2, a1, a0] for quadratic.\n",
    "    If deg=2 fit fails, fallback to deg=1, then to deg=0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coeffs = np.polyfit(x, y, deg)\n",
    "    except Exception:\n",
    "        coeffs = None\n",
    "\n",
    "    # Handle degeneracies: fewer samples or near-constant inputs\n",
    "    if coeffs is None or len(coeffs) != deg + 1:\n",
    "        # Try linear\n",
    "        try:\n",
    "            coeffs = np.polyfit(x, y, 1)\n",
    "            # Promote to quadratic form: ax^2 + bx + c\n",
    "            a = 0.0\n",
    "            b, c = coeffs\n",
    "            return np.array([a, b, c], dtype=float)\n",
    "        except Exception:\n",
    "            # Fallback constant\n",
    "            mean_val = float(np.mean(y))\n",
    "            return np.array([0.0, 0.0, mean_val], dtype=float)\n",
    "\n",
    "    # If returned coefficients are the wrong length, patch them\n",
    "    if len(coeffs) == 2:\n",
    "        a = 0.0\n",
    "        b, c = coeffs\n",
    "        return np.array([a, b, c], dtype=float)\n",
    "\n",
    "    if len(coeffs) == 1:\n",
    "        mean_val = float(coeffs[0])\n",
    "        return np.array([0.0, 0.0, mean_val], dtype=float)\n",
    "\n",
    "    return coeffs.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "def compute_trajectory_features(xs, ys, frame_w, frame_h):\n",
    "    \"\"\"\n",
    "    From xs, ys → compute normalized physics features robustly.\n",
    "    \"\"\"\n",
    "    n = len(xs)\n",
    "    if n < 5 or frame_w <= 0 or frame_h <= 0:\n",
    "        return {\n",
    "            \"x_norm_final\": 0.0,\n",
    "            \"y_norm_final\": 0.0,\n",
    "            \"vx_mean\": 0.0,\n",
    "            \"vy_mean\": 0.0,\n",
    "            \"ax_mean\": 0.0,\n",
    "            \"ay_mean\": 0.0,\n",
    "            \"speed_mean\": 0.0,\n",
    "            \"speed_max\": 0.0,\n",
    "            \"curvature\": 0.0,\n",
    "            \"px0\": 0.0, \"px1\": 0.0, \"px2\": 0.0,\n",
    "            \"py0\": 0.0, \"py1\": 0.0, \"py2\": 0.0,\n",
    "            \"traj_len\": float(n),\n",
    "        }\n",
    "\n",
    "    xs = np.array(xs, float)\n",
    "    ys = np.array(ys, float)\n",
    "    t = np.arange(n, dtype=float)\n",
    "\n",
    "    xs_n = xs / frame_w\n",
    "    ys_n = ys / frame_h\n",
    "\n",
    "    vx = np.gradient(xs_n)\n",
    "    vy = np.gradient(ys_n)\n",
    "    speed = np.hypot(vx, vy)\n",
    "\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "\n",
    "    curvature = np.mean(np.abs(ax * vy - ay * vx) / (speed**3 + 1e-6))\n",
    "\n",
    "    # SAFE polyfits\n",
    "    px_coeff = safe_polyfit(t, xs_n, deg=2)  # [a2, a1, a0]\n",
    "    py_coeff = safe_polyfit(t, ys_n, deg=2)\n",
    "\n",
    "    px2, px1, px0 = px_coeff\n",
    "    py2, py1, py0 = py_coeff\n",
    "\n",
    "    # create callable polynomials\n",
    "    px = np.poly1d(px_coeff)\n",
    "    py = np.poly1d(py_coeff)\n",
    "\n",
    "    # extrapolate\n",
    "    t_final = n / 0.8\n",
    "    x_norm_final = float(px(t_final))\n",
    "    y_norm_final = float(py(t_final))\n",
    "\n",
    "    return {\n",
    "        \"x_norm_final\": x_norm_final,\n",
    "        \"y_norm_final\": y_norm_final,\n",
    "        \"vx_mean\": float(np.mean(vx)),\n",
    "        \"vy_mean\": float(np.mean(vy)),\n",
    "        \"ax_mean\": float(np.mean(ax)),\n",
    "        \"ay_mean\": float(np.mean(ay)),\n",
    "        \"speed_mean\": float(np.mean(speed)),\n",
    "        \"speed_max\": float(np.max(speed)),\n",
    "        \"curvature\": float(curvature),\n",
    "        \"px0\": float(px0), \"px1\": float(px1), \"px2\": float(px2),\n",
    "        \"py0\": float(py0), \"py1\": float(py1), \"py2\": float(py2),\n",
    "        \"traj_len\": float(n),\n",
    "    }\n",
    "\n",
    "\n",
    "def process_video_trajectory(video_path):\n",
    "    \"\"\"\n",
    "    Track ball for a single video and return physics features.\n",
    "    No ground-truth usage here. No strike zone heuristics.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        # empty features\n",
    "        return compute_trajectory_features([], [], 1, 1)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    xs, ys = [], []\n",
    "    prev = None\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        c = detect_ball(frame, prev)\n",
    "        if c is not None:\n",
    "            prev = c\n",
    "            xs.append(c[0])\n",
    "            ys.append(c[1])\n",
    "\n",
    "    cap.release()\n",
    "    return compute_trajectory_features(xs, ys, w, h)\n",
    "\n",
    "\n",
    "def build_video_features_all():\n",
    "    \"\"\"\n",
    "    Process all train and test videos and save physics features:\n",
    "    They are purely learned-input features (no manual labels).\n",
    "    \"\"\"\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_FEATURES_CSV)\n",
    "\n",
    "    # Train video features\n",
    "    rows = []\n",
    "    print(\"Extracting trajectory features for TRAIN videos...\")\n",
    "    for fname in tqdm(train_df[\"file_name\"]):\n",
    "        vp = os.path.join(TRAIN_VID_DIR, fname)\n",
    "        feats = process_video_trajectory(vp)\n",
    "        feats[\"file_name\"] = fname\n",
    "        rows.append(feats)\n",
    "    train_feats = pd.DataFrame(rows)\n",
    "    train_feats.to_csv(TRAIN_VIDEO_FEATS, index=False)\n",
    "    print(\"Saved\", TRAIN_VIDEO_FEATS)\n",
    "\n",
    "    # Test video features\n",
    "    rows = []\n",
    "    print(\"Extracting trajectory features for TEST videos...\")\n",
    "    for fname in tqdm(test_df[\"file_name\"]):\n",
    "        vp = os.path.join(TEST_VID_DIR, fname)\n",
    "        feats = process_video_trajectory(vp)\n",
    "        feats[\"file_name\"] = fname\n",
    "        rows.append(feats)\n",
    "    test_feats = pd.DataFrame(rows)\n",
    "    test_feats.to_csv(TEST_VIDEO_FEATS, index=False)\n",
    "    print(\"Saved\", TEST_VIDEO_FEATS)\n",
    "\n",
    "    return train_feats, test_feats\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TABULAR + PHYSICS FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "def build_tabular_and_physics():\n",
    "    \"\"\"\n",
    "    Build full tabular feature matrices from Statcast + physics.\n",
    "    Returns:\n",
    "        train_df_full, test_df_full, X_train (np), X_test (np),\n",
    "        y_class (np), y_zone (np), scaler, feature_names\n",
    "    \"\"\"\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_FEATURES_CSV)\n",
    "\n",
    "    if os.path.exists(TRAIN_VIDEO_FEATS) and os.path.exists(TEST_VIDEO_FEATS):\n",
    "        train_vid = pd.read_csv(TRAIN_VIDEO_FEATS)\n",
    "        test_vid = pd.read_csv(TEST_VIDEO_FEATS)\n",
    "    else:\n",
    "        train_vid, test_vid = build_video_features_all()\n",
    "\n",
    "    # Merge video features\n",
    "    train = train_df.merge(train_vid, on=\"file_name\", how=\"left\")\n",
    "    test = test_df.merge(test_vid, on=\"file_name\", how=\"left\")\n",
    "\n",
    "    # Statcast numeric\n",
    "    base_numeric = [\n",
    "        \"sz_top\", \"sz_bot\",\n",
    "        \"release_speed\", \"effective_speed\",\n",
    "        \"release_spin_rate\",\n",
    "        \"release_pos_x\", \"release_pos_y\", \"release_pos_z\",\n",
    "        \"release_extension\",\n",
    "        \"pfx_x\", \"pfx_z\",\n",
    "    ]\n",
    "    categorical = [\"stand\", \"p_throws\"]\n",
    "\n",
    "    # Fill numeric\n",
    "    medians = {}\n",
    "    for col in base_numeric:\n",
    "        med = train[col].median()\n",
    "        medians[col] = med\n",
    "        train[col] = train[col].fillna(med)\n",
    "        test[col] = test[col].fillna(med)\n",
    "\n",
    "    # Fill categorical\n",
    "    for col in categorical:\n",
    "        train[col] = train[col].fillna(\"Unknown\")\n",
    "        test[col] = test[col].fillna(\"Unknown\")\n",
    "\n",
    "    # Derived Statcast features\n",
    "    for df in [train, test]:\n",
    "        df[\"sz_height\"] = df[\"sz_top\"] - df[\"sz_bot\"]\n",
    "        df[\"sz_center\"] = 0.5 * (df[\"sz_top\"] + df[\"sz_bot\"])\n",
    "        df[\"break_mag\"] = np.sqrt(df[\"pfx_x\"]**2 + df[\"pfx_z\"]**2)\n",
    "        df[\"abs_pfx_x\"] = df[\"pfx_x\"].abs()\n",
    "        df[\"abs_pfx_z\"] = df[\"pfx_z\"].abs()\n",
    "        df[\"ext_speed\"] = df[\"release_speed\"] * df[\"release_extension\"]\n",
    "        safe_speed = df[\"release_speed\"].replace(0, medians[\"release_speed\"])\n",
    "        df[\"eff_ratio\"] = df[\"effective_speed\"] / safe_speed\n",
    "\n",
    "        # Encode handedness\n",
    "        map_hand = {\"L\": 0, \"R\": 1}\n",
    "        df[\"stand_enc\"] = df[\"stand\"].map(map_hand).fillna(-1).astype(int)\n",
    "        df[\"p_throws_enc\"] = df[\"p_throws\"].map(map_hand).fillna(-1).astype(int)\n",
    "        df[\"same_side\"] = (df[\"stand_enc\"] == df[\"p_throws_enc\"]).astype(int)\n",
    "\n",
    "    # Physics feature columns (from trajectory)\n",
    "    physics_cols = [\n",
    "        \"x_norm_final\", \"y_norm_final\",\n",
    "        \"vx_mean\", \"vy_mean\",\n",
    "        \"ax_mean\", \"ay_mean\",\n",
    "        \"speed_mean\", \"speed_max\",\n",
    "        \"curvature\",\n",
    "        \"px0\", \"px1\", \"px2\",\n",
    "        \"py0\", \"py1\", \"py2\",\n",
    "        \"traj_len\",\n",
    "    ]\n",
    "\n",
    "    for col in physics_cols:\n",
    "        train[col] = train[col].fillna(0.0)\n",
    "        test[col] = test[col].fillna(0.0)\n",
    "\n",
    "    feature_cols = (\n",
    "        base_numeric\n",
    "        + [\n",
    "            \"sz_height\", \"sz_center\", \"break_mag\", \"abs_pfx_x\", \"abs_pfx_z\",\n",
    "            \"ext_speed\", \"eff_ratio\",\n",
    "            \"stand_enc\", \"p_throws_enc\", \"same_side\",\n",
    "        ]\n",
    "        + physics_cols\n",
    "    )\n",
    "\n",
    "    X_train_raw = train[feature_cols].astype(float).values\n",
    "    X_test_raw = test[feature_cols].astype(float).values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_raw)\n",
    "    X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "    # Targets\n",
    "    class_map = {\"ball\": 0, \"strike\": 1}\n",
    "    y_class = train[\"pitch_class\"].map(class_map).astype(int).values\n",
    "    y_zone = train[\"zone\"].astype(int).values - 1  # 0–13\n",
    "\n",
    "    return train, test, X_train, X_test, y_class, y_zone, scaler, feature_cols\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VIDEO LOADING FOR CNN\n",
    "# ============================================================\n",
    "\n",
    "video_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                                # HxWxC -> CxHxW, [0,1]\n",
    "    transforms.Resize((224, 224)),                        # ResNet18 size\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],                      # ImageNet stats\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "def load_video_frames_sampled(video_path, n_frames=N_FRAMES):\n",
    "    \"\"\"\n",
    "    Load a mp4 and sample n_frames uniformly over its length.\n",
    "    Returns tensor of shape (T, C, H, W).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total <= 0:\n",
    "        cap.release()\n",
    "        # return zeros\n",
    "        dummy = torch.zeros(n_frames, 3, 224, 224, dtype=torch.float32)\n",
    "        return dummy\n",
    "\n",
    "    # indices spread across frames\n",
    "    indices = np.linspace(0, total - 1, n_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # if read fails, use a black frame\n",
    "            frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_like = frame_rgb\n",
    "        tensor = video_transform(pil_like)\n",
    "        frames.append(tensor)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    video_tensor = torch.stack(frames, dim=0)  # (T, C, H, W)\n",
    "    return video_tensor\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================\n",
    "\n",
    "class PitchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        tab_array,\n",
    "        video_dir,\n",
    "        file_col=\"file_name\",\n",
    "        y_class=None,\n",
    "        y_zone=None,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tab = tab_array.astype(np.float32)\n",
    "        self.video_dir = video_dir\n",
    "        self.file_col = file_col\n",
    "        self.y_class = y_class\n",
    "        self.y_zone = y_zone\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.loc[idx, self.file_col]\n",
    "        video_path = os.path.join(self.video_dir, fname)\n",
    "\n",
    "        # video frames (T,C,H,W)\n",
    "        frames = load_video_frames_sampled(video_path)  # torch.float32\n",
    "\n",
    "        # tabular\n",
    "        tab = torch.from_numpy(self.tab[idx])\n",
    "\n",
    "        if self.y_class is not None:\n",
    "            c = int(self.y_class[idx])\n",
    "            z = int(self.y_zone[idx])\n",
    "            return frames, tab, c, z\n",
    "        else:\n",
    "            return frames, tab, fname\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL: CNN (video) + MLP (tabular) → 2 heads\n",
    "# ============================================================\n",
    "\n",
    "class HybridVideoTabModel(nn.Module):\n",
    "    def __init__(self, tab_dim, num_zones=14):\n",
    "        super().__init__()\n",
    "\n",
    "        res = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.cnn_backbone = nn.Sequential(*list(res.children())[:-1])  # (B,512,1,1)\n",
    "        video_feat_dim = 512\n",
    "\n",
    "        self.tab_mlp = nn.Sequential(\n",
    "            nn.Linear(tab_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(video_feat_dim + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.class_head = nn.Linear(256, 2)\n",
    "        self.zone_head = nn.Linear(256, num_zones)\n",
    "\n",
    "    def forward(self, video, tab):\n",
    "        # video: (B, T, C, H, W)\n",
    "        B, T, C, H, W = video.shape\n",
    "\n",
    "        # flatten time → (B*T, C, H, W)\n",
    "        video = video.reshape(B * T, C, H, W).contiguous()\n",
    "\n",
    "        feat = self.cnn_backbone(video)         # (B*T, 512, 1, 1)\n",
    "        feat = feat.contiguous().reshape(B, T, -1).mean(dim=1)  # (B,512)\n",
    "\n",
    "        tab_feat = self.tab_mlp(tab)           # (B,128)\n",
    "\n",
    "        fused = torch.cat([feat, tab_feat], dim=1)  # (B,512+128)\n",
    "        shared = self.shared(fused)\n",
    "\n",
    "        class_logits = self.class_head(shared)\n",
    "        zone_logits = self.zone_head(shared)\n",
    "        return class_logits, zone_logits\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN / EVAL LOOPS\n",
    "# ============================================================\n",
    "\n",
    "def train_one_epoch(model, loader, opt, loss_class, loss_zone):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for frames, tab, c, z in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        frames = frames.to(device)\n",
    "        tab = tab.to(device)\n",
    "        c = c.to(device)\n",
    "        z = z.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        out_c, out_z = model(frames, tab)\n",
    "\n",
    "        lc = loss_class(out_c, c)\n",
    "        lz = loss_zone(out_z, z)\n",
    "        loss = 0.7 * lc + 0.3 * lz\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * frames.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, loss_class, loss_zone):\n",
    "    model.eval()\n",
    "    all_c_true, all_c_pred = [], []\n",
    "    all_z_true, all_z_pred = [], []\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for frames, tab, c, z in tqdm(loader, desc=\"Val\", leave=False):\n",
    "        frames = frames.to(device)\n",
    "        tab = tab.to(device)\n",
    "        c = c.to(device)\n",
    "        z = z.to(device)\n",
    "\n",
    "        out_c, out_z = model(frames, tab)\n",
    "        lc = loss_class(out_c, c)\n",
    "        lz = loss_zone(out_z, z)\n",
    "        loss = 0.7 * lc + 0.3 * lz\n",
    "        total_loss += loss.item() * frames.size(0)\n",
    "\n",
    "        c_hat = out_c.argmax(dim=1).cpu().numpy()\n",
    "        z_hat = out_z.argmax(dim=1).cpu().numpy()\n",
    "        all_c_true.append(c.cpu().numpy())\n",
    "        all_c_pred.append(c_hat)\n",
    "        all_z_true.append(z.cpu().numpy())\n",
    "        all_z_pred.append(z_hat)\n",
    "\n",
    "    all_c_true = np.concatenate(all_c_true)\n",
    "    all_c_pred = np.concatenate(all_c_pred)\n",
    "    all_z_true = np.concatenate(all_z_true)\n",
    "    all_z_pred = np.concatenate(all_z_pred)\n",
    "\n",
    "    acc_c = accuracy_score(all_c_true, all_c_pred)\n",
    "    acc_z = accuracy_score(all_z_true, all_z_pred)\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    score = 0.7 * acc_c + 0.3 * acc_z\n",
    "\n",
    "    return avg_loss, acc_c, acc_z, score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # 1) Build tabular + physics matrices (also builds video physics CSVs if missing)\n",
    "    train_df_full, test_df_full, X_train, X_test, y_class, y_zone, scaler, feature_cols = build_tabular_and_physics()\n",
    "    tab_dim = X_train.shape[1]\n",
    "    print(\"Tabular feature dimension:\", tab_dim)\n",
    "\n",
    "    # 2) Train/val split\n",
    "    idx = np.arange(len(train_df_full))\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        idx, test_size=0.2, random_state=SEED, stratify=y_class\n",
    "    )\n",
    "\n",
    "    X_tr = X_train[train_idx]\n",
    "    y_class_tr = y_class[train_idx]\n",
    "    y_zone_tr = y_zone[train_idx]\n",
    "\n",
    "    X_val = X_train[val_idx]\n",
    "    y_class_val = y_class[val_idx]\n",
    "    y_zone_val = y_zone[val_idx]\n",
    "\n",
    "    df_tr = train_df_full.iloc[train_idx].reset_index(drop=True)\n",
    "    df_val = train_df_full.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    # 3) Datasets / loaders\n",
    "    train_ds = PitchDataset(\n",
    "        df_tr, X_tr, TRAIN_VID_DIR,\n",
    "        y_class=y_class_tr, y_zone=y_zone_tr\n",
    "    )\n",
    "    val_ds = PitchDataset(\n",
    "        df_val, X_val, TRAIN_VID_DIR,\n",
    "        y_class=y_class_val, y_zone=y_zone_val\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 4) Model, loss, optimizer\n",
    "    model = HybridVideoTabModel(tab_dim=tab_dim, num_zones=14).to(device)\n",
    "    loss_class = nn.CrossEntropyLoss()\n",
    "    loss_zone = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # 5) Training loop with validation\n",
    "    best_score = -1\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, opt, loss_class, loss_zone)\n",
    "        val_loss, acc_c, acc_z, score = eval_model(model, val_loader, loss_class, loss_zone)\n",
    "        print(f\"Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f}\")\n",
    "        print(f\"Val pitch_class acc: {acc_c:.4f}, Val zone acc: {acc_z:.4f}, Combined: {score:.4f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state = model.state_dict().copy()\n",
    "\n",
    "    print(f\"\\nBest validation combined score: {best_score:.4f}\")\n",
    "\n",
    "    # 6) Optionally fine-tune on full train\n",
    "    model.load_state_dict(best_state)\n",
    "    full_ds = PitchDataset(\n",
    "        train_df_full, X_train, TRAIN_VID_DIR,\n",
    "        y_class=y_class, y_zone=y_zone\n",
    "    )\n",
    "    full_loader = DataLoader(full_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "    print(\"\\nFine-tuning on full training data...\")\n",
    "    for epoch in range(1, 3):  # a couple extra passes\n",
    "        ft_loss = train_one_epoch(model, full_loader, opt, loss_class, loss_zone)\n",
    "        print(f\"Fine-tune epoch {epoch}, loss: {ft_loss:.4f}\")\n",
    "\n",
    "    # 7) Predict on test set\n",
    "    test_ds = PitchDataset(\n",
    "        test_df_full, X_test, TEST_VID_DIR,\n",
    "        y_class=None, y_zone=None\n",
    "    )\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    model.eval()\n",
    "    all_file_names = []\n",
    "    all_class_pred = []\n",
    "    all_zone_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frames, tab, fnames in tqdm(test_loader, desc=\"Test\", leave=False):\n",
    "            frames = frames.to(device)\n",
    "            tab = tab.to(device)\n",
    "            out_c, out_z = model(frames, tab)\n",
    "\n",
    "            c_hat = out_c.argmax(dim=1).cpu().numpy()\n",
    "            z_hat = out_z.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "            all_class_pred.extend(c_hat.tolist())\n",
    "            all_zone_pred.extend(z_hat.tolist())\n",
    "            all_file_names.extend(fnames)\n",
    "\n",
    "    idx_to_class = {0: \"ball\", 1: \"strike\"}\n",
    "    pred_class_str = [idx_to_class[i] for i in all_class_pred]\n",
    "    pred_zone = (np.array(all_zone_pred) + 1).astype(int)\n",
    "\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"file_name\": all_file_names,\n",
    "        \"pitch_class\": pred_class_str,\n",
    "        \"zone\": pred_zone,\n",
    "    })\n",
    "\n",
    "    # 8) Build submission in template order\n",
    "    template = pd.read_csv(TEMPLATE_CSV)\n",
    "    submission = template.drop(columns=[\"pitch_class\", \"zone\"], errors=\"ignore\")\n",
    "    submission = submission.merge(pred_df, on=\"file_name\", how=\"left\")\n",
    "\n",
    "    submission.to_csv(SUBMISSION_OUT, index=False)\n",
    "    print(\"\\nSubmission written to:\", SUBMISSION_OUT)\n",
    "    print(submission.head())\n",
    "\n",
    "\n",
    "# Run the whole thing\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8693b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Tabular dim: 37\n",
      "\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.3194 | Val 1.3885\n",
      "Class Acc: 0.5308 | Zone Acc: 0.1300 | Score: 0.4106\n",
      "\n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2700 | Val 1.4783\n",
      "Class Acc: 0.5575 | Zone Acc: 0.1692 | Score: 0.4410\n",
      "\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2439 | Val 1.3814\n",
      "Class Acc: 0.5292 | Zone Acc: 0.1867 | Score: 0.4264\n",
      "\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2227 | Val 1.4434\n",
      "Class Acc: 0.5333 | Zone Acc: 0.1933 | Score: 0.4313\n",
      "\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2110 | Val 1.4195\n",
      "Class Acc: 0.5275 | Zone Acc: 0.1950 | Score: 0.4277\n",
      "\n",
      "Epoch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2053 | Val 1.5302\n",
      "Class Acc: 0.5275 | Zone Acc: 0.1883 | Score: 0.4257\n",
      "\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.2053 | Val 1.3540\n",
      "Class Acc: 0.5083 | Zone Acc: 0.2067 | Score: 0.4178\n",
      "\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.1951 | Val 1.4150\n",
      "Class Acc: 0.5375 | Zone Acc: 0.1975 | Score: 0.4355\n",
      "\n",
      "Best validation score: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 578\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sub\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 578\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 551\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    549\u001b[0m all_cls, all_zone, all_names \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 551\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43moc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    238\u001b[0m             ]\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ============================================================\n",
    "# PATHS / CONFIG\n",
    "# ============================================================\n",
    "\n",
    "BASE = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/baseball_kaggle_dataset_trimmed_only\"\n",
    "\n",
    "TRAIN_VID_DIR = os.path.join(BASE, \"train_trimmed\")\n",
    "TEST_VID_DIR  = os.path.join(BASE, \"test\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE, \"data\", \"train_ground_truth.csv\")\n",
    "TEST_FEATURES_CSV = os.path.join(BASE, \"data\", \"test_features.csv\")\n",
    "TEMPLATE_CSV = \"data/Question4/baseball-pitch-tracking-cs-gy-6643/test_submission_template.csv\"\n",
    "\n",
    "TRAIN_VIDEO_FEATS = \"train_video_features_nn.csv\"\n",
    "TEST_VIDEO_FEATS  = \"test_video_features_nn.csv\"\n",
    "\n",
    "SUBMISSION_OUT = \"submission_hybrid_video_tabular_3dcnn.csv\"\n",
    "\n",
    "SEED = 42\n",
    "N_FRAMES = 16          # upscaled for better temporal modeling\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 8             # start here, raise if stable\n",
    "LR = 1e-4\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAFE POLYFIT WRAPPER\n",
    "# ============================================================\n",
    "\n",
    "def safe_polyfit(x, y, deg):\n",
    "    \"\"\"\n",
    "    np.polyfit wrapper that always returns a 3-coefficient quadratic (a2,a1,a0).\n",
    "    Falls back to linear or constant if needed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coeffs = np.polyfit(x, y, deg)\n",
    "    except Exception:\n",
    "        coeffs = None\n",
    "\n",
    "    # Degenerate → try linear\n",
    "    if coeffs is None or len(coeffs) != deg + 1:\n",
    "        try:\n",
    "            coeffs = np.polyfit(x, y, 1)\n",
    "            b, c = coeffs\n",
    "            return np.array([0.0, b, c], float)\n",
    "        except Exception:\n",
    "            mean_val = float(np.mean(y))\n",
    "            return np.array([0.0, 0.0, mean_val], float)\n",
    "\n",
    "    # If it returns 1 or 2 coeffs\n",
    "    if len(coeffs) == 2:\n",
    "        b, c = coeffs\n",
    "        return np.array([0.0, b, c], float)\n",
    "    if len(coeffs) == 1:\n",
    "        c = coeffs[0]\n",
    "        return np.array([0.0, 0.0, c], float)\n",
    "\n",
    "    return np.array(coeffs, float)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# IMPROVED BALL DETECTION + TRAJECTORY FEATURES\n",
    "# ============================================================\n",
    "\n",
    "def detect_ball(frame, prev=None, max_dist=80, roi_radius=80):\n",
    "    \"\"\"\n",
    "    Improved tracker:\n",
    "      - If prev is known, only search in a local ROI around it.\n",
    "      - If detection fails, return prev (hold last good position).\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    if prev is not None:\n",
    "        cx_prev, cy_prev = prev\n",
    "        x1 = max(int(cx_prev - roi_radius), 0)\n",
    "        x2 = min(int(cx_prev + roi_radius), w)\n",
    "        y1 = max(int(cy_prev - roi_radius), 0)\n",
    "        y2 = min(int(cy_prev + roi_radius), h)\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        offset = (x1, y1)\n",
    "    else:\n",
    "        roi = frame\n",
    "        offset = (0, 0)\n",
    "\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, np.array([0, 0, 200]), np.array([180, 40, 255]))\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    best = None\n",
    "    best_dist = 1e9\n",
    "\n",
    "    for c in cnts:\n",
    "        x, y, w_box, h_box = cv2.boundingRect(c)\n",
    "        area = w_box * h_box\n",
    "        if 8 < area < 500:\n",
    "            cx = x + w_box / 2 + offset[0]\n",
    "            cy = y + h_box / 2 + offset[1]\n",
    "            if prev is None:\n",
    "                return (cx, cy)\n",
    "            d = np.hypot(cx - prev[0], cy - prev[1])\n",
    "            if d < best_dist and d < max_dist:\n",
    "                best, best_dist = (cx, cy), d\n",
    "\n",
    "    if best is None and prev is not None:\n",
    "        # hold last known position to keep trajectory continuous\n",
    "        return prev\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def compute_trajectory_features(xs, ys, frame_w, frame_h):\n",
    "    n = len(xs)\n",
    "    if n < 5 or frame_w <= 0 or frame_h <= 0:\n",
    "        return {k: 0.0 for k in [\n",
    "            \"x_norm_final\",\"y_norm_final\",\n",
    "            \"vx_mean\",\"vy_mean\",\"ax_mean\",\"ay_mean\",\n",
    "            \"speed_mean\",\"speed_max\",\"curvature\",\n",
    "            \"px0\",\"px1\",\"px2\",\"py0\",\"py1\",\"py2\",\n",
    "            \"traj_len\"\n",
    "        ]}\n",
    "\n",
    "    xs = np.array(xs, float)\n",
    "    ys = np.array(ys, float)\n",
    "    t = np.arange(n, dtype=float)\n",
    "\n",
    "    xs_n = xs / frame_w\n",
    "    ys_n = ys / frame_h\n",
    "\n",
    "    vx = np.gradient(xs_n)\n",
    "    vy = np.gradient(ys_n)\n",
    "    speed = np.hypot(vx, vy)\n",
    "\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "    curvature = np.mean(np.abs(ax * vy - ay * vx) / (speed**3 + 1e-6))\n",
    "\n",
    "    px_coeff = safe_polyfit(t, xs_n, deg=2)\n",
    "    py_coeff = safe_polyfit(t, ys_n, deg=2)\n",
    "    px2, px1, px0 = px_coeff\n",
    "    py2, py1, py0 = py_coeff\n",
    "\n",
    "    px = np.poly1d(px_coeff)\n",
    "    py = np.poly1d(py_coeff)\n",
    "\n",
    "    t_final = n / 0.8\n",
    "    return {\n",
    "        \"x_norm_final\": float(px(t_final)),\n",
    "        \"y_norm_final\": float(py(t_final)),\n",
    "        \"vx_mean\": float(np.mean(vx)),\n",
    "        \"vy_mean\": float(np.mean(vy)),\n",
    "        \"ax_mean\": float(np.mean(ax)),\n",
    "        \"ay_mean\": float(np.mean(ay)),\n",
    "        \"speed_mean\": float(np.mean(speed)),\n",
    "        \"speed_max\": float(np.max(speed)),\n",
    "        \"curvature\": float(curvature),\n",
    "        \"px0\": float(px0), \"px1\": float(px1), \"px2\": float(px2),\n",
    "        \"py0\": float(py0), \"py1\": float(py1), \"py2\": float(py2),\n",
    "        \"traj_len\": float(n),\n",
    "    }\n",
    "\n",
    "\n",
    "def process_video_trajectory(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return compute_trajectory_features([], [], 1, 1)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    xs, ys = [], []\n",
    "    prev = None\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        c = detect_ball(frame, prev)\n",
    "        if c is not None:\n",
    "            prev = c\n",
    "            xs.append(c[0])\n",
    "            ys.append(c[1])\n",
    "\n",
    "    cap.release()\n",
    "    return compute_trajectory_features(xs, ys, w, h)\n",
    "\n",
    "\n",
    "def build_video_features_all():\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df  = pd.read_csv(TEST_FEATURES_CSV)\n",
    "\n",
    "    rows = []\n",
    "    print(\"Extracting video trajectory features for TRAIN...\")\n",
    "    for fname in tqdm(train_df[\"file_name\"]):\n",
    "        feats = process_video_trajectory(os.path.join(TRAIN_VID_DIR, fname))\n",
    "        feats[\"file_name\"] = fname\n",
    "        rows.append(feats)\n",
    "    pd.DataFrame(rows).to_csv(TRAIN_VIDEO_FEATS, index=False)\n",
    "\n",
    "    rows = []\n",
    "    print(\"Extracting video trajectory features for TEST...\")\n",
    "    for fname in tqdm(test_df[\"file_name\"]):\n",
    "        feats = process_video_trajectory(os.path.join(TEST_VID_DIR, fname))\n",
    "        feats[\"file_name\"] = fname\n",
    "        rows.append(feats)\n",
    "    pd.DataFrame(rows).to_csv(TEST_VIDEO_FEATS, index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TABULAR + PHYSICS FUSION\n",
    "# ============================================================\n",
    "\n",
    "def build_tabular_and_physics():\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df  = pd.read_csv(TEST_FEATURES_CSV)\n",
    "\n",
    "    if not os.path.exists(TRAIN_VIDEO_FEATS) or not os.path.exists(TEST_VIDEO_FEATS):\n",
    "        build_video_features_all()\n",
    "\n",
    "    train_vid = pd.read_csv(TRAIN_VIDEO_FEATS)\n",
    "    test_vid  = pd.read_csv(TEST_VIDEO_FEATS)\n",
    "\n",
    "    train = train_df.merge(train_vid, on=\"file_name\", how=\"left\")\n",
    "    test  = test_df.merge(test_vid, on=\"file_name\", how=\"left\")\n",
    "\n",
    "    base_numeric = [\n",
    "        \"sz_top\",\"sz_bot\",\"release_speed\",\"effective_speed\",\n",
    "        \"release_spin_rate\",\"release_pos_x\",\"release_pos_y\",\n",
    "        \"release_pos_z\",\"release_extension\",\"pfx_x\",\"pfx_z\"\n",
    "    ]\n",
    "    categorical = [\"stand\",\"p_throws\"]\n",
    "\n",
    "    med = {c: train[c].median() for c in base_numeric}\n",
    "    for df in [train, test]:\n",
    "        for c in base_numeric:\n",
    "            df[c] = df[c].fillna(med[c])\n",
    "\n",
    "    for df in [train, test]:\n",
    "        for c in categorical:\n",
    "            df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df[\"sz_height\"] = df[\"sz_top\"] - df[\"sz_bot\"]\n",
    "        df[\"sz_center\"] = 0.5 * (df[\"sz_top\"] + df[\"sz_bot\"])\n",
    "        df[\"break_mag\"] = np.sqrt(df[\"pfx_x\"]**2 + df[\"pfx_z\"]**2)\n",
    "        df[\"abs_pfx_x\"] = df[\"pfx_x\"].abs()\n",
    "        df[\"abs_pfx_z\"] = df[\"pfx_z\"].abs()\n",
    "        df[\"ext_speed\"] = df[\"release_speed\"] * df[\"release_extension\"]\n",
    "        safe = df[\"release_speed\"].replace(0, med[\"release_speed\"])\n",
    "        df[\"eff_ratio\"] = df[\"effective_speed\"] / safe\n",
    "\n",
    "        map_hand = {\"L\": 0, \"R\": 1}\n",
    "        df[\"stand_enc\"] = df[\"stand\"].map(map_hand).fillna(-1).astype(int)\n",
    "        df[\"p_throws_enc\"] = df[\"p_throws\"].map(map_hand).fillna(-1).astype(int)\n",
    "        df[\"same_side\"] = (df[\"stand_enc\"] == df[\"p_throws_enc\"]).astype(int)\n",
    "\n",
    "    physics_cols = [\n",
    "        \"x_norm_final\",\"y_norm_final\",\n",
    "        \"vx_mean\",\"vy_mean\",\"ax_mean\",\"ay_mean\",\n",
    "        \"speed_mean\",\"speed_max\",\"curvature\",\n",
    "        \"px0\",\"px1\",\"px2\",\"py0\",\"py1\",\"py2\",\n",
    "        \"traj_len\"\n",
    "    ]\n",
    "\n",
    "    for col in physics_cols:\n",
    "        train[col] = train[col].fillna(0.0)\n",
    "        test[col]  = test[col].fillna(0.0)\n",
    "\n",
    "    feature_cols = (\n",
    "        base_numeric +\n",
    "        [\"sz_height\",\"sz_center\",\"break_mag\",\"abs_pfx_x\",\"abs_pfx_z\",\n",
    "         \"ext_speed\",\"eff_ratio\",\"stand_enc\",\"p_throws_enc\",\"same_side\"] +\n",
    "        physics_cols\n",
    "    )\n",
    "\n",
    "    X_train_raw = train[feature_cols].astype(float).values\n",
    "    X_test_raw  = test[feature_cols].astype(float).values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_raw)\n",
    "    X_test  = scaler.transform(X_test_raw)\n",
    "\n",
    "    class_map = {\"ball\": 0, \"strike\": 1}\n",
    "    y_class = train[\"pitch_class\"].map(class_map).astype(int).values\n",
    "    y_zone  = train[\"zone\"].astype(int).values - 1\n",
    "\n",
    "    return train, test, X_train, X_test, y_class, y_zone, scaler, feature_cols\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VIDEO SAMPLING FOR 3D CNN\n",
    "# ============================================================\n",
    "\n",
    "video_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),  # smaller for 3D conv efficiency\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_video_frames_sampled(video_path, n_frames=N_FRAMES):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total <= 0:\n",
    "        cap.release()\n",
    "        return torch.zeros(n_frames, 3, 128, 128)\n",
    "\n",
    "    indices = np.linspace(0, total - 1, n_frames).astype(int)\n",
    "    frames = []\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            frames.append(torch.zeros(3, 128, 128))\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        tensor = video_transform(img)\n",
    "        frames.append(tensor)\n",
    "\n",
    "    cap.release()\n",
    "    return torch.stack(frames, dim=0)  # (T, C, H, W)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATASET\n",
    "# ============================================================\n",
    "\n",
    "class PitchDataset(Dataset):\n",
    "    def __init__(self, df, tab_arr, video_dir, y_class=None, y_zone=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tab = tab_arr.astype(np.float32)\n",
    "        self.dir = video_dir\n",
    "        self.yc = y_class\n",
    "        self.yz = y_zone\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.loc[idx, \"file_name\"]\n",
    "        video_tensor = load_video_frames_sampled(os.path.join(self.dir, fname))\n",
    "        tab = torch.from_numpy(self.tab[idx])\n",
    "        if self.yc is not None:\n",
    "            return video_tensor, tab, int(self.yc[idx]), int(self.yz[idx]), fname\n",
    "        else:\n",
    "            return video_tensor, tab, None, None, fname\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3D CNN BACKBONE + TABULAR FUSION\n",
    "# ============================================================\n",
    "\n",
    "class VideoBackbone3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 3D CNN encoder over (C,T,H,W).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, base_channels, kernel_size=(3,7,7),\n",
    "                               stride=(1,2,2), padding=(1,3,3))\n",
    "        self.bn1 = nn.BatchNorm3d(base_channels)\n",
    "        self.conv2 = nn.Conv3d(base_channels, base_channels*2, kernel_size=3,\n",
    "                               stride=(1,2,2), padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(base_channels*2)\n",
    "        self.conv3 = nn.Conv3d(base_channels*2, base_channels*4, kernel_size=3,\n",
    "                               stride=(2,2,2), padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(base_channels*4)\n",
    "\n",
    "        self.out_channels = base_channels * 4\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T, H, W)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        # global avg pool over (T,H,W)\n",
    "        x = F.adaptive_avg_pool3d(x, (1,1,1))  # (B, C,1,1,1)\n",
    "        x = x.view(x.size(0), -1)             # (B, C)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HybridVideoTabModel3D(nn.Module):\n",
    "    def __init__(self, tab_dim, num_zones=14):\n",
    "        super().__init__()\n",
    "        self.video_backbone = VideoBackbone3D(in_channels=3, base_channels=32)\n",
    "        video_feat_dim = self.video_backbone.out_channels\n",
    "\n",
    "        self.tab_mlp = nn.Sequential(\n",
    "            nn.Linear(tab_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(video_feat_dim + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.head_class = nn.Linear(256, 2)\n",
    "        self.head_zone  = nn.Linear(256, num_zones)\n",
    "\n",
    "    def forward(self, video, tab):\n",
    "        # video: (B, T, C, H, W) → (B, C, T, H, W)\n",
    "        video = video.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        vfeat = self.video_backbone(video)        # (B, video_feat_dim)\n",
    "        tfeat = self.tab_mlp(tab)                 # (B, 128)\n",
    "        fused = torch.cat([vfeat, tfeat], dim=1)  # (B, video_feat_dim+128)\n",
    "        h = self.shared(fused)\n",
    "        return self.head_class(h), self.head_zone(h)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN & EVAL\n",
    "# ============================================================\n",
    "\n",
    "def train_one_epoch(model, loader, opt, lc, lz):\n",
    "    model.train()\n",
    "    tot = 0\n",
    "    for v, t, c, z, _ in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        v, t, c, z = v.to(device), t.to(device), c.to(device), z.to(device)\n",
    "        opt.zero_grad()\n",
    "        oc, oz = model(v, t)\n",
    "        loss = 0.7 * lc(oc, c) + 0.3 * lz(oz, z)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        opt.step()\n",
    "        tot += loss.item() * v.size(0)\n",
    "    return tot / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, lc, lz):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    ac_true, ac_pred = [], []\n",
    "    az_true, az_pred = [], []\n",
    "\n",
    "    for v, t, c, z, _ in tqdm(loader, desc=\"Val\", leave=False):\n",
    "        v, t, c, z = v.to(device), t.to(device), c.to(device), z.to(device)\n",
    "        oc, oz = model(v, t)\n",
    "        loss = 0.7 * lc(oc, c) + 0.3 * lz(oz, z)\n",
    "        tot += loss.item() * v.size(0)\n",
    "\n",
    "        ac_pred.append(oc.argmax(1).cpu().numpy())\n",
    "        ac_true.append(c.cpu().numpy())\n",
    "        az_pred.append(oz.argmax(1).cpu().numpy())\n",
    "        az_true.append(z.cpu().numpy())\n",
    "\n",
    "    ac_pred = np.concatenate(ac_pred)\n",
    "    ac_true = np.concatenate(ac_true)\n",
    "    az_pred = np.concatenate(az_pred)\n",
    "    az_true = np.concatenate(az_true)\n",
    "\n",
    "    acc_c = accuracy_score(ac_true, ac_pred)\n",
    "    acc_z = accuracy_score(az_true, az_pred)\n",
    "    score = 0.7 * acc_c + 0.3 * acc_z\n",
    "\n",
    "    return tot / len(loader.dataset), acc_c, acc_z, score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # 1) Build fused features\n",
    "    train_df_full, test_df_full, X_train, X_test, y_class, y_zone, scaler, feature_cols = build_tabular_and_physics()\n",
    "    tab_dim = X_train.shape[1]\n",
    "    print(\"Tabular dim:\", tab_dim)\n",
    "\n",
    "    # 2) Train/val split\n",
    "    idx = np.arange(len(train_df_full))\n",
    "    tr_idx, va_idx = train_test_split(idx, test_size=0.2, random_state=SEED, stratify=y_class)\n",
    "\n",
    "    df_tr, df_va = train_df_full.iloc[tr_idx], train_df_full.iloc[va_idx]\n",
    "    X_tr, yc_tr, yz_tr = X_train[tr_idx], y_class[tr_idx], y_zone[tr_idx]\n",
    "    X_va, yc_va, yz_va = X_train[va_idx], y_class[va_idx], y_zone[va_idx]\n",
    "\n",
    "    train_ds = PitchDataset(df_tr, X_tr, TRAIN_VID_DIR, yc_tr, yz_tr)\n",
    "    val_ds   = PitchDataset(df_va, X_va, TRAIN_VID_DIR, yc_va, yz_va)\n",
    "\n",
    "    train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_ld   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 3) Model\n",
    "    model = HybridVideoTabModel3D(tab_dim).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    lc, lz = nn.CrossEntropyLoss(), nn.CrossEntropyLoss()\n",
    "\n",
    "    best_score = -1\n",
    "    best_state = None\n",
    "\n",
    "    # 4) Training with validation, early selection\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "        tl = train_one_epoch(model, train_ld, opt, lc, lz)\n",
    "        vl, ac, az, sc = eval_model(model, val_ld, lc, lz)\n",
    "\n",
    "        print(f\"Train {tl:.4f} | Val {vl:.4f}\")\n",
    "        print(f\"Class Acc: {ac:.4f} | Zone Acc: {az:.4f} | Score: {sc:.4f}\")\n",
    "\n",
    "        if sc > best_score:\n",
    "            best_score = sc\n",
    "            best_state = model.state_dict().copy()\n",
    "\n",
    "    print(\"\\nBest validation score:\", best_score)\n",
    "    # Use the best validation model directly for testing\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # 5) Predict on test\n",
    "    test_ds = PitchDataset(test_df_full, X_test, TEST_VID_DIR)\n",
    "    test_ld = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    all_cls, all_zone, all_names = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for v, t, _, _, fn in tqdm(test_ld, desc=\"Test\"):\n",
    "            v, t = v.to(device), t.to(device)\n",
    "            oc, oz = model(v, t)\n",
    "            all_cls.extend(oc.argmax(1).cpu().tolist())\n",
    "            all_zone.extend(oz.argmax(1).cpu().tolist())\n",
    "            all_names.extend(fn)\n",
    "\n",
    "    idx2cls = {0: \"ball\", 1: \"strike\"}\n",
    "    cls_str = [idx2cls[i] for i in all_cls]\n",
    "    zone = (np.array(all_zone) + 1).tolist()\n",
    "\n",
    "    pred = pd.DataFrame({\n",
    "        \"file_name\": all_names,\n",
    "        \"pitch_class\": cls_str,\n",
    "        \"zone\": zone\n",
    "    })\n",
    "\n",
    "    template = pd.read_csv(TEMPLATE_CSV)\n",
    "    sub = template.drop(columns=[\"pitch_class\", \"zone\"], errors=\"ignore\")\n",
    "    sub = sub.merge(pred, on=\"file_name\", how=\"left\")\n",
    "\n",
    "    sub.to_csv(SUBMISSION_OUT, index=False)\n",
    "    print(\"\\nSaved submission:\", SUBMISSION_OUT)\n",
    "    print(sub.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bac200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m all_cls, all_zone, all_names \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43moc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    238\u001b[0m             ]\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "def load_video_frames_sampled(video_path, n_frames=N_FRAMES):\n",
    "    \"\"\"\n",
    "    Always returns a tensor of shape (T, C, H, W)\n",
    "    Never returns None, even if video is corrupted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if total <= 1 or not cap.isOpened():\n",
    "            cap.release()\n",
    "            return torch.zeros(n_frames, 3, 128, 128)\n",
    "\n",
    "        indices = np.linspace(0, total - 1, n_frames).astype(int)\n",
    "        frames = []\n",
    "\n",
    "        for idx in indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            if not ret or img is None:\n",
    "                # return black frame instead of None\n",
    "                frames.append(torch.zeros(3, 128, 128))\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            tensor = video_transform(img)\n",
    "            frames.append(tensor)\n",
    "\n",
    "        cap.release()\n",
    "        return torch.stack(frames, dim=0)\n",
    "\n",
    "    except Exception:\n",
    "        # absolute fallback\n",
    "        return torch.zeros(n_frames, 3, 128, 128)\n",
    "    \n",
    "train_df_full, test_df_full, X_train, X_test, y_class, y_zone, scaler, feature_cols = build_tabular_and_physics()\n",
    "# 5) Predict on test\n",
    "test_ds = PitchDataset(test_df_full, X_test, TEST_VID_DIR)\n",
    "test_ld = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "all_cls, all_zone, all_names = [], [], []\n",
    "with torch.no_grad():\n",
    "    for v, t, _, _, fn in tqdm(test_ld, desc=\"Test\"):\n",
    "        v, t = v.to(device), t.to(device)\n",
    "        oc, oz = model(v, t)\n",
    "        all_cls.extend(oc.argmax(1).cpu().tolist())\n",
    "        all_zone.extend(oz.argmax(1).cpu().tolist())\n",
    "        all_names.extend(fn)\n",
    "\n",
    "idx2cls = {0: \"ball\", 1: \"strike\"}\n",
    "cls_str = [idx2cls[i] for i in all_cls]\n",
    "zone = (np.array(all_zone) + 1).tolist()\n",
    "\n",
    "pred = pd.DataFrame({\n",
    "    \"file_name\": all_names,\n",
    "    \"pitch_class\": cls_str,\n",
    "    \"zone\": zone\n",
    "})\n",
    "\n",
    "template = pd.read_csv(TEMPLATE_CSV)\n",
    "sub = template.drop(columns=[\"pitch_class\", \"zone\"], errors=\"ignore\")\n",
    "sub = sub.merge(pred, on=\"file_name\", how=\"left\")\n",
    "\n",
    "sub.to_csv(SUBMISSION_OUT, index=False)\n",
    "print(\"\\nSaved submission:\", SUBMISSION_OUT)\n",
    "print(sub.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
